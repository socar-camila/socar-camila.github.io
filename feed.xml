<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.6">Jekyll</generator><link href="https://tech.socarcorp.kr/feed.xml" rel="self" type="application/atom+xml" /><link href="https://tech.socarcorp.kr/" rel="alternate" type="text/html" /><updated>2022-03-18T02:00:11+00:00</updated><id>https://tech.socarcorp.kr/feed.xml</id><title type="html">SOCAR Tech Blog</title><subtitle>쏘카 기술 블로그</subtitle><author><name>SOCAR</name></author><entry><title type="html">쏘카 QA는 무슨 일을 하고 어떻게 일하나요?</title><link href="https://tech.socarcorp.kr/qa/2022/03/18/probationary-period_QA.html" rel="alternate" type="text/html" title="쏘카 QA는 무슨 일을 하고 어떻게 일하나요?" /><published>2022-03-18T02:00:00+00:00</published><updated>2022-03-18T02:00:00+00:00</updated><id>https://tech.socarcorp.kr/qa/2022/03/18/probationary-period_QA</id><content type="html" xml:base="https://tech.socarcorp.kr/qa/2022/03/18/probationary-period_QA.html">&lt;p&gt;안녕하세요.  작년 11월에 쏘카 QA 팀에 경력직으로 입사한 카밀라입니다.&lt;/p&gt;

&lt;p&gt;신입 때 QA 업무는 반복적인 업무를 하는 단순 직무라 생각했었습니다. 하지만 여러 프로젝트들을 진행하며 커버리지를 높이기 위한 활동들과 기본 기능을 지속적으로 검증하기 위한 자동화 테스트 구축 등 계속해서 배워야 할 것들이 많은 직무라는 것을 몸소 깨달았습니다.&lt;/p&gt;

&lt;p&gt;이번 글에서는 저의 입사 지원 과정부터 입사 후 3개월간의 수습 기간 동안 경험하며 느꼈던 내용을 공유해 보려고 합니다.&lt;/p&gt;

&lt;p&gt;다음과 같은 내용에 관심 있으신 분들이 보시면 도움 될 거라 생각합니다. 🙂&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;쏘카 QA 팀에 어떻게 입사했을까?&lt;/li&gt;
  &lt;li&gt;QA가 하는 일?&lt;/li&gt;
  &lt;li&gt;쏘카 QA 팀은 온보딩을 어떻게 진행할까?&lt;/li&gt;
  &lt;li&gt;쏘카의 QA 팀이 어떻게 업무할까?&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;목차&quot;&gt;목차&lt;/h2&gt;

&lt;p&gt;저는 다음 순서에 따라 글을 적어보았습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;QA 팀 입사 지원 과정
    &lt;ul&gt;
      &lt;li&gt;쏘카에 지원한 이유&lt;/li&gt;
      &lt;li&gt;입사 과정&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;QA란?
    &lt;ul&gt;
      &lt;li&gt;QA? 뭐 하는 팀이지?&lt;/li&gt;
      &lt;li&gt;일반적으로 QA는 무엇을 하나?&lt;/li&gt;
      &lt;li&gt;이슈를 찾기 위한 QA의 활동들&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;쏘카 QA의 업무
    &lt;ul&gt;
      &lt;li&gt;업무 방식&lt;/li&gt;
      &lt;li&gt;회의&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;쏘카 QA 팀의 온보딩 과정
    &lt;ul&gt;
      &lt;li&gt;쏘키에 익숙해지기&lt;/li&gt;
      &lt;li&gt;업무 경험하기&lt;/li&gt;
      &lt;li&gt;혼자 프로젝트 진행하기&lt;/li&gt;
      &lt;li&gt;온보딩을 하며 느낀 점&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;QA 직군 지원자를 위한 TIP&lt;/li&gt;
  &lt;li&gt;끝으로&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;1-qa-팀-입사-지원-과정&quot;&gt;1. QA 팀 입사 지원 과정&lt;/h2&gt;

&lt;p&gt;먼저 간략히 쏘카 QA 팀에 입사하게 된 과정에 대해 소개해 보려고 합니다.&lt;/p&gt;

&lt;h3 id=&quot;11-쏘카에-지원한-이유&quot;&gt;1.1. 쏘카에 지원한 이유&lt;/h3&gt;

&lt;p&gt;제가 쏘카에 지원한 이유는 모빌리티 산업에 관심이 많았고 자동차를 좋아해서였습니다. 또한 다음의 기준들을 만족하는지도 중요했습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;내가 좋아하는 일을 하면서 회사가 성장하고 나도 성장할 수 있는지&lt;/li&gt;
  &lt;li&gt;자체 서비스를 운영하는 회사인지&lt;/li&gt;
  &lt;li&gt;직원 규모가 어느 정도 이상인지(100명 이상)&lt;/li&gt;
  &lt;li&gt;지속적으로 성장하고 있는 회사인지&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;쏘카는 ‘쏘카 앱’을 기반으로 다양한 서비스를 운영하고 있고, 위와 같은 기준을 충분히 만족하는 회사였습니다. 그리고 채용공고와 커뮤니티 후기에서 QA 팀에서는 ‘주도적인 업무를 진행해 볼 수 있다’라는 부분과 ‘테스팅 자동화’를 진행한다는 부분이 가장 마음에 들었습니다. 쏘카에서는 저의 부족한 부분을 발전시키고 이전과는 다른 업무 경험을 쌓을 수 있을 것이라는 생각이 들었습니다.&lt;/p&gt;

&lt;h3 id=&quot;12-입사-과정&quot;&gt;1.2. 입사 과정&lt;/h3&gt;

&lt;p&gt;입사 과정은 다음 프로세스로 진행되었습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;서류 제출&lt;/li&gt;
  &lt;li&gt;1차 면접 (기술)&lt;/li&gt;
  &lt;li&gt;2차 면접 (본부장 면접)&lt;/li&gt;
  &lt;li&gt;3차 면접 (CTO 면접)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;서류를 제출하고 일주일이 지나기 전에 전화로 채용 과정에 대해 안내받았습니다. 1차 면접 전날까지 사전과제를 제출해야 한다는 안내를 받았고 1차 면접이 통과하면 2차, 3차 면접이 있다고 안내받았습니다. 사전과제는 채용공고에도 나와있듯 쏘카의 서비스 중 하나를 선택하여 테스트 케이스를 작성하는 것이었습니다.&lt;/p&gt;

&lt;p&gt;1차 면접(기술면접)에 실무진, 쏘카에 입사하면 같이 일하게 될 팀장님과 팀원 두 분이 면접관으로 참여하였습니다. 주로 이력서 위주의 질문이 나왔습니다. 참여했던 프로젝트에서 어떤 업무를 어떤 프로세스와 방식으로 진행했는지에 대한 질문과 업무를 하면서 마주할 수 있는 문제들에 대한 해결 방법을 묻는 질문이었습니다. 제출한 사전과제에 대해 해당 주제를 선택한 이유와 본인이 진행한 과제에 대해 설명하는 시간을 가졌고 마지막으로 입사해서 하고 싶은 업무와 본인의 성격에 대한 질문으로 마무리되었습니다.&lt;/p&gt;

&lt;p&gt;1차 면접 후 1주일 안에 합격 연락이 왔고 2차와 3차 면접이 같은 날에 진행될 것이라 안내받았습니다. 2차는 본부장 면접이고 3차는 인사팀과 CTO 면접이라 안내받았습니다.&lt;/p&gt;

&lt;p&gt;2차 면접에서는 본부장님과의 면접이 이루어졌고 1차와 비슷하게 이력서 위주의 질문들과 기술적인 부분, 인성 관련 질문도 있었습니다. 2차는 30분 정도 진행되었고 2차 면접 종료 후 바로 3차 면접을 진행했습니다. 3차 면접에서는 주로 CTO 님이 질문을 하셨고 딱딱한 질의응답보다는 저의 경험을 바탕으로 자유롭게 대화를 하듯 진행되었습니다. 그리고 조언도 해주셨는데 면접이 종료되고 난 뒤에도 해주신 말씀이 계속 생각나고 질문을 곱씹어 생각할 정도로 여운이 남는 면접이었습니다.&lt;/p&gt;

&lt;p&gt;3차 면접 이후로 최종적으로 합격하여 쏘카에서 일하게 되었습니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;2-qa란&quot;&gt;2. QA란?&lt;/h2&gt;

&lt;p&gt;먼저 쏘카 QA 업무 설명에 앞서, 일반적으로 QA는 어떤 일을 하는지 먼저 설명해 보고자 합니다.&lt;/p&gt;

&lt;h3 id=&quot;21-qa-뭐-하는-팀이지&quot;&gt;2.1. QA? 뭐 하는 팀이지?&lt;/h3&gt;

&lt;p&gt;QA에 대해 궁금하고 생소하신 분들도 계시고 왜 필요한지에 대한 의문을 가지는 분들도 많을 겁니다. 먼저 QA는 Quality Assurance의 약자로 ‘품질 보증’ 이란 뜻을 가지고 있습니다. QA 팀은 서비스의 ‘품질 보증’ 관련 업무를 하는 팀으로, &lt;strong&gt;서비스의 기능을 검증하고 관리하기 위한 일련의 활동을 합니다.&lt;/strong&gt; 프로젝트, 조직 규모가 작은 경우 개발자나 관리 조직에서 직접 기능 검증을 진행하기도 하지만, 프로젝트와 조직 규모가 커지는 경우 QA를 전담으로 하는 QA 팀을 구성해서 운영하기도 합니다.&lt;/p&gt;

&lt;p&gt;‘QA = Tester’라고 생각하시는 분들이 많습니다. 물론 QA의 활동 중 기능 테스트도 포함되어 있습니다. 하지만 QA는 단순히 서비스의 기능 테스트만 하지 않습니다. QA는 프로젝트의 시작부터 마무리까지 모든 과정에 참여하여 각 단계별로 품질을 저하시키거나 리소스가 낭비될 수 있는 요소를 발견한 뒤, 해당 프로젝트의 품질을 향상시키고 리소스 낭비를 방지하는 것을 목적으로 품질 보증 활동을 합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/QA/qa_1.png&quot; alt=&quot;img&quot; width=&quot;50%&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;22-일반적으로-qa는-무엇을-하나&quot;&gt;2.2. 일반적으로 QA는 무엇을 하나?&lt;/h3&gt;

&lt;h4 id=&quot;킥오프-참여&quot;&gt;킥오프 참여&lt;/h4&gt;

&lt;p&gt;회사마다 QA가 투입되는 시기는 다를 수 있지만 주로 QA는 킥오프(Kick-off) 단계부터 참여하게 됩니다. &lt;strong&gt;단순히 버그를 찾기 위한 것이 아니라 프로젝트의 방향성, 목적, 요구사항 등 프로젝트의 근본적인 목적을 명확히 파악해야 올바른 검증을 진행할 수 있기 때문입니다.&lt;/strong&gt; 또한 초기 단계에서 발생할 수 있는 오류를 사전에 방지하여 낭비될 수 있는 리소스를 줄일 수 있습니다.&lt;/p&gt;

&lt;p&gt;프로젝트가 진행되는 중간에 QA가 참여할 경우 프로젝트의 구성과 기능 파악, 테스트 범위, 검증 항목 선정 등에 더 많은 시간을 소모하게 되고 초기에 발견할 수 있던 문제점이 발견된다면 불필요한 리소스가 낭비될 수 있습니다. 그리고 프로젝트의 기간과 목적에 적합한지, 프로젝트 기간을 고려하여 진행 가능한지, 기간이 얼마나 더 필요한지 등을 제대로 판단할 수 없게 됩니다.&lt;/p&gt;

&lt;p&gt;QA는 지속적으로 개발자, 기획자와 소통하며 기획의 목적대로 흘러가고 있는지 업무상 진행되는 과정에서 비효율적인 부분은 없는지 리뷰를 진행하고 개선안을 제시합니다. 또한 유저의 입장에서 발생할 수 있는 불편함은 없는지 확인합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/QA/qa_3.png&quot; alt=&quot;img&quot; /&gt;
&lt;em&gt;QA의 업무 단계별 활동과 산출물입니다.&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&quot;분석--qa-plan-작성&quot;&gt;분석 &amp;amp; QA Plan 작성&lt;/h4&gt;

&lt;p&gt;킥오프가 진행된 후에는 기획서를 분석하여 프로젝트 수행 시 발생할 수 있는 리스크를 예상해 보고 테스트 전략을 수립합니다.&lt;/p&gt;

&lt;p&gt;이후에는 QA Plan 또는 테스트 계획이라고도 하는 문서는 작성합니다. &lt;strong&gt;QA Plan은 테스트를 하기 위해 필요한 리소스들을 요약해놓은 문서로, QA가 정해진 프로세스대로 업무를 수행하기 위한 청사진 역할을 합니다.&lt;/strong&gt; 이 안에서 테스트의 명확한 기준을 세워 원하는 방향으로 테스트가 진행될 수 있도록 합니다. 이 문서는 테스트를 수행하는 도중 변경되기도 하는 등 지속적으로 관리됩니다.&lt;/p&gt;

&lt;p&gt;QA Plan에는 다음 내용들이 포함됩니다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[프로젝트 명] QA Plan

1. 요약
2. 프로젝트명
3. 프로젝트 자료
    3.1. 기획서
    3.2. 디자인
    3.3. Test case
    3.4. Test data
4. 참여자
5. 배포되는 버전
6. QA 기간
    6.1. Test case 작성 기간
    6.2. 테스트 기간
    6.3. Sign off 날짜
    6.4. 배포 요청일
    6.5. 모니터링
7. 테스트 범위
8. 테스트 제외 범위
9. 품질 목표 설정
10. 테스트 종료 조건 설정
11. 테스트 환경
    11.1. 디바이스
    11.2. OS 버전
12. 테스트 요청사항
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;테스트-케이스-작성&quot;&gt;테스트 케이스 작성&lt;/h4&gt;

&lt;p&gt;QA Plan이 작성되었다면 테스트 케이스(TC)를 작성합니다. &lt;strong&gt;테스트 케이스를 작성하는 과정에서 요구사항에 대한 오류를 찾을 수도 있고 고려되지 않았던 부분을 찾아낼 수 있습니다&lt;/strong&gt;. 또한 테스트 케이스 리뷰 과정을 통해 팀 구성원들에게 테스트 케이스 적정성을 점검하고 잘못된 이해로 인한 오류도 점검할 수 있습니다.&lt;/p&gt;

&lt;p&gt;다음은 테스트 케이스 예시입니다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;ID&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Category&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Preconditions&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Steps&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Expected result&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Galaxy21 (Android 11)&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;iPhoneX (iOS 14.4.2)&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Comment&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Socar_001&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;예약하기&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;쏘카 앱에 로그인되어 있는 상태&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;지도에서 쏘카 존을 선택&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;선택한 쏘카 존의 차량 목록이 노출됨&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;PASS&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;N/A&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;다른 기종 확인 필요&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&quot;테스트-데이터와-환경-준비&quot;&gt;테스트 데이터와 환경 준비&lt;/h4&gt;

&lt;p&gt;테스트 케이스 작성과 리뷰가 완료되었다면, 본격적으로 테스트에 들어가기에 앞서 테스트 데이터와 환경을 준비해야 합니다. &lt;strong&gt;테스트를 수행하기 위한 기본 데이터들을 정리하고 어떤 환경에서 테스트가 시작될지를 미리 준비하는 과정입니다.&lt;/strong&gt; 테스트를 위한 데이터의 예로는 테스트 계정, 계정에 따른 권한 등이 있을 수 있고 테스트 환경은 테스트 서버 설정이 포함됩니다.&lt;/p&gt;

&lt;h4 id=&quot;테스트-수행--버그-리포트-작성&quot;&gt;테스트 수행 &amp;amp; 버그 리포트 작성&lt;/h4&gt;

&lt;p&gt;본격적으로 테스트 수행을 시작하게 되면 준비된 테스트 케이스 외에도 &lt;strong&gt;탐색적 테스트, ad-hoc 테스트&lt;/strong&gt;를 통해 이슈를 발견할 수 있습니다. 이때 발견한 이슈들을 구두로만 개발자와 주고받게 된다면 히스토리 관리가 힘들어질 수 있습니다. 이런 불편함을 줄이고 프로젝트 이슈들을 관리하기 위해 버그 리포트를 작성합니다.&lt;/p&gt;

&lt;p&gt;버그 리포트에는 다음 내용들이 포함됩니다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[버그리포트 제목]

- 발생 환경(os 버전, 앱/웹 버전, 서버)
- 재현율
- 이슈 설명
- 사전 조건
- 재현 절차
- 예상 결과
- 실제 결과
- 담당 부서
- 우선순위/심각도
- 발생 버전/수정 버전
- 이슈 카테고리
- 첨부파일
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;테스트-결과-공유&quot;&gt;테스트 결과 공유&lt;/h4&gt;

&lt;p&gt;테스트가 완료되고 나면 결과를 정리하여 프로젝트 구성원들에게 공유합니다. QA Plan에서 정한 품질 목표를 달성하여 &lt;strong&gt;릴리즈가 가능한 상태인지를 알려주고 테스트 수행 결과와 품질 목표 달성에 따른 판단 결과, 테스트 진행하면서 발생한 이슈 현황들에 대한 정보&lt;/strong&gt;를 담고 있습니다.&lt;/p&gt;

&lt;p&gt;QA가 수행하는 단계마다 산출물이 발생하고 있고 이 산출물들은 QA가 프로젝트를 수행함에 있어 어떤 업무를 수행하고 어떻게 진행해야 하는지 방향을 알려주는 표지판 역할을 하게 됩니다. 수행하는 단계별로 QA 업무에 대해 정리하였지만 사실 ‘여기까지가 QA의 업무입니다’라고 할 수 없습니다.&lt;/p&gt;

&lt;p&gt;사실 유관부서와 협의하에 품질 향상에 도움이 되는 일 중 QA가 할 수 있는 모든 일들을 한다고 생각하시면 QA 업무가 더 쉽게 와닿을 것 같습니다.&lt;/p&gt;

&lt;h3 id=&quot;23-이슈를-찾기-위한-qa의-활동들&quot;&gt;2.3. 이슈를 찾기 위한 QA의 활동들&lt;/h3&gt;

&lt;p&gt;“이슈 찾는 활동? 테스트 케이스로만 테스트하고 이슈 찾는 거 아니었나요?”라고 생각하실 수 있습니다.&lt;/p&gt;

&lt;p&gt;작성한 테스트 케이스로만 이슈를 찾을 수는 없습니다. 일반적으로 테스트 케이스는 기획서를 기반으로 재현 조건과 기대 결과를 도출하여 기대 결과가 정상적으로 출력되는지 확인하는 긍정 테스트에 가깝습니다. 그럼 부정 테스트 케이스를 추가하면 되지 않을까? 물론 부정 테스트의 방법도 있지만 비정상적인 상황은 너무 다양하기 때문에 모든 것을 다 케이스화하는 것은 현실적으로 불가능합니다. 또한 자주 업데이트가 되는 서비스라면 더욱 힘들 겁니다.&lt;/p&gt;

&lt;p&gt;그래서 QA는 각 단계에서 할 수 있는 최선의 활동들을 통해 이슈를 찾아가고 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;개발 전에 프로젝트의 목적과 기획서를 바탕으로 다양한 시나리오를 생각하는 과정에서 명확히 정의되지 않은 것들을 확인한 뒤, 이해관계에 따라 발생할 수 있는 문제점들을 발견하여 개선될 수 있도록 합니다.&lt;/strong&gt; 또한 기획이나 컨텐츠 리뷰를 통해 논리적 오류나 유저에게 잘못 이해될 수 있는 부분, 오타 등을 확인하여 &lt;strong&gt;개발 이후 발생할 수 있는 이슈들을 파악&lt;/strong&gt;합니다.&lt;/p&gt;

&lt;p&gt;또한 단순히 버그를 찾는 것이 아닌 유저 입장에서 미래에 발생할 수 있는 문제들을 미리 예측해 보는 것도 이슈를 찾는 활동입니다. 실제 유저의 입장에서 서비스를 사용해 보며 유저가 사용할 수 있는 경로는 어떤 것이 있으며 어떤 부분에서 불편함을 느낄 수 있을지에 대한 고민을 합니다. 이때 유저 사용성에 따른 시나리오를 분리하여 테스트를 진행하기도 하는데 앞서 언급한 부정 테스트(Unhappy Path Test)와 긍정 테스트(Happy Path Test) 방법이 있습니다. 부정 테스트는 주어진 소프트웨어가 올바르게 작동하는지 확인하기 위해 잘못된 데이터를 입력하고 잘못된 작업을 수행하도록 구성합니다. 그러면 소프트웨어는 작동되지 않고 &lt;strong&gt;사용자가 이해할 수 있는 오류 메시지를 노출해 주는지 확인합니다.&lt;/strong&gt; 반대로 긍정 테스트는 오류가 생성되지 않는 데이터를 입력하여 &lt;strong&gt;소프트웨어가 의도대로 작동하는 것을 확인합니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;기존 서비스에 기능이 추가되는 경우 기존 서비스가 정상 동작하는지 확인하기 위해 기본 기능에 대한 체크리스트를 수행하기도 하지만, 반복적으로 진행해야 되는 테스트의 경우 자동화 테스트를 진행하기도 합니다. 자동화 테스트란 자동화 도구로 테스트 스크립트를 개발하여 소프트웨어의 유효성을 검사하는 것입니다. &lt;strong&gt;자동화 테스트를 통해 기존에는 발생하지 않았던 문제점들을 찾아낼 수 있고 변경된 부분을 발견할 수 있습니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;이처럼 QA는 테스트 케이스를 활용하는 테스트 외에도 다양한 활동들 가운데 품질 향상을 위해 문제점을 찾고 개선하는 노력을 하고 있습니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;3-쏘카-qa의-업무&quot;&gt;3. 쏘카 QA의 업무&lt;/h2&gt;

&lt;p&gt;이제 쏘카 QA 팀에서는 구체적으로 어떻게 업무하는지에 대해서 설명드리고자 합니다.&lt;/p&gt;

&lt;h3 id=&quot;31-업무-방식&quot;&gt;3.1. 업무 방식&lt;/h3&gt;

&lt;p&gt;QA라도 회사마다 각기 다른 프로세스에 따라 업무를 진행합니다. 기획과 개발이 다 완료된 상태에서 QA가 투입되는 경우도 있고, 주제만 정하고 기획을 만들어 가는 과정에서 QA가 투입되는 경우, 기획서가 만들어진 후 QA가 투입되는 경우 등 다양한 단계에서 참여가 이루어지고 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/QA/qa_2.png&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;쏘카에서는 QA 요청서가 발의되었을 때 QA가 프로젝트에 참여합니다.&lt;/strong&gt; QA 요청서는 JIRA를 통해 만들어지고 정해진 양식에 맞춰 프로젝트 리더가 작성하여 요청합니다. 이 요청서에는 기획서가 포함되어 있고 기획, 개발, 디자인 일정이 포함됩니다. 프로젝트별로 상이하긴 하지만 디자인이 완료된 경우 디자인 링크도 포함됩니다. 그리고 프로젝트에 관련된 자료들이 첨부됩니다.&lt;/p&gt;

&lt;p&gt;QA 요청서가 발의되면 팀 내에서 &lt;strong&gt;담당자를 정하게 되고 본격적으로 프로젝트에 투입&lt;/strong&gt;되어 업무를 하게 됩니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;배정된 담당자는 킥오프(Kick-off) 회의에 참여&lt;/strong&gt;하여 프로젝트의 규모와 목적을 파악하고 다음 내용들을 &lt;strong&gt;QA Plan에 작성&lt;/strong&gt;합니다.
    - 프로젝트 정보
    - QA 일정
    - 테스트 데이터
    - 테스트 기준
    - 테스트 범위
    - 테스트 환경&lt;/p&gt;

&lt;p&gt;QA Plan을 작성할 때 보통 QA 요청서를 참고하고 QA를 진행하면서 필요할 사항들을 수집하고 정리합니다. 프로젝트를 진행하기에 앞서 필요한 전제 조건들과 검증 시 반드시 확인해야 될 사항들, 그리고 검증 진행 방법들도 회의를 통해 확인하고 적어놓습니다. 쏘카의 QA Plan은 초기에 한번 적고 끝나는 것이 아니라 테스트 케이스를 작성하거나 테스트를 수행하면서도 새로운 내용이나 참고할 사항들을 꾸준히 업데이트하게 됩니다.
프로젝트에 관해 설명이 더 필요한 부분이나 의견이 있다면 PM, 개발자, 디자이너 등 프로젝트에 참여하는 인원들과 소통하여 문제를 해결합니다.&lt;/p&gt;

&lt;p&gt;프로젝트에 대해 파악되었다면 &lt;strong&gt;테스트 케이스 혹은 체크리스트를 작성&lt;/strong&gt;합니다. 프로젝트의 규모가 크지 않거나 빠르게 확인해야 프로젝트의 경우, 확인해야 될 주요 항목을 간략하게 적어서 정상적으로 수행이 되는지를 판단하기 위해 체크리스트를 작성하게 됩니다. 체크리스트와 다르게 테스트 케이스의 경우에는 전제조건과 수행하는 절차 그리고 수행함으로 인해 기대되는 결과가 포함되기 때문에 체크리스트보다 더 세밀하게 기능을 테스트를 진행할 수 있습니다. 쏘카에서는 테스트 케이스 관리를 웹 기반 테스트 관리 시스템인 &lt;a href=&quot;https://testlink.org/&quot;&gt;Testlink&lt;/a&gt;로 하고 있습니다. 테스트 케이스는 작성하는 사람에 따라 다르겠지만 주어진 형식은 맞추되 작성하는 건 본인 성향에 따라 작성하고 있습니다. 어떤 사람은 오타와 띄어쓰기 하나까지 세세하게 테스트 케이스로 작성할 수 있고 어떤 사람은 기능만 위주로 작성하여 차이가 나지 않을까 우려할 수 있지만 테스트 케이스를 작성한 후 팀 내에서 리뷰를 진행하고 피드백을 통해 맞춰가고 있습니다. 또한 필요에 따라 &lt;strong&gt;팀 내에서 테스트 케이스 리뷰가 진행된 후 프로젝트 내에서도 테스트 케이스 리뷰&lt;/strong&gt;를 진행합니다.&lt;/p&gt;

&lt;p&gt;개발이 완료되고 나면 개발 환경에서 테스트를 수행할 수 있게 &lt;strong&gt;테스트 서버를 띄워 QA를 수행&lt;/strong&gt;합니다. 작성한 테스트 케이스를 바탕으로 테스트를 수행하는 데 프로젝트에 따라서 앱 또는 웹 테스트를 진행합니다. 데이터를 확인해야 되는 프로젝트라면 DB를 조회해서 테스트를 진행할 수도 있고 실제 차량에 들어가는 장비를 가지고 테스트를 진행하기도 합니다. 또한 일정에 따라 실제 차량으로 테스트를 진행하는 등 다양한 테스트 활동을 추가로 진행하기도 합니다. &lt;strong&gt;테스트를 수행하면서 발견되는 이슈들은 JIRA에 등록&lt;/strong&gt;합니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;QA가 완료된 후에 팀과 프로젝트 내에 프로젝트가 종료되었다는 의미로 Sign off&lt;/strong&gt;를 합니다. 프로젝트 수행 내용을 간략하게 전달하고 서버나 웹 관련 프로젝트라 배포까지 완료되었다면 모니터링에 대한 내용도 포함하여 공유합니다.&lt;/p&gt;

&lt;p&gt;그 후에는 &lt;strong&gt;프로젝트를 수행하면서 알게 된 내용이나 공유할 내용, 남겨야 되는 주요 토픽 등에 대해 자유롭게 문서 정리&lt;/strong&gt;를 합니다. QA Plan에 내용을 추가하여 정리하는 경우도 있지만 규모와 히스토리가 긴 프로젝트의 경우엔 컨플루언스에 따로 페이지를 만들어서 작성합니다.&lt;/p&gt;

&lt;p&gt;프로젝트별로 QA가 완료되고 나면 &lt;strong&gt;하나의 버전으로 배포하기 위해 검토를 한 후 빌드 요청&lt;/strong&gt;을 합니다. 빌드 된 앱의 회귀 테스트(Regression test)를 진행한 후 앱 심사를 요청하고 &lt;strong&gt;심사가 완료되고 난 뒤 QA 팀에서 마켓 배포를 수행합니다.&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;32-회의&quot;&gt;3.2. 회의&lt;/h3&gt;

&lt;p&gt;쏘카 QA 팀에서 정기적으로 진행되는 회의는 2개가 있는데 그중 하나는 &lt;strong&gt;매일 아침 10시에 업무공유를 위한 회의&lt;/strong&gt;입니다. 각자 당일에 진행할 업무에 대해 공유하고 전달사항을 공유 받는 회의입니다. 또한 새로운 업무가 생겼을 때 담당자를 지정하는 것도 아침 회의 시간에 주로 진행됩니다.&lt;/p&gt;

&lt;p&gt;또 다른 하나는 &lt;strong&gt;매주 금요일 오후 2시에 진행하는 회고&lt;/strong&gt;입니다. 한주를 돌아보며 자유롭게 이야기하고 의견을 나누는 시간입니다. 한 주 동안 업무를 하면서 좋았던 점과 아쉬웠던 점에 대해 이야기를 하고 진행하고 있는 프로젝트나 팀 내에서 논의하고 싶은 내용에 대해 주제를 정해 이야기하기도 합니다. 처음에는 회고라 해서 무겁고 딱딱한 분위기일 수도 있겠다라 생각이 들었지만, 실제로 해보니  편하게 수다 떨듯 얘기하면서도 진지한 얘기를 할 때는 진지하게 의견을 나누기도 했습니다. 참여하기 전에는 무슨 얘기를 해야 될지, 이런 얘기도 해도 되나? 하는 걱정이 들었지만 생각보다 2시간이 훌쩍 지나가곤 합니다. 회고 시간을 통해 팀원들과 다 같이 얘기하는 시간을 갖고 업무에 대한 조언과 도움도 받을 수 있습니다. 또한 우리 팀이 나아 갈 방향과 진행할 업무들 그리고 개선할 점들을 토론하며 각자가 QA 팀의 일원으로서 함께 팀을 만들어나가는 의미 있는 시간이라 생각합니다.&lt;/p&gt;

&lt;p&gt;이 외에 한 달에 한 번 쏘카의 전 직원들이 참여하는 &lt;strong&gt;Town Hall 이라는 회의&lt;/strong&gt;가 있고 각자가 속한 &lt;strong&gt;프로젝트에서 진행하는 회의&lt;/strong&gt;가 있습니다. 팀 내에서 갑자기 생긴 논의사항이나 전달사항이 있을 경우에도 회의가 생기기도 합니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;4-쏘카-qa-팀의-온보딩-과정&quot;&gt;4. 쏘카 QA 팀의 온보딩 과정&lt;/h2&gt;

&lt;p&gt;다음으로 QA 팀에 합류한 이후 온보딩 과정의 경험을 공유해 보려 합니다.&lt;/p&gt;

&lt;h3 id=&quot;41-쏘카에-익숙해지기&quot;&gt;4.1. 쏘카에 익숙해지기&lt;/h3&gt;

&lt;p&gt;채용 프로세스가 끝나고 드디어 쏘카 입사 첫날! 로비로 가는 것부터 지하를 뱅글뱅글 돌고 물어보고서야 찾아갈 수 있었습니다. 팀 내에서 진행되는 온보딩은 4주 과정으로 계획되어 있었지만 일정상 5주간 진행되었습니다.&lt;/p&gt;

&lt;p&gt;재택근무를 시행하고 있어 동료들을 많이 만나진 못했지만 화상회의로 또는 종종 사무실에 출근하시는 분들과 인사하고 같이 점심을 먹거나 티타임을 가졌습니다. 팀 온보딩을 진행하는 동안 저는 사무실 출근을 했고 사무실 투어도 하고 근처 맛집들을 가보기도 하며 종종 서울숲 산책도 했습니다. 그동안 미로 같던 회사 길도 이리저리 잘 찾아다닐 수 있게 되었고 예약도 찾기도 어렵던 회의실도 척척 예약하고 찾아갈 수 있게 되었습니다.&lt;/p&gt;

&lt;p&gt;PX(People Experience) 팀에서 진행하는 온보딩은 입사 후 일주일 뒤에 하루 일정으로 진행되었습니다. 같은 날 입사한 동료들과 온보딩에 참여하여 자연스럽게 서로에 대해 알아가며 점심도 같이 먹으며 친해질 수 있었습니다. 또한 쏘카의 히스토리와 문화를 액티비티를 통해 몸으로 익히며 알 수 있었습니다. 온보딩을 같이한 동료들과는 팀이 달라 자주는 아니지만 종종 만나서 점심을 먹기도 하고 티타임을 갖고 있습니다. 입사 후 몇 번의 만족도 조사를 시행했는데 신규 입사자가 쏘카에 적응할 수 있도록 지속적으로 돕는 프로세스가 정말 잘 되어있다고 느꼈습니다.&lt;/p&gt;

&lt;h3 id=&quot;42-업무-경험하기&quot;&gt;4.2. 업무 경험하기&lt;/h3&gt;

&lt;p&gt;QA 팀에서 진행된 온보딩은 5주 동안 진행되었고 입사 후 첫 주는 주로 PC 세팅과 업무에 필요한 장비와 계정을 등록했습니다. 업무 파악을 위해 각종 회의에 참여하기도 했습니다. 2주에 걸쳐 팀장님에게 업무 프로세스와 쏘카 앱에 대한 설명과 히스토리에 대해 교육을 받았습니다. 이후에는 쏘카 앱을 직접 사용해 보는 시간을 가졌고 각 서비스들을 담당했던 팀원들과 같이 해당 서비스를 살펴보는 시간을 가졌습니다. 3주 차엔 테스트 케이스 관리 툴의 사용법을 익혔습니다. 쏘카 앱 체크리스트를 직접 수행하면서 교육받은 내용을 리마인드하고 모르는 부분을 체크하는 시간도 가졌습니다. 마지막으로 4주 차, 5주 차에는 팀원과 같이 프로젝트에 참여하여 실제 업무를 익혔습니다. 해당 프로젝트 종료 후에는 혼자 프로젝트에 참여하여 직접 QA 업무를 수행할 수 있었습니다.&lt;/p&gt;

&lt;h4 id=&quot;문서-작성은-중요해&quot;&gt;문서 작성은 중요해&lt;/h4&gt;

&lt;p&gt;쏘카에 입사 후 놀랐던 것 중 하나가 신규 입사자가 볼 수 있는 자료가 많다는 것이었습니다.
회사와 업무에 대해 궁금한 것들을 찾아볼 수 있게 자료들이 잘 정리되어 있습니다.
신규 입사자들이 쏘카의 업무방식과 쏘카에 대한 이야기, 그리고 업무지원 및 요청 가이드 등을 알 수 있도록 ‘SOCAR 백과사전’ 이라는 것이 있고 노션(Notion)과 컨플루언스(Confluence)에 각 팀별, 프로젝트 별로 문서가 정리되어 있습니다.&lt;/p&gt;

&lt;p&gt;신규 입사자를 위한 것뿐 아니라 쏘카의 모든 직원들을 위한 자료도 많았습니다. 저도 입사 후 온보딩을 진행하면서 필요하다고 생각되는 문서들은 직접 만들거나 기존 문서를 업데이트하기도 했습니다.
이 문서들은 한 번에 일괄적으로 작성되는 것은 아니고, 업무를 하는 동안 본인이 수행한 업무를 리마인드하고 히스토리를 관리하기 위해 작성되곤 했습니다. 이렇게 모인 자료들은 쏘카의 모든 직원들에게 공유될 수 있었습니다. 저는 본인이 수행한 일을 문서로 남기는 것은 실제 업무를 수행하는 것만큼이나 중요하다고 생각하는데, 이게 생각과 다르게 지속되기란 쉽지 않은 문제입니다. 그런데 쏘카에서는 많은 동료들이 본인이 진행한 업무뿐만 아니라, 다른 동료들에게 필요할 수 있는 정보들을 문서화하고 지속적인 업데이트를 통해 관리해나가고 있는 것을 볼 수 있어서 인상 깊었습니다.&lt;/p&gt;

&lt;h4 id=&quot;같이하는-프로젝트-진행-경험하기&quot;&gt;같이하는 프로젝트 진행 경험하기&lt;/h4&gt;

&lt;p&gt;온보딩 4주 차에는 팀원과 같이 프로젝트에 참여하여 실제 업무를 하며 익히는 시간을 가졌습니다. 업무에 익숙한 팀원과 같이 프로젝트를 진행하면서 쏘카의 업무를 알아가도록 도와주는 과정이었습니다. 저는 팀 동료 에이미와 같이 프로젝트에 참여하였는데, 어느 단계에서 무엇을 해야 하는지, 다음 순서는 무엇인지, 제가 수행할 수 있는 업무는 직접 해볼 수 있게 에이미가 도와주셨고, 처음 해보는 것은 같이 수행하면서 업무에 적응할 수 있도록 도와주셨습니다. 물론 프로젝트마다 참여하는 인원은 다르지만 담당자와 어떻게 소통을 해야 하는지, 어떤 방식으로 업무가 진행되는지에 대해서도 배울 수 있는 시간이었습니다.&lt;/p&gt;

&lt;h4 id=&quot;모르는-건-질문하기&quot;&gt;모르는 건 질문하기&lt;/h4&gt;

&lt;p&gt;새로운 회사에 경력직으로 입사를 하더라도 새로운 회사의 업무방식에 맞춰 기존에 알던 것도 다시 보고 사용하던 도구들도 다시 배우게 됩니다. “경력직이니까 이런 건 당연히 알겠지?”라고 생각하시는 분들이 종종 있기 때문에, 입사 전에 심적으로 꽤 큰 부담이 있었습니다. 하지만 걱정했던 게 무색할 정도로 쏘카에 첫 출근하는 날 모두들 “모르는 거 궁금한 거 언제든 물어보세요”라고 먼저 말씀해 주셨습니다. 저도 마음을 조금 내려놓고 정말 많이 질문했는데 다들 하나같이 친절하게 알려주셨습니다. 시간 날 때마다 계속 신경 써주시고 알려주셔서 업무를 익히고 적응하는 데 도움이 되었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/QA/qa_4.png&quot; alt=&quot;img&quot; width=&quot;50%&quot; /&gt;
&lt;img src=&quot;/assets/images/QA/qa_5.png&quot; alt=&quot;img&quot; width=&quot;50%&quot; /&gt;
&lt;em&gt;팀 채널에 궁금한 사항을 남기면 팀원 분들이 친절하게 알려주십니다.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;또한 회사 뒤편에 서울숲이 있어 점심을 먹고 가볍게 산책하면서 소소한 이야기를 나누기도 합니다. 회사가 카페가 많은 성수동에 있어, 커피를 종종 마시면서 수다를 떨면서 자연스럽게 모르는 걸 묻기도 하고, 팀원들 간에 서로 일상을 공유하는 시간을 가지기도 합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/QA/qa_6.jpeg&quot; alt=&quot;img&quot; width=&quot;50%&quot; /&gt;
&lt;em&gt;성수동엔 이쁜 카페가 많습니다.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/QA/qa_7.jpeg&quot; alt=&quot;img&quot; width=&quot;50%&quot; /&gt;
&lt;em&gt;가을에 서울숲에 꼭 가보시길 추천드립니다.&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;43-혼자-프로젝트-진행하기&quot;&gt;4.3. 혼자 프로젝트 진행하기&lt;/h3&gt;

&lt;p&gt;같이 프로젝트를 진행해 본 후 혼자서 프로젝트에 참여하게 되었습니다. 쏘카의 QA로서 처음 맡은 업무였습니다.&lt;/p&gt;

&lt;p&gt;참여하게 된 프로젝트는 일부 기능 변경이 있는 작은 규모였습니다. 하지만 당혹스럽게도 팀 동료 에이미와 함께 진행했던 프로젝트와는 일하는 방식이 달랐습니다. 팀원들에게 조언을 구하며 업무를 진행했고, 예상치 못한 문제들이 발생하여 일정이 기존에 계획했던 것보다 딜레이가 되었지만 결과적으로는 잘 마무리를 할 수 있었습니다. 프로젝트가 종료된 후에는 진행한 업무에 대해 문서 정리를 하고, 이해관계자들과 논의하는 자리를 마련하여 개선되었으면 하는 부분과, 정리가 아직 안 된 부분에 대해 정리하였습니다.&lt;/p&gt;

&lt;h3 id=&quot;44-온보딩을-하며-느낀-점&quot;&gt;4.4. 온보딩을 하며 느낀 점&lt;/h3&gt;

&lt;p&gt;쏘카에 와서 처음부터 지금까지 너무 좋다고 생각하는 부분은 모두가 자유롭게 의견을 내고 듣는 사람들도 편견 없이 들어주고 같이 고민하고 개선하려 한다는 것입니다. 적극적이고 쏘카의 서비스를 쏘카의 모든 직원들이 같이 만들어나가고 있다는 느낌을 받았고 제가 그런 쏘카의 직원이라는 게 자랑스럽게 느껴졌습니다. 개개인이 아닌 쏘카라는 하나의 목표를 향해 나아간다는 느낌을 들었고 그것이 누군가의 강요가 아닌 모두의 자발적인 모습에서 비롯된 것이라는 점이 인상 깊었습니다.&lt;/p&gt;

&lt;p&gt;한편 온보딩을 하는 동안 좀 더 개선하면 좋겠다고 생각한 것은 ‘회의가 너무 많아서 줄었으면 좋겠다’ 이었습니다. 어떤 날은 정말 하루 종일 점심시간을 제외하고 회의에 참석한 날도 있었으니까요. 하지만 조직 개편 후에는 정기적으로 진행되던 많은 회의들이 사라졌고 본인 업무에 직접적인 연관이 있는 회의로 많이 축소되었습니다. 맡은 업무에 따라 여전히 많은 회의를 참석하는 날도 있지만 그만큼 할 수 있는 일이 늘었다는 것에 한편으로는 정말 쏘팸이 된 걸 느끼게 됩니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;5-qa-직군-지원자를-위한-tip&quot;&gt;5. QA 직군 지원자를 위한 TIP&lt;/h2&gt;

&lt;p&gt;이번에는 QA 직군 지원자분들을 위한 저만의 팁에 대해 공유드리려 합니다.&lt;/p&gt;

&lt;p&gt;QA는 꼼꼼해야 해, 커뮤니케이션이 능숙해야 해, 대처법을 잘 알아야 해, 문제를 많이 찾을 수 있어야 해, 남들과 다른 관점에서 볼 줄 알아야 해 등 QA 직무에 대해 물어보면 주로 들을 수 있는 말입니다. 하지만 모든 QA가 저런 특성을 가지진 않습니다. 커뮤니케이션이 약한 사람도 있고 꼼꼼하지 못한 사람도 많습니다. 저런 부분은 각 사람의 성향에 해당하는 것이기 때문에 저런 성향을 가지신 분들이라면 좋겠지만 저는 다음 세 가지가 더 중요하다 생각합니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;먼저 QA를 하고 싶다면 QA가 사용하는 기본적인 용어를 알고 있어야 된다 생각합니다.&lt;/strong&gt; 왜 그런 걸 알아야 하지? 몰라도 할 수 있지 않나? 하고 생각하실 수 있습니다. 물론 모르셔도 업무는 할 수 있습니다. 하지만 해당 직군에서 사용하는 용어들을 알고 있으면 본인 업무에 대한 이해와 수행할 수 있는 업무의 폭을 넓혀줄 수 있다 생각합니다. QA 채용공고를 보면 우대 항목에 ‘ISTQB 자격증’ 이 있습니다. 자격증이 있어야 된다는 것은 아닙니다. 하지만 QA에 대한 지식이 없다면 ISTQB 책을 한 번 정도는 읽어보면 업무를 이해하는 데 도움이 될 것입니다.&lt;/p&gt;

&lt;p&gt;두 번째로는 &lt;strong&gt;QA 프로세스를 알고 있어야 된다 생각합니다.&lt;/strong&gt; 여기서 말하는 프로세스는 단순히 ‘QA Plan을 작성하고 테스트 케이스를 만들어 테스트를 한다’가 아닌 프로젝트에 투입된 순간부터 QA가 각 단계별로 수행할 수 있는 업무와 만들어지는 산출물들의 구성을 파악하고 있는지를 말합니다. 회사별로 프로젝트 진행은 다르더라도 QA가 수행하는 기본 프로세스는 동일합니다. 해당 직무의 업무 순서와 정의를 알고 있다면 어떤 프로젝트에 참여하던지 흔들리지 않고 본인의 역할을 해낼 수 있다 생각합니다.&lt;/p&gt;

&lt;p&gt;마지막으로는 &lt;strong&gt;스스로 나아가려는 의지가 필요합니다.&lt;/strong&gt; 알아서 모든 일을 하라는 의미가 아니고 품질 개선을 위해 스스로 다양한 방법을 시도하고 업무를 찾아서 할 수 있어야 한다는 의미입니다. 글을 시작할 때 언급했던 바와 같이 QA 업무는 결코 단순하지 않습니다. 소프트웨어 개발 환경이 발전함에 따라 품질을 높이기 위한 방법들도 다양해지고 빠르게 변화하고 있습니다. 틀에 박힌 테스트 방식이 아닌 새로운 방법들을 스스로 해보고 발전시키려는 의지가 필요하다 생각합니다.&lt;/p&gt;

&lt;p&gt;위의 세 가지는 제가 면접관일 때나 지원자일 때 중요하게 생각하는 부분입니다. 그래서 면접을 보기 전에 QA 용어와 프로세스에 대해 다시 리마인드를 하고, 항상 배우려는 마인드 셋을 갖추려고 합니다. 저의 팁이라고 하기엔 거창한 거 같지만 이 팁이 QA 지원을 준비하거나 생각하시는 분들에게 작은 도움이라도 되길 바랍니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;6-끝으로&quot;&gt;6. 끝으로&lt;/h2&gt;

&lt;p&gt;처음 쏘카 블로그 글 제안을 받았을 때 걱정이 앞섰습니다. 글을 잘 쓰는 것도 아니고 누군가에게 설명하는 것도 잘하지 못해 글 순서를 정하는 것부터 쉽지 않았습니다. 글도 생각한 것처럼 써지지 않아 다시 읽을 때마다 수정하고 있고, 글의 마지막을 작성하는 지금도 다시 읽을 때마다 계속 지웠다 썼다를 반복하고 있습니다. 여전히 이 글이 어떻게 보일까 걱정은 되지만 최선을 다해 글을 썼고,  제가 쏘카에서 보낸 3개월을 돌아보며 QA로서 스스로도 다시 한번 돌아 볼 수 있는 뜻깊은 시간이었습니다. 쏘카 블로그 글 작성을 제안해 주신 팀장님 감사드리고 응원해 주신 팀원들도 감사합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/QA/qa_8.png&quot; alt=&quot;img&quot; width=&quot;30%&quot; /&gt;
&lt;em&gt;쏘카 10주년 기념으로 키카쿠브를 받았어요&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;-참고&quot;&gt;* 참고&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://brunch.co.kr/@210a51cb29764cb/2&quot;&gt;https://brunch.co.kr/@210a51cb29764cb/2&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://blog.illunex.com/202010105-2/&quot;&gt;http://blog.illunex.com/202010105-2/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://neklo.com/what-is-quality-assurance-testing/&quot;&gt;https://neklo.com/what-is-quality-assurance-testing/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://tech.devsisters.com/posts/not-enough-testcase/&quot;&gt;https://tech.devsisters.com/posts/not-enough-testcase/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://brunch.co.kr/@hsoochun/13&quot;&gt;https://brunch.co.kr/@hsoochun/13&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>camila</name></author><category term="QA" /><category term="qa" /><category term="onboarding" /><summary type="html">안녕하세요. 작년 11월에 쏘카 QA 팀에 경력직으로 입사한 카밀라입니다. 신입 때 QA 업무는 반복적인 업무를 하는 단순 직무라 생각했었습니다. 하지만 여러 프로젝트들을 진행하며 커버리지를 높이기 위한 활동들과 기본 기능을 지속적으로 검증하기 위한 자동화 테스트 구축 등 계속해서 배워야 할 것들이 많은 직무라는 것을 몸소 깨달았습니다.</summary></entry><entry><title type="html">데이터 디스커버리 플랫폼 도입기 - 2편. GKE에 Datahub 구축하기</title><link href="https://tech.socarcorp.kr/data/2022/03/16/metdata-platform-02.html" rel="alternate" type="text/html" title="데이터 디스커버리 플랫폼 도입기 - 2편. GKE에 Datahub 구축하기" /><published>2022-03-16T07:00:00+00:00</published><updated>2022-03-16T07:00:00+00:00</updated><id>https://tech.socarcorp.kr/data/2022/03/16/metdata-platform-02</id><content type="html" xml:base="https://tech.socarcorp.kr/data/2022/03/16/metdata-platform-02.html">&lt;p&gt;안녕하세요, 데이터 플랫폼 팀의 디니입니다.&lt;/p&gt;

&lt;p&gt;이번 글은 ‘쏘카의 데이터 디스커버리 플랫폼 도입기’ 3부작 중 2편입니다. &lt;a href=&quot;https://tech.socarcorp.kr/data/2022/02/25/data-discovery-platform-01.html&quot;&gt;1편 : 데이터 디스커버리 플랫폼 도입기 - 데이터 디스커버리란?&lt;/a&gt;에서는 데이터 디스커버리의 개념과 쏘카가 데이터 디스커버리 플랫폼으로 Datahub를 선택하게 된 의사결정 과정을 소개했습니다.&lt;/p&gt;

&lt;p&gt;2편에서는 Datahub를 GKE 환경에 배포한 과정과 데이터 디스커버리 플랫폼에 필요한 추가 기능들을 어떻게 구현하였는지에 대해 소개하려고 합니다. 다음과 같은 분들이 읽으시면 도움이 되리라고 생각합니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;메타데이터 플랫폼 도입에 관심이 있는 개발자&lt;/li&gt;
  &lt;li&gt;클라우드 환경에 메타데이터 플랫폼 배포하는 과정에 관심이 있는 사람&lt;/li&gt;
  &lt;li&gt;쏘카 데이터 플랫폼팀 업무에 관심이 있는 사람&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;목차는 다음과 같습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;#problem-definition&quot;&gt;문제 정의&lt;/a&gt;&lt;/p&gt;

    &lt;p&gt;1.1. 무엇을 해야 하나요?&lt;/p&gt;

    &lt;p&gt;1.2. 고려해야 할 부분&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;#datahub-on-gke&quot;&gt;Datahub on GKE 배포 과정&lt;/a&gt;&lt;/p&gt;

    &lt;p&gt;2.1. GKE 배포&lt;/p&gt;

    &lt;p&gt;2.2. CloudSQL DB migration&lt;/p&gt;

    &lt;p&gt;2.3. Keycloak 인증&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;#metadata-ingestion&quot;&gt;메타데이터 주입 과정&lt;/a&gt;&lt;/p&gt;

    &lt;p&gt;3.1. 메타데이터 주입 방법&lt;/p&gt;

    &lt;p&gt;3.2. 메타데이터 주입 정책 결정&lt;/p&gt;

    &lt;p&gt;3.3. 메타데이터 주입 과정 자동화 (with Airflow)&lt;/p&gt;

    &lt;p&gt;3.4. 메타데이터 추출 과정의 권한 축소&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;#wrap-up&quot;&gt;마무리&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;1-문제-정의&quot;&gt;1. 문제 정의&lt;a name=&quot;problem-definition&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&quot;11-무엇을-해야-하나요&quot;&gt;1.1. 무엇을 해야 하나요?&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Datahub를 사내 클라우드 환경에 안정적으로 배포합니다.&lt;/li&gt;
  &lt;li&gt;Datahub에 메타데이터 주입 파이프라인을 자동화합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;12-고려해야-할-부분&quot;&gt;1.2. 고려해야 할 부분&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;쏘카는 데이터 소스로 MySQL(운영)과 BigQuery(분석)를 사용하고 있습니다. 두 데이터 소스의 특성을 고려한 메타데이터 주입 파이프라인이 필요합니다.&lt;/li&gt;
  &lt;li&gt;플랫폼 상의 데이터가 유실 위험 없이 안전하게 저장되어야 합니다.&lt;/li&gt;
  &lt;li&gt;인증된 사용자만 플랫폼에 접속할 수 있어야 합니다.&lt;/li&gt;
  &lt;li&gt;CI/CD 파이프라인을 이용한 배포 자동화가 되어야 합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;2-datahub-on-gke-배포-과정-&quot;&gt;2. Datahub on GKE 배포 과정 &lt;a name=&quot;datahub-on-gke&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;먼저 Datahub를 어떻게 사내 클라우드 환경에 안정적으로 배포했는지 알아보겠습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Datahub는 오픈소스 기반으로 매우 빠르게 업데이트되고 있습니다. 해당 배포는 6개월 전에 이루어진 것으로, 현재 Datahub 배포 및 metadata ingestion 과정과는 다소 차이가 있을 수 있습니다. 이 점 양해 부탁드립니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;21-gke-배포&quot;&gt;2.1. GKE 배포&lt;/h3&gt;

&lt;p&gt;쏘카 데이터 엔지니어링 그룹의 쿠버네티스 환경은 GCP(Google Cloud Platform)의 GKE(Google Kuberentes Engine)를 사용하고 있습니다. 또한 대부분의 애플리케이션을 &lt;a href=&quot;https://helm.sh/&quot;&gt;Helm&lt;/a&gt; Chart를 이용하여 클러스터에 배포하고 있습니다. Datahub 역시 공식 &lt;a href=&quot;https://github.com/acryldata/datahub-helm&quot;&gt;Helm Chart&lt;/a&gt;를 제공하고 있으며, 총 2벌의 차트로 구성되어 있습니다. Datahub Helm Chart 구성은 다음과 같습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;datahub&lt;/code&gt; : Datahub 애플리케이션에 필요한 요소들 설치 (Frontend, GMS 등)&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;prerequisites&lt;/code&gt; : Datahub에 필요한 사전 요소들을 설치 (MySQL, Kafka, ElasticSearch, Neo4j 등)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-02/datahub-helm-chart-tree.png&quot; alt=&quot;datahub-helm-chart-tree&quot; /&gt; &lt;em&gt;Datahub 차트 구조&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;공식 Datahub Helm Chart의 Ingress를 쏘카의 환경에 맞게 수정한 뒤 배포하였습니다. 또한 원활한 테스트를 위해 개발 클러스터, 운영 클러스터에 각각 배포하였습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-02/datahub-pods.png&quot; alt=&quot;datahub-pods&quot; /&gt; &lt;em&gt;Datahub 최초 배포 시 Pod 상태&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;22-cloudsql-db-migration&quot;&gt;2.2. CloudSQL DB migration&lt;/h3&gt;

&lt;p&gt;Datahub는 자체 DB(storage)로 MySQL Pod을 사용합니다. 물론 PVC(PersistentVolumeClaim)이 붙어있긴 했지만, 앞으로 Datahub 애플리케이션 상에서 쌓일 데이터가 점점 늘어날 것이며 데이터의 내용 또한 중요하기 때문에, 앞으로의 확장성과 만에 하나라도 있을 유실 가능성을 방지하는 방향으로 아키텍처를 고민했습니다. 결국에는 MySQL Pod 대신 외부 데이터베이스로 GCP CloudSQL Instance를 연결하기로 결정했습니다.&lt;/p&gt;

&lt;p&gt;구체적으로는 다음 과정으로 진행했습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;CloudSQL DB (혹은 새로운 Instance) 생성&lt;/li&gt;
  &lt;li&gt;(Optional) 사용자 생성&lt;/li&gt;
  &lt;li&gt;Datahub가 CloudSQL 가리키게 하기&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;기존 Datahub의 Helm Chart는 SQL Host로 MySQL Pod을 가리키고 있습니다. 위에서 만든 CloudSQL DB를 가리키게 하기 위해서 Helm Chart를 다음과 같이 수정합니다.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# charts/datahub/values.yaml&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;datasource&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;host&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;lt;cloudsql_host_address&amp;gt;:&amp;lt;port&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;jdbc:mysql://&amp;lt;cloudsql_host_address&amp;gt;:&amp;lt;port&amp;gt;/&amp;lt;cloudsql_db_name&amp;gt;?verifyServerCertificate=false&amp;amp;useSSL=true&amp;amp;useUnicode=yes&amp;amp;characterEncoding=UTF-8&amp;amp;enabledTLSProtocols=TLSv1.2&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;hostForMysqlClient&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;lt;cloudsql_host_address&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;lt;port&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;driver&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;com.mysql.jdbc.Driver&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;username&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;lt;username&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;password&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;secretRef&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;lt;별도로 생성한 secret 이름&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;secretKey&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;lt;별도로 생성한 secret 키&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# charts/datahub/subcharts/datahub-gms/values.yaml&lt;/span&gt;

&lt;span class=&quot;na&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;datasource&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;host&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;lt;cloudsql_host_address&amp;gt;:&amp;lt;port&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;jdbc:mysql://&amp;lt;cloudsql_host_address&amp;gt;:&amp;lt;port&amp;gt;/datahub?verifyServerCertificate=false&amp;amp;useSSL=true&quot;&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;driver&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;com.mysql.jdbc.Driver&quot;&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;username&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;lt;username&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;password&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;secretRef&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;lt;별도로 생성한 secret 이름&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;secretKey&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;lt;별도로 생성한 secret 키&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;실제로는 민감한 정보들을 Helm Chart에 직접 명시하지 않고 다음처럼 별도의 Secret으로 생성하여 참조하였습니다.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;na&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;datasource&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;host&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;secretRef&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mysql-secrets&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;secretKey&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mysql-host&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;secretRef&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mysql-secrets&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;secretKey&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mysql-url&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;hostForMysqlClient&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;secretRef&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mysql-secrets&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;secretKey&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mysql-hostForMysqlClient&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;3306&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;driver&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;com.mysql.jdbc.Driver&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;username&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;secretRef&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mysql-secrets&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;secretKey&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mysql-username&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;password&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;secretRef&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mysql-secrets&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;secretKey&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mysql-password&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Secret yaml 파일은 다음과 같습니다.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;v1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Secret&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mysql-secrets&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;datahub&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Opaque&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;mysql-host&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;lt;data&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;mysql-hostForMysqlClient&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;lt;data&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;mysql-password&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;lt;data&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;mysql-root-password&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;lt;data&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;mysql-url&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;lt;data&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;mysql-username&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;lt;data&amp;gt;&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;최종적으로 정상 작동을 테스트합니다. 예를 들어, Datahub UI 상에서 데이터를 수정한 뒤 해당 CloudSQL DB에서 동일한 데이터가 업데이트되는지 확인합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-02/datahub-create-policy.png&quot; alt=&quot;create-test-policy&quot; /&gt;&lt;em&gt;test_policy라는 정책을 생성해 보았습니다.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-02/datahub-check-data.png&quot; alt=&quot;check-data&quot; /&gt;&lt;em&gt;CloudSQL DB에서 동일한 데이터가 확인됩니다.&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;23-keycloak-인증&quot;&gt;2.3. Keycloak 인증&lt;/h3&gt;

&lt;p&gt;Datahub이 배포되고 나면, 인증된 사용자만 애플리케이션에 접속되어야 합니다. Datahub는 Okta, Keycloak 등 여러 SSO를 지원합니다. 쏘카에서 이미 Keycloak을 이용하고 있기 때문에 Keycloak을 사용하기로 결정했습니다.&lt;/p&gt;

&lt;p&gt;Datahub에 Keycloak 로그인을 적용하는 방법은 간단했습니다. Helm Chart의 &lt;code class=&quot;highlighter-rouge&quot;&gt;values.yaml&lt;/code&gt;파일에서 frontend 부분에 몇 줄의 설정만 넣어주면 가능했습니다.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;datahub-frontend&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;...&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;extraEnvs&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;AUTH_OIDC_ENABLED&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;true&quot;&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;AUTH_OIDC_CLIENT_ID&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;your-client-id&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;AUTH_OIDC_CLIENT_SECRET&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;your-client-secret&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;AUTH_OIDC_DISCOVERY_URI&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;your-provider-discovery-url&lt;/span&gt;  
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;AUTH_OIDC_BASE_URL&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;your-datahub-url&lt;/span&gt;  
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;또한 다음과 같은 다양한 설정을 쉽게 정의할 수 있었습니다.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# User and groups provisioning&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# OIDC 로그인 시, Datahub 상에 유저 없으면 자동 생성 여부&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;AUTH_OIDC_JIT_PROVISIONING_ENABLED=true&lt;/span&gt; 

&lt;span class=&quot;c1&quot;&gt;# OIDC 로그인 시, Datahub 상에 유저가 이미 존재해야 로그인 성공하는지 여부&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;AUTH_OIDC_PRE_PROVISIONING_REQUIRED=false&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# OIDC의 그룹 정보를 Datahub에 연동&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;AUTH_OIDC_EXTRACT_GROUPS_ENABLED=true&lt;/span&gt; 
&lt;span class=&quot;s&quot;&gt;AUTH_OIDC_GROUPS_CLAIM=&amp;lt;your-groups-claim-name&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;3-메타데이터-주입-과정--&quot;&gt;3. 메타데이터 주입 과정  &lt;a name=&quot;metadata-ingestion&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;이렇게 Datahub를 클라우드 상에 안정적으로 구축했습니다. 하지만 아직 데이터 디스커버리 플랫폼으로서의 기능을 하지는 못합니다. 데이터 소스에서 실제로 메타데이터를 가져와서 플랫폼에서 보여줘야 하고, 이렇게 메타데이터를 가져오는 과정(=metadata ingestion)이 자동화되어야 합니다.&lt;/p&gt;

&lt;h3 id=&quot;31-메타데이터-주입-방법&quot;&gt;3.1. 메타데이터 주입 방법&lt;/h3&gt;

&lt;p&gt;Datahub에서는 &lt;code class=&quot;highlighter-rouge&quot;&gt;recipe&lt;/code&gt;라고 불리는 yaml 파일을 &lt;code class=&quot;highlighter-rouge&quot;&gt;datahub CLI&lt;/code&gt;로 실행하여 메타데이터를 주입합니다. 다음은 BigQuery에서 메타데이터를 가져오는 recipe 파일의 기본 예시입니다.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
 &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;bigquery&lt;/span&gt;
 &lt;span class=&quot;na&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
   &lt;span class=&quot;na&quot;&gt;project_id&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;lt;project_id&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;na&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
     &lt;span class=&quot;na&quot;&gt;credentials_path &lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;${GOOGLE_APPLICATION_CREDENTIALS}&lt;/span&gt;

&lt;span class=&quot;na&quot;&gt;sink&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
 &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;datahub-rest&quot;&lt;/span&gt;
 &lt;span class=&quot;na&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
   &lt;span class=&quot;na&quot;&gt;server&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;${DATAHUB_GMS_ADDRESS}&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# datahub 애플리케이션의 backend 서버&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;source&lt;/code&gt; : 데이터 소스, 즉 “데이터를 어디서 가져오는지” 정의합니다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sink&lt;/code&gt; : “데이터를 어디에 저장하는지” 를 정의합니다. Datahub 어플리케이션에 올릴 수도 있고, 콘솔에 출력할 수도 있고, 파일로 저장할 수도 있습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 형식을 바탕으로 데이터 소스를 바꿀 수도 있고 여러 설정을 적용할 수도 있습니다. 파일을 실행할 때는 &lt;code class=&quot;highlighter-rouge&quot;&gt;datahub ingestion -c &quot;&amp;lt;파일_이름&amp;gt;&quot;&lt;/code&gt;으로 실행합니다.&lt;/p&gt;

&lt;h3 id=&quot;32-메타데이터-주입-정책-결정&quot;&gt;3.2. 메타데이터 주입 정책 결정&lt;/h3&gt;

&lt;p&gt;먼저 “어떤 데이터 소스”에서 메타데이터를 “얼마나 자주” 가져올 건지 결정해야 합니다.&lt;/p&gt;

&lt;p&gt;쏘카에서는 주요 데이터 소스로 MySQL Aurora(운영)와 BigQuery(분석)를 사용하고 있습니다. 하지만 이 데이터 소스의 모든 테이블을 가져올 필요는 없었습니다. 예를 들면 DB에 따라서 개인 정보 관련 민감한 데이터들도 있고, 분석 DB 쪽에는 굳이 전사에 공유될 필요는 없는 임시 테이블들도 다수 존재했습니다. 따라서 각 데이터 소스 별 DB의 목록을 사전에 정하고, 해당 DB의 메타데이터를 주입하기로 했습니다.&lt;/p&gt;

&lt;p&gt;참고로, 다음과 같이 Table 혹은 DB의 이름을 &lt;code class=&quot;highlighter-rouge&quot;&gt;regex pattern&lt;/code&gt;으로 감지하여 선택적 메타데이터 주입이 가능합니다. (물론 데이터 소스마다 방법이 약간 다를 수 있습니다 - 예시는 BigQuery입니다.)&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;bigquery&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;schema_pattern&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;allow&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 허용하는 dataset 패턴&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;my_dataset&quot;&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;table_pattern&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;allow&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 허용하는 table 패턴&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;^my_project.my_dataset.my_good_table&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;$&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;deny&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 허용하지 않는 table 패턴&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;^my_project.my_dataset.my_bad_table&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;$&quot;&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;include_views&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;false&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;그러면 얼마나 자주 가져와야 할까요? 매일매일 필요에 따라 테이블이 생겨났다가 사라지기도 하고, 테이블의 칼럼이 추가되거나 변경되는 일도 있을 것입니다. 하지만 이런 변화들을 꼭 실시간으로 봐야 할 필요는 없다고 생각했습니다. 하루에 한 번 정도 업데이트한다면, 리소스도 효율화하고 사내 데이터 현황을 파악하는 데 충분하다고 결정을 내렸습니다.&lt;/p&gt;

&lt;h3 id=&quot;33-메타데이터-주입-과정-자동화-with-airflow&quot;&gt;3.3. 메타데이터 주입 과정 자동화 (with Airflow)&lt;/h3&gt;

&lt;p&gt;이렇게 하루에 한 번 메타데이터 주입을 결정하고 난 뒤, 메타데이터 주입을 어떻게 자동화했는지 알아보겠습니다.&lt;/p&gt;

&lt;p&gt;하루에 한 번 Batch 단위의 주입이라면 &lt;code class=&quot;highlighter-rouge&quot;&gt;Airflow DAG&lt;/code&gt;로 간단하게 구현할 수 있었습니다. 데이터 소스에서 메타데이터를 주입하는 Task를 만들고, 하루 한 번만 돌려주면 됐습니다. 그런데 이 작업에는 &lt;code class=&quot;highlighter-rouge&quot;&gt;datahub&lt;/code&gt; 패키지를 설치해야 하는 의존성이 필요합니다.&lt;/p&gt;

&lt;p&gt;데이터 플랫폼 팀에서는 이런 경우 Airflow에 직접 의존성을 설치하지 않고, 필요한 의존성을 담은 Docker Image를 실행하는 &lt;code class=&quot;highlighter-rouge&quot;&gt;KubernetesPodOperator&lt;/code&gt;를 만들어 해결하고 있습니다. 이렇게 하면 DAG 가 아무리 많아도 DAG 간 사용하는 라이브러리나 환경의 의존성 충돌을 방지할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-02/metadata-ingestion-flow.png&quot; alt=&quot;metadata-ingestion-flow&quot; /&gt; &lt;em&gt;메타데이터 주입 흐름&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;작성한 Dockerfile은 다음처럼 간단합니다.&lt;/p&gt;

&lt;div class=&quot;language-dockerfile highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# datahub-ingestion 이미지를 이용합니다. &lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; linkedin/datahub-ingestion:v0.8.20 &lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# 미리 정의한 recipe 파일을 복사해 가져옵니다. &lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; datahub-ingestion-bigquery /datahub-ingestion-bigquery &lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# datahub CLI를 이용하여 recipe를 실행합니다. &lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CMD&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; [&quot;ingest&quot;, &quot;-c&quot;, &quot;/datahub-ingestion-bigquery/recipe_bigquery.yaml&quot;] &lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;datahub-ingestion-bigquery 안에는 recipe 파일이 들어 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-02/datahub-ingestion-bigquery.png&quot; alt=&quot;datahub-ingestion-bigquery&quot; /&gt; &lt;em&gt;datahub-ingestion-bigquery 디렉터리 구조&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;34-메타데이터-추출-과정의-권한-축소&quot;&gt;3.4. 메타데이터 추출 과정의 권한 축소&lt;/h3&gt;

&lt;h4 id=&quot;어떻게-하면-최소한의-권한으로-메타데이터를-추출할-수-있을까&quot;&gt;어떻게 하면 최소한의 권한으로 메타데이터를 추출할 수 있을까?&lt;/h4&gt;

&lt;p&gt;Datahub는 메타데이터를 끌어오는 모든 대상 DB에 SELECT 권한을 허용해야 메타데이터 추출이 가능하도록 만들어져 있습니다. 예를 들면 MySQL DB에 3000개의 DB가 있다고 가정할 때, Datahub의 서비스 계정은 3000개의 DB에 대해 모두 권한이 있어야 하는 것입니다.&lt;/p&gt;

&lt;p&gt;하지만 이 권한을 단독 솔루션에 부여하기에는 보안상 너무 무겁다고 판단했습니다. 그래서 어떻게 하면 최소한의 DB에 접근하면서 같은 기능을 구현할 수 있을지가 큰 고민거리였습니다.&lt;/p&gt;

&lt;h4 id=&quot;information-schema에서-직접-뽑아내-보자&quot;&gt;Information Schema에서 직접 뽑아내 보자&lt;/h4&gt;

&lt;p&gt;당시 데이터 엔지니어링 팀 팀장(이시고 지금은 그룹장이신) 토마스가 아이디어를 주셨습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-02/file-based-ingestion-flow.png&quot; alt=&quot;file-based-ingestion-flow&quot; /&gt; &lt;em&gt;file을 이용하여 메타데이터 상태를 저장하는 흐름&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Datahub에는 데이터 소스의 메타데이터를 특정 형태의 &lt;code class=&quot;highlighter-rouge&quot;&gt;json file&lt;/code&gt;로 변환하여 저장하는 기능이 있습니다. 또한 같은 형식의 json file을 기반으로 메타데이터를 Datahub 플랫폼에 주입하는 것도 가능했습니다. 그리고 해당 파일 형식을 확인해 본 결과 &lt;code class=&quot;highlighter-rouge&quot;&gt;information_schema&lt;/code&gt;에서 대부분(사실 모두) 가져올 수 있는 정보였습니다.&lt;/p&gt;

&lt;p&gt;그러면 &lt;code class=&quot;highlighter-rouge&quot;&gt;information_schema&lt;/code&gt;에서 정보를 가져와서 file 형식을 맞춰 만들어주는 기능을 개발하고, 그 file을 기반으로 Datahub에 메타데이터를 주입하면 되지 않을까? 하는 생각이 들었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-02/metadata-ingestion-as-is.png&quot; alt=&quot;metadata-ingestion-as-is&quot; /&gt;&lt;em&gt;metadata ingestion AS-IS 흐름&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-02/metadata-ingestion-to-be.png&quot; alt=&quot;metadata-ingestion-to-be&quot; /&gt;&lt;em&gt;metadata ingestion TO-BE 흐름&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;그래서 앞부분은 python script로 개발하고, file을 기반으로 메타데이터를 주입하는 부분은 기존 Datahub 프레임워크를 그대로 이용했습니다.&lt;/p&gt;

&lt;div class=&quot;language-dockerfile highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# 파이썬 이미지를 이용합니다. &lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; python:3.8 &lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; datahub-ingestion-mysql /datahub-ingestion-mysql &lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;WORKDIR&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; /datahub-ingestion-mysql/src&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;USER&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; root&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# datahub를 포함한 필요한 의존성을 설치합니다. &lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;RUN &lt;/span&gt;pip &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--no-cache-dir&lt;/span&gt; mysql-connector-python&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;8.0.27 &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; pip &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--no-cache-dir&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--upgrade&lt;/span&gt; acryl-datahub&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;0.8.20 

&lt;span class=&quot;c&quot;&gt;# information_schema에서 메타데이터를 추출하는 python script를 실행하고, datahub CLI로 Datahub 플랫폼에 주입합니다.&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CMD&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; python main.py ; datahub ingest -c recipe_mysql_prod.yaml &lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;main.py&lt;/code&gt;의 내용은 다음과 같습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# main.py
&lt;/span&gt;	
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;json&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;os&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;get_info_from_query&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_json_result&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;make_and_execute_query&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;execute_query&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;mysql.connector&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;connection&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;errorcode&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;templates&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;json_table_template&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;user&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;environ&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;USER&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;password&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;environ&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;PASSWORD&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;host&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;environ&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;HOST&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;pattern_conditions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;schema_pattern_allowed&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;json&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;environ&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;PATTERN&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;schema_pattern_denied&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;table_pattern_allowed&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;table_pattern_denied&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_metadata_from_info_schema&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;user&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;password&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;host&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pattern_conditions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;cnx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;connection&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MySQLConnection&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;user&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;user&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;password&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;password&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;host&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;host&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;database&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;information_schema&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;3306&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;cursor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cnx&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cursor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;table_and_column_result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;constraint_result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;execute_query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;cursor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cursor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pattern_conditions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pattern_conditions&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;json_result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_json_result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;table_and_column_result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;constraint_result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;json_table_template&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;json_table_template&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;metadata.json&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;w+&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;json_result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;cursor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;cnx&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;except&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Error&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;err&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;err&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errno&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;errorcode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ER_ACCESS_DENIED_ERROR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;err&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Something is wrong with your user name or password&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;err&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errno&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;errorcode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ER_BAD_DB_ERROR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Database does not exist&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;err&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__name__&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;__main__&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;get_metadata_from_info_schema&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;user&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;password&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;host&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pattern_conditions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;information_schema에서는 Table 정보, Column 정보, Constraint (Primary Key 등) 정보 등 여러 가지 정보를 추출합니다. 예를 들어 Column 정보는 다음과 같은 쿼리로 추출합니다. 이렇게 실행한 쿼리 결과를 Datahub에서 이용하는 json 형식에 맞게 바꿔줍니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# python script 중 information_schema에서 column info를 뽑아내는 부분
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_column_info_query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pattern_clause&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;column_info_query&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
        SELECT Concat(table_schema, '.', table_name) AS schemaName,
               column_name,
               column_comment,
               data_type,
               column_type,
               is_nullable,
               column_key
        FROM   information_schema.columns 
        {pattern_clause}
        ORDER BY schemaname,
                 ordinal_position; 
        &quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;column_info_query&lt;/span&gt;
 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;최종-테스트&quot;&gt;최종 테스트&lt;/h4&gt;

&lt;p&gt;이렇게 기능을 구현한 뒤 프로젝트에 같이 참여하시고 계시는 DBA 제이든과 직접 테스트를 해보았습니다. 마지막으로 MySQL 계정 권한에 변경이 필요했습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;AS-IS : 모든 DB에 대해 SELECT 권한&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;TO-BE : 모든 DB에 대해 REFERENCE 권한&lt;/p&gt;

    &lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;USER&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&amp;lt;username&amp;gt;'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'XX.XX.%'&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IDENTIFIED&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&amp;lt;password&amp;gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GRANT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;References&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&amp;lt;username&amp;gt;'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'XX.XX.%'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;결과적으로 원하는 DB의 모든 메타데이터를 가져와서 Datahub에 주입하는 데에 성공했습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-02/datahub-test-success.png&quot; alt=&quot;datahub-test-success&quot; /&gt; &lt;em&gt;기능 구현 내용&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-02/datahub-test-success-3.png&quot; alt=&quot;datahub-test-success&quot; /&gt; &lt;em&gt;축소된 권한으로 모든 정보를 가져올 수 있습니다.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;이 기능 개발로 쏘카의 DB에 접근하는 Datahub 계정의 권한이 크게 축소되어 내부 정보보호 규칙에 맞게 보안을 개선할 수 있습니다. 그리고 Datahub 최종 도입 결정에 긍정적인 영향을 미쳤습니다.&lt;/p&gt;

&lt;h2 id=&quot;4-마무리--&quot;&gt;4. 마무리  &lt;a name=&quot;wrap-up&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;이러한 여러 과정 끝에, Datahub가 쏘카에 도입될 준비를 마쳤습니다. 현재는 이렇게 테스트 배포를 마치고 사내 공개를 위한 준비 작업을 하고 있습니다. 이 자리를 빌려 Datahub 도입에 힘써주신 모든 분들에게 감사드립니다.&lt;/p&gt;

&lt;p&gt;입사하고 맡은 첫 프로젝트였는데 쏘카 데이터 플랫폼팀의 전반적인 인프라와 배포 흐름에 대해 알 수 있는 좋은 기회였습니다. 여담으로, 구현하면서 슬랙에서 질답을 너무 많이 한 나머지 커뮤니티 기여자로 Datahub 팀과 원격 인터뷰를 하는 기회도 얻었습니다 (!)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-02/datahub-swag-all.jpeg&quot; alt=&quot;datahub-swag-all&quot; /&gt; &lt;em&gt;인터뷰 기념품으로 준 Datahub 기념품 세트&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-02/datahub-swag-thanks.jpeg&quot; alt=&quot;datahub-swag-thanks&quot; /&gt;&lt;em&gt;기념품과 함께 온 감사 메시지&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;마지막으로 Datahub를 도입하려는 분들에게 팁을 드리자면 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;데이터 소스 특성에 따라서 메타데이터 파이프라인 구현 방법 정하기&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;데이터 소스와 업데이트 주기를 결정한 뒤 구현 방법을 결정하기를 추천합니다.&lt;/li&gt;
  &lt;li&gt;하루 한 번 정도의 Batch 작업이라면 &lt;code class=&quot;highlighter-rouge&quot;&gt;Airflow DAG&lt;/code&gt; 로도 충분합니다.&lt;/li&gt;
  &lt;li&gt;최근에는 Datahub UI 상에서 Ingestion을 설정할 수 있는 기능도 나왔습니다. 장단점을 비교해 보고 결정하시면 좋을 것 같습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;DB 특성에 따라서 메타데이터 추출 로직 조정하기&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;권한에 민감한 DB라면 information_schema에서 바로 메타데이터를 뽑는 로직을 구현하는 방법이 있습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Datahub 공식 Slack Workspace에 참여하기&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Ingestion, Deployment 등 다양한 주제별로 질답을 나눌 수 있는 채널이 있습니다.&lt;/li&gt;
  &lt;li&gt;거의 모든 질문에 빠르게 답이 달릴 정도로 커뮤니티가 활성화되어 있습니다. 적극적으로 참여하시면서 도움을 얻기를 추천드립니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;다음 편에서는 실제로 데이터 디스커버리 플랫폼이 도입된 후의 운영 방식과 효과에 대해서 살펴보겠습니다.&lt;/p&gt;

&lt;p&gt;긴 글 읽어주셔서 감사합니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;데이터 플랫폼팀이 하는 업무가 궁금하시다면 &lt;a href=&quot;https://tech.socarcorp.kr/data/2021/03/24/what-socar-data-engineering-team-does.html&quot;&gt;데이터 엔지니어링 팀이 하는 일&lt;/a&gt;과 &lt;a href=&quot;https://www.notion.so/socarcorp/d458b6b77a2243fb873d1ac800c321f7?p=7c55b58735794368876dfb58acae96c5&quot;&gt;쏘카 데이터 플랫폼 엔지니어 채용공고&lt;/a&gt;를, 데이터 플랫폼 팀의 신입 온보딩 과정이 궁금하시다면 &lt;a href=&quot;https://tech.socarcorp.kr/data/2021/12/28/data-engineering-team-onboarding.html&quot;&gt;쏘카 신입 데이터 엔지니어 디니의 4개월 회고&lt;/a&gt;를 보시기를 추천드립니다.&lt;/p&gt;
&lt;/blockquote&gt;</content><author><name>dini</name></author><category term="data" /><category term="data" /><category term="metadata-platform" /><category term="data-engineering" /><summary type="html">안녕하세요, 데이터 플랫폼 팀의 디니입니다.</summary></entry><entry><title type="html">데이터 디스커버리 플랫폼 도입기 - 1편. 데이터 디스커버리란?(feat. Datahub VS Amundsen 비교 분석)</title><link href="https://tech.socarcorp.kr/data/2022/02/25/data-discovery-platform-01.html" rel="alternate" type="text/html" title="데이터 디스커버리 플랫폼 도입기 - 1편. 데이터 디스커버리란?(feat. Datahub VS Amundsen 비교 분석)" /><published>2022-02-25T02:00:00+00:00</published><updated>2022-02-25T02:00:00+00:00</updated><id>https://tech.socarcorp.kr/data/2022/02/25/data-discovery-platform-01</id><content type="html" xml:base="https://tech.socarcorp.kr/data/2022/02/25/data-discovery-platform-01.html">&lt;p&gt;안녕하세요. 데이터 플랫폼 팀의 디니입니다.&lt;/p&gt;

&lt;p&gt;여러분 혹시 도서관에서 가서 책을 찾아보신 경험이 있으신가요? 방대한 도서관에서 원하는 책을 찾으려면 책의 제목, 저자, 분류 기호 같은 정보가 매우 중요합니다. 이런 정보가 없다면 책을 찾기가 많이 힘들어질 겁니다.&lt;/p&gt;

&lt;p&gt;데이터 분석, 머신러닝을 위해 회사의 데이터베이스에서 원하는 데이터를 찾으려고 할때도 비슷한 일이 발생합니다. 어느 데이터가 어디에 있는지, 이 데이터는 무슨 의미인지에 대한 안내가 없으면 데이터를 이용하기가 불편할 것입니다. 이런 문제를 해결하기 위해 데이터의 위치와 의미를 한눈에 보게 돕는 플랫폼이 &lt;strong&gt;“데이터 디스커버리 플랫폼”(DDP, Data Discovery Platform)&lt;/strong&gt;입니다.&lt;/p&gt;

&lt;p&gt;앞으로 3부에 걸쳐 쏘카의 데이터 디스커버리 플랫폼 도입기를 소개하려고 합니다. 그중 1부인 이 글에서는 데이터 디스커버리의 개념과 데이터 디스커버리 플랫폼은 왜 필요한지, 쏘카는 어떤 기준으로 데이터 디스커버리 플랫폼을 선택했는지를 담으려고 합니다. 다음과 같은 분들이 읽으시면 도움이 되리라고 생각합니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;사내 데이터 디스커버리 플랫폼 도입에 관심이 있는 분&lt;/li&gt;
  &lt;li&gt;Datahub, Amundsen 등의 데이터 디스커버리 플랫폼을 PoC 하고 있는 개발자&lt;/li&gt;
  &lt;li&gt;쏘카가 데이터 디스커버리 및 메타데이터 관리를 어떻게 하고 있는지 궁금하신 분&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;목차는 이렇습니다. 각 제목을 클릭하시면 해당 부분으로 이동합니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;#what-is-metadata&quot;&gt;데이터 디스커버리란 무엇인가요?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#why-we-need-metadata-platform&quot;&gt;데이터 디스커버리 플랫폼이 왜 필요한가요?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#metadata-platform-comparison&quot;&gt;데이터 디스커버리 플랫폼 비교 분석 : Datahub VS Amundsen&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#final-decision&quot;&gt;최종 결정 : Datahub 결정 이유&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#wrap-up&quot;&gt;마무리 &amp;amp; 다음 편 예고&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;1-데이터-디스커버리란-무엇인가요--&quot;&gt;1. 데이터 디스커버리란 무엇인가요?  &lt;a name=&quot;what-is-metadata&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&quot;데이터-디스커버리의-정의&quot;&gt;데이터 디스커버리의 정의&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;데이터 디스커버리(Data Discovery)&lt;/strong&gt;란, “원하는 데이터를 쉽고 빠르게 찾을 수 있다” 의 개념입니다. 빅데이터 시대라는 흐름에 맞게, 회사에도 많은 양의 데이터가 여러 형태로 존재하게 되었습니다. 그리고 많은 사람이 데이터를 생산 및 소비하고 시간이 지나게 되면서 히스토리 파악도 점점 복잡해지기 시작합니다. 이런 상황에서 데이터 디스커버리는 데이터 이용자에게 &lt;strong&gt;“어떤 데이터”가 “어디에” “어떻게 존재”하는지에 대한 정보를 편리하게 제공&lt;/strong&gt;합니다.&lt;/p&gt;

&lt;p&gt;이런 데이터 디스커버리에는 &lt;strong&gt;“메타데이터”&lt;/strong&gt;라는 개념이 중요합니다. 메타데이터는 간단히 말해서 테이블 정보, 컬럼 정보, 코멘트, 테이블을 만든 사람(오너), 테이블 사이의 관계(데이터 리니지) 등을 말합니다. 이러한 메타데이터를 잘 관리하는 것이 데이터 디스커버리의 핵심 역할입니다.&lt;/p&gt;

&lt;h3 id=&quot;데이터-디스커버리의-중요성&quot;&gt;데이터 디스커버리의 중요성&lt;/h3&gt;

&lt;p&gt;데이터를 적극적으로 활용하는 기업은 데이터 디스커버리의 존재에 따라 업무 효율성이 크게 달라집니다. 사내에 많은 직원들이 데이터를 활용해 데이터 분석, 머신러닝, 데이터 기반 기획 등을 하고 있습니다. 각자의 목적에 맞는 데이터가 “어디에 있는지”, “이 데이터가 어떤 의미인지”를 파악하는 데에 대부분의 시간을 소요하게 된다면, 업무 효율성이 매우 떨어지게 될 겁니다.&lt;br /&gt;
데이터 디스커버리를 도입하여 잘 관리한다면 이런 비효율성을 피할 수 있습니다.&lt;/p&gt;

&lt;h3 id=&quot;데이터-디스커버리-플랫폼의-정의&quot;&gt;데이터 디스커버리 플랫폼의 정의&lt;/h3&gt;

&lt;p&gt;데이터 디스커버리를 가능하게 하는 플랫폼입니다. 웹 UI 환경을 제공하며, 데이터의 구조와 관계 등 메타데이터를 한 곳에서 쉽게 보고 검색할 수 있습니다(같은 이유로 데이터 디스커버리는 메타데이터 플랫폼이라는 용어로 쓰이기도 합니다) 대표적인 데이터 디스커버리 프레임워크는 다음과 같습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/linkedin/datahub&quot;&gt;Datahub&lt;/a&gt; : LinkedIn에서 만든 플랫폼입니다.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/amundsen-io/amundsen&quot;&gt;Amundsen&lt;/a&gt; : Lyft에서 만든 플랫폼입니다.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://eng.uber.com/databook/&quot;&gt;Databook&lt;/a&gt; : Uber에서 만든 인하우스 플랫폼 입니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;2-데이터-디스커버리-플랫폼이-왜-필요한가요--&quot;&gt;2. 데이터 디스커버리 플랫폼이 왜 필요한가요?  &lt;a name=&quot;why-we-need-metadata-platform&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&quot;도입-효과---data-discovery의-관점&quot;&gt;도입 효과 - Data Discovery의 관점&lt;/h3&gt;

&lt;p&gt;쏘카에서는 데이터 분석가, PM, 마케터 등 여러 직군이 업무에 데이터를 활용합니다. 하지만 데이터가 다양한 형식으로 존재하고 비개발 직군 입장에서는 DB에 직접 접근하는 것도 어려움이 있습니다. 기존에 스키마에 대한 정보를 알려주는 어드민이 있었지만, 유지보수가 되고 있지 않았습니다. 이런 이유로 “어떤 데이터를 어디서 찾아야 하는지” 혹은 “이 테이블의 데이터가 어떤 의미인지” 에 대한 질문을 기존에는 슬랙 채널을 이용해 받곤 했습니다. 이런 방식은 히스토리 파악도 쉽지 않고, 답변하는 사람의 시간을 많이 사용하게 됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-01/data-ask-brown.png&quot; alt=&quot;data-ask-brown&quot; /&gt;&lt;em&gt;데이터의 의미를 찾아 헤매는 브라운&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-01/data-ask-jung.png&quot; alt=&quot;data-ask-jung&quot; /&gt;&lt;em&gt;데이터의 의미를 찾아 헤매는 정&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;데이터 디스커버리 플랫폼을 도입하면 개발에 대한 도메인이 없더라도 간편한 UI를 통해서 메타데이터를 확인할 수 있습니다.&lt;/p&gt;

&lt;h3 id=&quot;도입-효과---data-governance의-관점&quot;&gt;도입 효과 - Data Governance의 관점&lt;/h3&gt;

&lt;p&gt;데이터 거버넌스란 데이터를 효과적으로 관리하기 위한 일련의 보안, 품질, 규정 등과 관련된 체계를 말합니다. 여러 사람이 데이터를 생산하고 소비할 수록 데이터 거버넌스의 관점은 중요해집니다. 데이터 디스커버리 플랫폼을 도입하면 기존에 흩어져서 관리되던 테이블 스키마, 코멘트가 중앙 관리될 수 있습니다.&lt;/p&gt;

&lt;p&gt;이러한 여러 이유들 때문에 쏘카는 데이터 디스커버리 플랫폼을 도입하기로 결정했습니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;3-데이터-디스커버리-플랫폼-비교-분석--datahub-vs-amundsen-&quot;&gt;3. 데이터 디스커버리 플랫폼 비교 분석 : Datahub vs Amundsen &lt;a name=&quot;metadata-platform-comparison&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&quot;poc-과정-소개&quot;&gt;PoC 과정 소개&lt;/h3&gt;

&lt;p&gt;디스커버리 플랫폼을 선정하기 전, 공식 문서 등의 지원이 풍부하고 일반적으로 많이 쓰이는 Datahub와 Amundsen을 직접 배포하고 테스트하며 비교하는 PoC 과정을 거쳐보기로 했습니다.&lt;/p&gt;

&lt;p&gt;사용성, UI, 문서화, 권한, 인증 등 다양한 측면에서 비교해 보았는데, 이 글에서는 그중 중요한 콘셉트를 간추려서 소개해 보겠습니다.&lt;/p&gt;

&lt;h3 id=&quot;datahub-vs-amundsen-비교-분석&quot;&gt;Datahub VS Amundsen 비교 분석&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-01/datahub-vs-amundsen.png&quot; alt=&quot;datathub-vs-amundsen&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;1-구조&quot;&gt;1) 구조&lt;/h4&gt;

&lt;p&gt;두 플랫폼의 구조에는 다음과 같은 공통점이 있습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;React 기반 Frontend&lt;/li&gt;
  &lt;li&gt;Elasticsearch 기반 Search Engine&lt;/li&gt;
  &lt;li&gt;Neo4j 기반 Graph DB&lt;/li&gt;
  &lt;li&gt;MySql 기반 Storage&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;차이점은 Datahub는 데이터를 주입할때 Kafka를 사용하고 Amundsen은 ETL 라이브러리를 통한 크롤링 방식을 사용하는 점입니다. 메타데이터 플랫폼 프레임워크의 히스토리를 살펴봤을 때, Amundsen 은 Monolith 방식인 반면 Datahub는 Event-based 방식입니다. 메타데이터 플랫폼의 히스토리에 대해서 좀더 궁금하신 분들은, LinkedIn의 엔지니어링 블로그에 작성된 &lt;a href=&quot;https://engineering.linkedin.com/blog/2020/datahub-popular-metadata-architectures-explained&quot;&gt;DataHub: Popular metadata architectures explained&lt;/a&gt; 글을 보시는 것을 추천합니다.&lt;/p&gt;

&lt;h4 id=&quot;2-메타데이터-주입-방식&quot;&gt;2) 메타데이터 주입 방식&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Datahub는 &lt;code class=&quot;highlighter-rouge&quot;&gt;yaml&lt;/code&gt; 파일을 실행하여 메타데이터를 주입합니다.
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;datahub CLI&lt;/code&gt;를 이용하여 yaml 파일을 실행합니다.&lt;/li&gt;
      &lt;li&gt;연결하는 데이터 소스에 따라 Datahub 라이브러리에 따라오는 연결 플러그인 설치가 필요합니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Amundsen은 &lt;code class=&quot;highlighter-rouge&quot;&gt;python&lt;/code&gt; 파일을 실행하여 메타데이터를 주입합니다.
    &lt;ul&gt;
      &lt;li&gt;기본적으로 &lt;code class=&quot;highlighter-rouge&quot;&gt;amundsen databuilder&lt;/code&gt; 라는 Python 라이브러리 (ETL framework) 를 사용하며, Extract, Transform, Load 각 과정에 여러 자체 모듈을 끌어와서 사용하는 방식입니다.&lt;/li&gt;
      &lt;li&gt;이 외에도 종종 여러 디펜던시(Dependancy)가 필요했습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;&lt;img src=&quot;/img/data-discovery-platform-01/datahub-ingestion-script.png&quot; alt=&quot;datahub-ingestion-script&quot; /&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;&lt;img src=&quot;/img/data-discovery-platform-01/amundsen-ingestion-script.png&quot; alt=&quot;amundsen-ingestion-script&quot; /&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;em&gt;Datahub -  BigQuery 데이터 주입 script&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;em&gt;Amundsen - BigQuery 데이터 주입 script&lt;/em&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;흥미로운 점은 같은 기능을 수행할 때 Datahub와 Amundsen의 &lt;strong&gt;script 길이 차이&lt;/strong&gt;였습니다. Datahub는 10줄 내외의 직관적인 yaml 코드로 가능한 반면, Amundsen의 script는 기본적으로 50 줄 이상이었습니다. 개인적으로 스크립트가 긴 만큼 섬세한 커스텀이 가능하거나 필요하다는 생각은 들지 않았고 오히려 읽기 무겁다는 생각이 들었습니다(공식 깃헙에 있는 샘플이 400줄이었습니다)&lt;/p&gt;

&lt;p&gt;각 ingestion 소스코드는 &lt;a href=&quot;https://github.com/linkedin/datahub/blob/master/metadata-ingestion/examples/recipes/bigquery_to_datahub.yml&quot;&gt;Datahub 공식 Github Repository&lt;/a&gt; 와 &lt;a href=&quot;https://github.com/amundsen-io/amundsen/blob/main/databuilder/example/scripts/sample_bigquery_metadata.py&quot;&gt;Amundsen 공식 Repository&lt;/a&gt; 에서 좀더 자세히 확인할 수 있습니다.&lt;/p&gt;

&lt;h4 id=&quot;3-ui&quot;&gt;3) UI&lt;/h4&gt;

&lt;p&gt;개인 차가 있을 수 있으나, 팀원들의 의견으로는 &lt;strong&gt;Datahub가 훨씬 깔끔하고 보기 편하다&lt;/strong&gt;는 의견이 많았습니다. Datahub UI는 &lt;a href=&quot;https://demo.datahubproject.io/&quot;&gt;공식 데모 사이트&lt;/a&gt;에서 더 확인하실 수 있습니다. (Amundsen은 따로 데모 사이트를 제공하지 않습니다)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-01/datahub-main.png&quot; alt=&quot;datahub-main&quot; /&gt;&lt;em&gt;Datahub - 메인 UI&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-01/datahub-dataset.png&quot; alt=&quot;datahub-dataset&quot; /&gt; &lt;em&gt;Datahub - 상세 UI&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-01/amundsen-main.png&quot; alt=&quot;amundsen-main&quot; /&gt;&lt;em&gt;Amundsen - 메인 UI&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-01/amundsen-main.png&quot; alt=&quot;amundsen-main&quot; /&gt;&lt;em&gt;Amundsen - 상세 UI&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&quot;4-문서-기능&quot;&gt;4) 문서 기능&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Datahub
    &lt;ul&gt;
      &lt;li&gt;테이블 별 / 컬럼 별 태그 부여가 가능합니다.&lt;/li&gt;
      &lt;li&gt;테이블 별 / 컬럼 별 풍부한 마크다운 문서 작성이 가능하고, 원본 소스의 Description을 보존합니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Amundsen
    &lt;ul&gt;
      &lt;li&gt;테이블 별 태그 부여가 가능합니다.&lt;/li&gt;
      &lt;li&gt;역시 테이블 별 / 컬럼 별 마크다운 제한적인 문서 작성이 가능하고, 원본 소스의 Description을 보존하지 않습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;중요한 점은 플랫폼 UI 상에서 테이블 혹은 컬럼의 설명을 수정했을 때 &lt;strong&gt;원본 소스의 Description을 따로 확인할 수 있는지&lt;/strong&gt;의 여부였습니다. Datahub는 다음과 같은 방식으로 Original Description을 동시에 보여주지만, Amundsen은 이런 기능이 없습니다. 또한 Datahub는 원본 Description과 UI 상 Description이 별개로 버전 관리가 되고 있어서, 한쪽의 수정이 다른 쪽에 영향을 끼치지 않았습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-01/datahub-description.png&quot; alt=&quot;datahub-dataset&quot; /&gt;&lt;em&gt;Datahub - UI 상에서 수정하더라도 “Original”(원본 코멘트)이 함께 표기됩니다.&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&quot;5-오너십&quot;&gt;5) 오너십&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Datahub는 테이블에 유저 / 그룹 단위로 오너십을 지정할 수 있습니다.&lt;/li&gt;
  &lt;li&gt;Amundsen은 테이블에 유저 단위로만 오너십을 지정할 수 있습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;6-데이터-계보data-lineage&quot;&gt;6) 데이터 계보(Data Lineage)&lt;/h4&gt;

&lt;p&gt;데이터 계보(Data Lineage)란 데이터의 흐름을 시각화한 개념으로 특정 테이블이 어떤 테이블들을 참조하는지, 데이터가 어디에서 와서 어디로 흘러가는지를 편리하게 알 수 있습니다.&lt;/p&gt;

&lt;p&gt;Datahub와 Amundsen 모두 dbt* 등을 연동하여 데이터 계보를 시각화 할 수 있습니다. (최근에는 Datahub에 dbt 없이 BigQuery 자체에서도 데이터 계보를 가져오는 기능이 추가되었습니다)&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;*&lt;a href=&quot;https://github.com/dbt-labs/dbt-core&quot;&gt;dbt&lt;/a&gt; : 데이터 ETL 과정에서 T(Transform) 과정을 효율화하는 도구입니다. dbt 를 이용하면 SQL 쿼리 모듈화, 테스트, 계보 확인을 편하게 할 수 있습니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-01/datahub-lineage.png&quot; alt=&quot;datahub-lineage&quot; /&gt;&lt;em&gt;Datahub - 데이터 계보&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-01/amundsen-lineage.png&quot; alt=&quot;amundsen-lineage&quot; /&gt;&lt;em&gt;Amudsen - 데이터 계보 (출처 : https://medium.com/alvin-ai/data-lineage-in-amundsen-powered-by-alvin-df50cd40944c)&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&quot;7-인증-및-권한&quot;&gt;7) 인증 및 권한&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Datahub는 SSO 지원 및 세부적인 권한 설정이 가능합니다.
    &lt;ul&gt;
      &lt;li&gt;SSO(Single Sing-On)로 Keycloak, Okta, Google Auth를 지원합니다.&lt;/li&gt;
      &lt;li&gt;사용자 / 그룹 단위로 정책 부여가 가능합니다. 현재는 View 관련 권한은 설정할 수 없고, 테이블이나 컬럼에 대한 설명, 오너, 태그 등을 수정할 수 있는 Edit 권한을 세부적으로 조정 가능합니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Amundsen은 SSO을 지원하나 세부적인 권한 설정은 지원하지 않습니다.
    &lt;ul&gt;
      &lt;li&gt;SSO 로 Keycloack, Okta, Flask_oidc를 지원합니다.&lt;/li&gt;
      &lt;li&gt;Amundsen은 자체적인 권한 설정을 지원하지 않습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-01/datahub-policies.png&quot; alt=&quot;datahub-policies&quot; /&gt;&lt;em&gt;Datahub - 권한 및 정책 페이지&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&quot;8-데이터-소스-지원&quot;&gt;8) 데이터 소스 지원&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;두 플랫폼 모두 BigQuery, Mysql, dbt, AWS S3 등 대중적으로 쓰이는 데이터 소스를 지원합니다.&lt;/li&gt;
  &lt;li&gt;Amundsen은 pandas, neo4j 등의 더 다양한 형태를 지원합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;9-사용자-이용-통계&quot;&gt;9) 사용자 이용 통계&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Datahub는 시각화된 이용 분석 페이지가 따로 존재합니다.
    &lt;ul&gt;
      &lt;li&gt;자주 검색된 데이터 셋  / 자주 수행된 액션 등을 그래프로 확인할 수 있습니다. (데모 사이트에서 &lt;a href=&quot;https://demo.datahubproject.io/analytics&quot;&gt;해당 페이지&lt;/a&gt;를 직접 확인하실 수 있습니다.)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Amundsen은 단편적인 이용 통계를 제공합니다.
    &lt;ul&gt;
      &lt;li&gt;메인 화면에서 “인기 있는 데이터셋”을, 각 테이블마다 “해당 테이블을 자주 이용한 사용자”을 확인할 수 있습습니다.&lt;/li&gt;
      &lt;li&gt;따로 분석 페이지는 없습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-01/datahub-analytics.png&quot; alt=&quot;datahub-analytics&quot; /&gt;&lt;em&gt;Datahub - 사용자 이용 통계 페이지&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-01/amundsen-analytics.png&quot; alt=&quot;amundsen-analytics&quot; /&gt;&lt;em&gt;Amundsen - 테이블을 자주 이용한 사용자&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&quot;10-서포트&quot;&gt;10) 서포트&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;공식 Github Repository 의 Star 수를 비교했을 때 Datahub가 4.5K, Amundsen이 3K 로 Datahub 가 더 많은 Star를 보유하고 있었습니다.&lt;/li&gt;
  &lt;li&gt;두 플랫폼 모두 공식 슬랙, 웹사이트, Github repository 등의 다양한 채널을 지원했으나, 슬랙의 활성화(질문, 답변의 활발함)나 공식 문서의 체계성 측면에서 Datahub가 좀더 우세했습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;4-최종-결정--datahub--&quot;&gt;4. 최종 결정 : Datahub!  &lt;a name=&quot;final-decision&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&quot;사용성의-편리함&quot;&gt;사용성의 편리함&lt;/h3&gt;

&lt;p&gt;가장 결정적인 이유는 사용성 차이였습니다. 사용성은 데이터 이용자와 플랫폼 개발자, 두 측면에서 생각할 수 있습니다.&lt;/p&gt;

&lt;p&gt;데이터 이용자 측면에서는 위에서도 비교했듯이, Datahub가 문서화, 오너십, 권한, 통계, 데이터 계보 관점에서 &lt;strong&gt;더 다양하고 풍부한 기능들을 지원&lt;/strong&gt;합니다. 이런 기능들이 실제로 도입됐을 때, 이용자가 원하는 데이터를 빠르게 찾고 쏘카의 데이터 디스커버리를 발전시키는 데에 더 많은 도움을 얻을 수 있을거라 판단했습니다.&lt;/p&gt;

&lt;p&gt;플랫폼 개발자 측면에서도 &lt;strong&gt;메타데이터 주입 시 Datahub가 더 편리&lt;/strong&gt;했습니다. 동일한 메타데이터를 주입한다고 가정했을 때 Datahub는 10 줄 내외의 yaml 파일로 가능한 반면, Amundsen은 100줄 이상의 Python Script가 필요했습니다. Amundsen Script가 긴 만큼 세세한 설정이 가능한지, 또 그런 세세한 설정이 가능하다고 해도 현재 상황에 필요한지를 고민해봤을 때는 의문점이 있었습니다. 따라서 메타데이터를 주입할 데이터 소스가 한정된 쏘카의 상황에는 Datahub 가 더 적절하다고 판단했습니다.&lt;/p&gt;

&lt;h3 id=&quot;ui의-깔끔함&quot;&gt;UI의 깔끔함&lt;/h3&gt;

&lt;p&gt;많은 사람이 이용하는 솔루션이나 플랫폼을 도입할때는 UI도 무시할 수 없다고 생각합니다. PoC시 Datahub UI가 훨씬 깔끔하다는 반응이 많았고, 매 버전마다 UI가 개선되고 있는 점도 Datahub으로 결정힌 이유 중 하나였습니다.&lt;/p&gt;

&lt;h3 id=&quot;빠르고-풍부한-서포트&quot;&gt;빠르고 풍부한 서포트&lt;/h3&gt;

&lt;p&gt;Datahub의 공식 슬랙 채널에는 현재 2,000명이 넘는 사람이 활동하고 있고, 주제별로 분리된 다양한 채널에서 질답과 오류 대응이 활발하게 이루어지는 편입니다. 또한 새로운 기능을 제안(Feature Request)하는 채널도 따로 있어서, 사용자의 피드백을 풍부하게 반영하려는 노력이 느껴졌습니다. 이 뿐만 아니라 최근 발생한 Log4j 취약점 사태에도 빠르게 해당 취약점을 보완한 패치가 반영되고, 모든 진행 상황이 슬랙을 통해 공유되었습니다.&lt;/p&gt;

&lt;p&gt;개인적인 경험으로는 공식 채널에 질문을 올리면 답이 안달리는 경우가 거의 없었던 것 같습니다. 국내에 데이터 디스커버리 플랫폼 관련 자료가 많지 않고, 팀에 합류하지 얼마 되지 않은 신입 엔지니어의 입장에서는 이런 활발한 서포트가 있다는 것이 매우 중요했습니다. 여담으로 PoC 과정에서 Datahub 공식 슬랙에 질문을 100개정도 한 것 같은데, 이제는 사람들이 질문이 있으면 저를 호출합니다(!)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-01/datahub-slack-01.png&quot; alt=&quot;datahub-slack-01&quot; /&gt;&lt;em&gt;디니 콜 1&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-01/datahub-slack-02.png&quot; alt=&quot;datahub-slack-02&quot; /&gt;&lt;em&gt;디니 콜 2&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-01/datahub-slack-03.png&quot; alt=&quot;datahub-slack-03&quot; /&gt;&lt;em&gt;디니 콜 3&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;5-마무리--다음-편-예고-&quot;&gt;5. 마무리 &amp;amp; 다음 편 예고 &lt;a name=&quot;wrap-up&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;이렇게 쏘카는 데이터 디스커버리 플랫폼으로 Datahub를 선정하게 되었습니다. 다음 편에는 구체적으로 Datahub를 어떻게 사내 인프라 환경에 구축했는지, 메타데이터 주입 방식을 어떻게 자동화하고 효율화 했는지 설명하려고 합니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;쏘카에서 신입 데이터 엔지니어가 어떤 일을 하는지 궁금하시다면, &lt;a href=&quot;https://tech.socarcorp.kr/data/2021/12/28/data-engineering-team-onboarding.html&quot;&gt;쏘카 신입 데이터 엔지니어 디니의 4개월 회고&lt;/a&gt;에서 확인하실 수 있습니다(데이터 엔지니어링 팀이 데이터 엔지니어링 그룹으로 바뀌고 데이터 웨어하우스 팀, 데이터 플랫폼 팀, 모비딕 팀으로 세분화되었어요)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;긴 글 읽어주셔서 감사합니다. 그러면 다음 편에서 만나요!&lt;/p&gt;</content><author><name>dini</name></author><category term="data" /><category term="data" /><category term="data-engineering" /><summary type="html">안녕하세요. 데이터 플랫폼 팀의 디니입니다.</summary></entry><entry><title type="html">쏘카 PM(Product Manager)은 어떻게 성장하나요?</title><link href="https://tech.socarcorp.kr/product/2022/02/23/growing-up-together-with-the-pm-team.html" rel="alternate" type="text/html" title="쏘카 PM(Product Manager)은 어떻게 성장하나요?" /><published>2022-02-23T07:00:00+00:00</published><updated>2022-02-23T07:00:00+00:00</updated><id>https://tech.socarcorp.kr/product/2022/02/23/growing-up-together-with-the-pm-team</id><content type="html" xml:base="https://tech.socarcorp.kr/product/2022/02/23/growing-up-together-with-the-pm-team.html">&lt;p&gt;안녕하세요. 쏘카의 PM1 팀 프로덕트 매니저 마리입니다.&lt;/p&gt;

&lt;p&gt;“PM은 어떻게 성장하나요? 역량을 키워 나가기 위해 무엇을 하나요?” 주변 동료들과 종종 이런 이야기를 나누곤 합니다. 저 역시 커리어를 시작하면서, 이런 고민들을 많이 했던 것 같습니다. 
이번 글에서는 PM 개인 관점과 동료, 조직과 함께 성장했던 경험을 공유하고자 합니다. 특히 빠르게 성장하는 조직에서 성장하는 방법을 고민하는 PM, PM 팀에게 도움이 되었던 방법을 소개합니다.&lt;/p&gt;

&lt;h2 id=&quot;목차&quot;&gt;목차&lt;/h2&gt;

&lt;p&gt;글의 목차는 다음과 같습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;쏘카의 프로덕트 매니저는&lt;/li&gt;
  &lt;li&gt;빠르게 성장하는 조직, 그 성장 속도만큼 생겨나는 어려움과 고민 지점들&lt;/li&gt;
  &lt;li&gt;돌파구 1: 어려운 점이 있으면, 함께 풀어보자 ‘위클리 미팅’&lt;/li&gt;
  &lt;li&gt;돌파구 2: 업무 관련 공부 갈증은 스터디로 채워보자 ‘빅쿼리 스터디’&lt;/li&gt;
  &lt;li&gt;정리&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;쏘카의-프로덕트-매니저는&quot;&gt;쏘카의 프로덕트 매니저는&lt;/h2&gt;

&lt;p&gt;본격적으로 글을 시작하기에 앞서, 쏘카의 PM이 어떻게 일하는지를 간략하게 소개하고자 합니다.&lt;/p&gt;

&lt;p&gt;IT 스타트업 업계에서도, 회사마다 PM의 역할이 조금씩 다릅니다. 크게 Product Manager, Project Manager, Product Owner로 이야기해 볼 수 있을 것 같습니다. 주요 관리 대상이 Product라면 Product Manager, Project라면 Project Manager로 칭합니다. Product를 관장하더라도 관리의 범위 및 역할을 넓혀 Product Owner라고 칭하기도 합니다.&lt;/p&gt;

&lt;p&gt;쏘카의 PM은 Product Manager로 쏘카의 여러 Product를 관리합니다. PM 그룹은 PM1팀과 PM2팀으로 구성되어 있습니다. PM 1팀은 고객분들이 사용하는 앱&amp;amp;웹 제품을 담당하고 PM 2팀은 B2B, 쏘카 내부 구성원들을 위한 인터널 프로덕트를 담당합니다(보다 상세한 설명은 &lt;a href=&quot;https://bit.ly/SOCAR-RECRUIT&quot;&gt;채용 문서&lt;/a&gt;의 프로덕트 매니저 부분에 나와있습니다 😉)&lt;/p&gt;

&lt;p&gt;그리고 팀 명칭에서도 알 수 있듯이, 쏘카의 PM 조직은 기능 조직의 형태로 구성되어 있습니다. 기능 조직이란 조직 안에서 같은 전문 기능 영역을 수행하는 구성원들 간 같은 팀으로 구성되어 있는 형태를 말합니다. 기능 조직의 가장 큰 장점은 동일한 업무를 진행하는 PM들과 고민을 나누고, 주변 동료들이 진행하는 프로젝트를 가까이서 보면서 정말 많이 배울 수 있다는 점입니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;빠르게-성장하는-조직-그-성장-속도만큼-생겨나는-어려움과-고민-지점들&quot;&gt;빠르게 성장하는 조직, 그 성장 속도만큼 생겨나는 어려움과 고민 지점들&lt;/h2&gt;

&lt;p&gt;팀 동료들과 서로의 프로젝트를 공유하고, 함께 성장하기까지는 부단한 노력이 필요했습니다. 조직이 빠르게 성장하는 만큼 프로젝트의 진행 속도가 빠르고, 일하는 동료들 대부분 바빠 보였습니다. 특히 지난 하반기는 IPO를 앞두고 회사가 빠르게 성장하면서 더 효율적으로 일할 수 있는 방법에 대해 고민하기 시작했습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/growing-up-together-with-the-pm-team/1.png&quot; alt=&quot;&quot; /&gt;
&lt;em&gt;제가 좋아하는 유튜브 채널 ‘존잡생각’에서도 비슷한 얘기를 합니다. 그렇기 때문에 회사에서 본인을 빠르게 성장하는 방법 - People Scaling이 필요하다고 강조합니다.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;쏘카의 PM들은 PM 직업 특성상 문제를 가만두지 않습니다. 이 문제를 해결할 방법을 찾아보기로 했습니다. 방법을 찾고, 작년에 실행했던 프로젝트 2가지를 소개합니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;돌파구-1-어려운-점이-있으면-함께-풀어보자-위클리-미팅&quot;&gt;돌파구 1: 어려운 점이 있으면, 함께 풀어보자 ‘위클리 미팅’&lt;/h2&gt;

&lt;p&gt;우선 우리의 고민거리를 함께 이야기하는 시간을 마련했습니다. 매주 수요일 오전 11시로 미팅을 잡아두고, 안건이 있으면 이 시간에 함께 모여 이야기를 나눴습니다. 헤아려보니, 작년 6월 초에 시작해서 12월까지 7개월간 총 24번의 위클리 미팅이 진행되었습니다! 
&lt;img src=&quot;/img/growing-up-together-with-the-pm-team/2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/growing-up-together-with-the-pm-team/3.png&quot; alt=&quot;&quot; /&gt;
위클리 미팅은 아래의 방식으로 진행되었습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;위클리 미팅 하루 전까지, 동료들과 이야기하고 싶은 안건이 있으면 ‘PM1 팀 위클리’ 노션 페이지에 해당 내용을 등록합니다.&lt;/li&gt;
  &lt;li&gt;안건이 등록되면, 매주 수요일 오전 11시에 회의실 또는 행아웃으로 만납니다. (가끔 날이 좋으면, 서울숲으로 나가기도 합니다 🌳 🎵)&lt;/li&gt;
  &lt;li&gt;발제자가 안건을 소개하고, 동료들과 함께 이야기를 나눕니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;처음 위클리 미팅을 만들자는 제안이 나왔을 때, 동료들의 의견은 반반이었습니다. “오, 너무 좋겠다. 나 이야기해보고 싶은 것 있어.” 라고 긍정적인 견해를 가진 경우도 있었지만, “매주 이야기할 만큼, 고민이 많을까.” 회의적인 동료들도 있었습니다. 그래서 안건이 있을 때마다 만나자고 한 것인데, 되돌아보니 한 달 평균 3번 이상, 1주 정도를 제외하면 늘 만났습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/growing-up-together-with-the-pm-team/4.jpg&quot; alt=&quot;&quot; /&gt;
&lt;em&gt;가을 날의 서울숲 미팅은 정말 환상입니다! 😍&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;위클리 미팅은 ‘함께’ ‘빠르게’ 문제를 풀어나가는 창구가 되었습니다. 개개인은 프로젝트를 진행하면서 겪는 다음과 같은 문제를 해결할 수 있는 아이디어를 얻어 갔습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;“배포하고 작고 큰 문제들이 발생하는데, 배포 시나리오는 어떻게 작성하고 계시나요?”&lt;/li&gt;
  &lt;li&gt;“업무 대체자는 어떻게 선정하고, 공유하는 게 좋을까요?”&lt;/li&gt;
  &lt;li&gt;“미팅이 너무 많아지고 있는데, 미팅 시간은 어떻게 조정하고 계신가요?”&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;PM들마다 경험한 프로젝트도 다르고, 강점도 다릅니다. 누군가 이런 고민을 발제하면, 각자 도움 되었던 문서와 방법을 공유했고, 꿀팁 가득한 가이드 문서가 하나 뚝딱 만들어졌습니다. 위클리 회의 이후 팀 내 모든 PM이 가이드 문서를 보고 고민 포인트가 줄었습니다.&lt;/p&gt;

&lt;p&gt;또한 PM 위클리 미팅은 팀의 문제를 하나씩 푸는 계기가 되었습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;“새로운 구성원이 오면, 매번 온보딩 준비를 해야해요. 시간도 줄이고 일관성도 갖추기 위해 가이드문서를 만드는 게 어떨까요?”&lt;/li&gt;
  &lt;li&gt;“다른 팀에서 제품에 관한 공통 질문이 자주 들어오는데요. 앱 사용설명서를 만들어서 공유하면 좋겠어요.”&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이런 부분은 혼자 해결해 나가기 어려운 문제입니다. 문서화 작업을 하더라도 끊임없는 업데이트가 필요하고, 이를 위해 우리 팀에 필요한 일임에 공감대가 형성되어야 하기 때문입니다. 실제 이 시간을 통해 그간의 숙원 사업이었던 ‘쏘카 앱 사용설명서’도 만들어졌습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/growing-up-together-with-the-pm-team/5.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;결과적으로 위클리 미팅의 효과는 기대했던 만큼 좋았습니다. 24번의 미팅을 거치면서 총 17개의 의제가 논의되었고, 그중 9개는 안건을 제안한 동료의 문제에 공감해 새로운 방법으로 시도해 보고 있습니다. 이를테면, 새로운 구성원이 우리 팀에 왔을 때, 보다 잘 온보딩할 수 있는 방법이 필요하다는 이야기에 PM1 팀 뉴비를 위한 온보딩 프로세스가 만들어졌습니다. 프로젝트 하고 나서 백로그를 체계적으로 관리하자는 안건이 제안되어 백로그 프로세스 및 문서를 만들어 운영하고 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/growing-up-together-with-the-pm-team/6.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;돌파구-2-업무-관련-공부-갈증은-스터디로-채워보자-빅쿼리-스터디&quot;&gt;돌파구 2: 업무 관련 공부 갈증은 스터디로 채워보자 ‘빅쿼리 스터디’&lt;/h2&gt;

&lt;p&gt;일을 하다 보면 더 공부해 보고 싶은 갈증이 생깁니다. 저의 경우에는 ‘프로덕트 데이터’에 대한 공부를 좀 더 하고 싶다는 생각이 있었습니다. 기능을 배포하고, 유저들의 행동 패턴을 더 들여다보고 싶거나 백로그에 등록해 둔 일감을 좀 더 디벨롭해보고 싶을 때 데이터를 직접 조회하여 문제를 해결하고 싶다는 생각이 들었습니다.&lt;/p&gt;

&lt;p&gt;그래서 빅쿼리 조회 역량을 키워나가는데 관심이 있는 동료들을 모아, 빅쿼리 스터디를 진행했습니다. 처음에는 PM팀으로 시작해, 지금은 사업팀, CRM팀의 동료도 모여 함께 진행하고 있습니다. 헤아려보니, 작년 7월부터 시작해서 총 20회 스터디가 진행되었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/growing-up-together-with-the-pm-team/7.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;빅쿼리 스터디는 아래의 방식으로 진행되었습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;4명의 동료들이 돌아가면서 매주 문제를 출제합니다.&lt;/li&gt;
  &lt;li&gt;직접 쿼리를 작성해 빅쿼리로 사내 데이터를 직접 조회합니다.&lt;/li&gt;
  &lt;li&gt;매주 금요일 오전 9시에 만나 서로 쿼리를 공유하며 피드백합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;조금 더 구체적인 설명을 하기 위해 과거에 진행했던 스터디 경험을 공유합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/growing-up-together-with-the-pm-team/8.png&quot; alt=&quot;&quot; /&gt;
&lt;em&gt;1) 문제를 출제하고, 슬랙 스터디 채널에서 공유합니다.&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;이 케이스는 카리나가 발제자였습니다. 화요일 중에 발제자가 문제를 제출하고, 슬랙 스터디 채널에 문제 링크를 공유합니다. 유저의 서비스 사용 자료를 기반으로, &lt;성장 지수=&quot;&quot;&gt; 지표를 집계하고 도출하는 방법을 알아보았습니다.&lt;/성장&gt;&lt;/li&gt;
  &lt;li&gt;성장지수란 사용자의 서비스 사용과 관련한 상태 변화를 수치화해서 서비스가 성장하는지를 알려주는 지표입니다. 유저의 서비스 사용 자료를 기반으로 Signup(신규 등록 후 사용을 시작함), Deactivation(활성화 유저에서 비활성화 유저로 전환), Reactivation(비활성화 유저에서 활성화 유저로 전환), Exit(서비스를 탈퇴함)을 정의하고 이를 기반으로 성장지수(signup user + reactivation user - deactivation user - exit) 지표를 도출합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/img/growing-up-together-with-the-pm-team/9.png&quot; alt=&quot;&quot; /&gt;
&lt;em&gt;2) 퇴근 후 목요일 밤은 빅쿼리 문제 푸는 시간입니다. 😂 질문과 답변이 오고 갑니다.&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;발제자가 문제를 출제하고 나면 스터디가 있는 금요일 오전 전까지 각자 문제를 풀어옵니다. 보통 퇴근 후 목요일 밤 다시 출근했다고 표현하곤 합니다 😂. 문제를 풀면서, 모르는 부분에 대해서는 질문과 답변이 오고 갑니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/img/growing-up-together-with-the-pm-team/10.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/growing-up-together-with-the-pm-team/11.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;금요일 오전 9시에 만나서, 작성한 쿼리를 공유하고, 피드백을 주고 받습니다. 피드백은 ‘출제자의 의도에 부합하는 방향으로 함수를 적재적소에 사용했는지’를 중점적으로 나눕니다. 이번 문제는 12월 1일부터 12월 10일까지 해당 기간 동안 첫 사용을 한 회원의 날짜별 회원 상태를 구하고, 그 집계를 통해 성장성을 지수화하는 것이 목표였습니다. 이를 위해
    &lt;ul&gt;
      &lt;li&gt;SELECT, UNION ALL 구문을 활용해 12월 1일부터, 12월 10일까지의 날짜 컬럼을 가진 테이블 생성&lt;/li&gt;
      &lt;li&gt;CASE WHEN 함수를 활용하여, 유저의 ‘신규 등록일’과 ‘탈퇴일’, ‘사용일’ 구하기&lt;/li&gt;
      &lt;li&gt;CROSS JOIN 함수를 활용하여, 두 개의 테이블을 상호 조인하기&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;위와 같은 내용이 잘 진행되었는지 이야기합니다. “우선 유저별 회원 상태를 구할 수 있도록, 각각의 활동 로그를 모은 테이블을 만들었어. 여기서 예약 테이블과 탈퇴 테이블을 left join 했고…” 와 같이 쿼리를 왜 이렇게 작성했는지를 동료들에게 설명합니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;피드백을 주고 받는 과정을 통해 좀 더 효율적으로 쿼리를 작성할 수 있는 방법, 보다 적은 용량으로 조회할 수 있는 방법, 다른 사람들이 더 알아보기 쉽게 쿼리를 작성하는 방법을 익히게 되었습니다. 스터디 이후 서브 쿼리보다 WITH 구문을 더 애용하게 되었습니다!&lt;/li&gt;
  &lt;li&gt;특히 이번 시간에는 ‘확장성’ 에 대한 이야기를 나누었습니다. 성장 지수라는 것은 카리나가 제시한 것과 같은 특정한 날짜 구간이 아니더라도 더 넓히거나 좁혀가면서 다양하게 조회해 볼 수 있을텐데, 이를 위해서는 쿼리를 어떻게 작성해보면 좋을까는 궁금함이 생겨서 이야기를 꺼냈습니다. 이때 에이든이 이전에 실무에서 사용했던 DECLARE 구문을 소개해 주셨습니다!&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;declare&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d1&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;date&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DEFAULT&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;TIMESTAMP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;CURRENT_DATE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;&quot;Asia/Seoul&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;&quot;Asia/Seoul&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    
&lt;span class=&quot;c1&quot;&gt;-- WHERE 조건에서 아래와 같이 표현하면, '어제까지' 로 조회 가능.&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;DATE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d1&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이처럼 사내 스터디는 데이터 역량을 키워나가는데 매우 효과적이었습니다. 이를 통해 SELECT / FROM / WHERE 정도의 간단한 조회만 할 수 있었는데, 윈도우 함수가 손에 익는 수준으로 쿼리를 조회할 수 있게 되었습니다. 실무 진행에도 큰 도움이 되었습니다. 직접 제품 성과를 조회해서 업무 성과를 어필할 수 있게 되었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/growing-up-together-with-the-pm-team/12.png&quot; alt=&quot;&quot; /&gt;
&lt;em&gt;최근 1년 빅쿼리 스터디 회고하면서 나눴던 이야기들&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/growing-up-together-with-the-pm-team/13.jpg&quot; alt=&quot;&quot; /&gt;
&lt;em&gt;어느덧 8개월 가까이, 매주 금요일 온라인으로 함께 빅쿼리를 해나가고 있는 마리, 카리나, 에이든, 브라운&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;정리&quot;&gt;정리&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;무엇이건 실제 임팩트를 남기려면 혼자 힘으로만 되는 게 없습니다. 함께 해야 합니다. 
그리고 무엇보다 이런 ‘함께’, 그리고 ‘자라기’를 매일매일 해야 합니다. 
(…) 대화는 우리가 혼자서는 생각하지 못했던 것들을 만들게 해 줄 것입니다.&lt;/p&gt;

  &lt;p&gt;- 함께 자라기, 김창준&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;최근 재밌게 읽었던 &amp;lt;함께 자라기: 애자일로 가는 길&amp;gt; 책에 나오는 이야기입니다. 쏘카는 빠르게 성장하는 조직인 만큼, 어떻게 함께 성장할 것인가에 대한 고민을 끊임없이 하고 있습니다.&lt;/p&gt;

&lt;p&gt;이 글에서는 PM1팀 위클리와 사내 스터디를 소개해드렸습니다. PM1팀 위클리, 회고, 1on1을 통해 주 단위로 빠르게 피드백을 주고받고, 필요시 사내 스터디를 만들어 실무에 필요한 역량을 함께 키워나가고 있습니다. 만약 쏘카 PM 직군에 관심이 있다면 채용 공고를 확인 부탁드립니다!&lt;/p&gt;</content><author><name>marie</name></author><category term="product" /><category term="product manager" /><summary type="html">안녕하세요. 쏘카의 PM1 팀 프로덕트 매니저 마리입니다.</summary></entry><entry><title type="html">쏘카의 관제 장치(Telematics Device)가 하는 일</title><link href="https://tech.socarcorp.kr/mobility/2022/02/15/control-device-with-car-sharing.html" rel="alternate" type="text/html" title="쏘카의 관제 장치(Telematics Device)가 하는 일" /><published>2022-02-15T07:00:00+00:00</published><updated>2022-02-15T07:00:00+00:00</updated><id>https://tech.socarcorp.kr/mobility/2022/02/15/control-device-with-car-sharing</id><content type="html" xml:base="https://tech.socarcorp.kr/mobility/2022/02/15/control-device-with-car-sharing.html">&lt;p&gt;안녕하세요. 쏘카 커넥티드플랫폼 그룹 커넥티드디바이스팀 주노입니다.&lt;/p&gt;

&lt;p&gt;쏘카에서 운영되는 차량과 개인 소유의 차량은 어떠한 차이가 있을까요? 비대면으로 카셰어링을 운영하기 위해, 다양한 기술들이 쏘카 차량에 담겨있다는 사실 혹시 알고 계셨나요?&lt;/p&gt;

&lt;p&gt;원격으로 차량의 예약, 차량 운행, 차량 반납이 가능하도록, 쏘카의 차량에는 일반 차량과 달리 다양한 IoT 장치들이 설치되어 있습니다. 관제 장치, 블랙박스, 하이패스 등 겉으로 보기엔 일반 제품들과 유사한 모습입니다. 하지만 쏘카에는 다소 특별한 기능들을 가진 장치들이 차량 내부에 장착됩니다.&lt;/p&gt;

&lt;h2 id=&quot;목차&quot;&gt;목차&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;쏘카 차량의 관제 장치(Telematics Device)란&lt;/li&gt;
  &lt;li&gt;쏘카 차량의 관제 장치가 하는 일
    &lt;ul&gt;
      &lt;li&gt;1) 차량의 데이터를 수집합니다.&lt;/li&gt;
      &lt;li&gt;2) 차량의 문을 잠그고 열 수 있습니다.&lt;/li&gt;
      &lt;li&gt;3) 다양한 통신 방법으로 데이터를 교환합니다.&lt;/li&gt;
      &lt;li&gt;4) 외부에 노출된 차량이라는 조건(온도, 습기)을 견뎌야만 합니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;맺으며&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;쏘카-차량의-관제-장치telematics-device란&quot;&gt;쏘카 차량의 관제 장치(Telematics Device)란&lt;/h2&gt;

&lt;p&gt;관제 장치의 사전적 정의는 ‘위성이 본래의 역할을 수행하도록 관리하여 통제하는 장치. 주로 통신 위성, 방송 위성, 탐사 위성 따위를 관제하며, 위성의 임무에 따라 기기의 내용도 달라진다’입니다. &lt;strong&gt;쏘카의 관제 장치는 ‘차량이 본래의 역할을 수행할 수 있도록 관리, 통제하는 장치’&lt;/strong&gt;라고 정의할 수 있습니다. 쏘카는 비대면으로 차량을 대여할 수 있는 비대면 카셰어링 서비스를 운영하고 있습니다. 이런 서비스를 운영하기 위해 차량을 관리하고 통제하는 장치가 필요합니다.&lt;/p&gt;

&lt;p&gt;개인이 소유한 차량과는 달리, 쏘카의 차량은 관제 장치를 장착함으로써 카셰어링 차량으로 변하게 됩니다. 고객이 차량을 예약하고, 주행하고, 반납하기 위해서는 차량의 위치나 차량의 상태가 자동으로 확인되어야 하며, 예약한 고객이 스마트키를 들고 있지 않더라도 차량을 이용할 수 있도록 차량의 문을 열고 잠글 수 있어야 하기 때문입니다.&lt;/p&gt;

&lt;p&gt;이번 글에서는 쏘카에서 운영하는 1만 7천 대의 차량에 장착된 다양한 장치들 중 관제 장치에 관해 다루고자 합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/control-device-with-car-sharing/sts-1-app.png&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/control-device-with-car-sharing/sts-0-schematic.jpg&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;쏘카-차량의-관제-장치가-하는-일&quot;&gt;쏘카 차량의 관제 장치가 하는 일&lt;/h2&gt;

&lt;h3 id=&quot;1-차량의-데이터를-수집합니다&quot;&gt;1) 차량의 데이터를 수집합니다.&lt;/h3&gt;

&lt;p&gt;차량의 정보를 수집하여, 비대면으로 예약 / 반납이 가능할 수 있는 기능들이 숨겨져 있습니다.&lt;/p&gt;

&lt;p&gt;쏘카에는 40 종류가 넘는 다양한 차종을 보유하고 있고, 차량 대수로는 약 17,000대가 존재합니다. 이 많은 차량은 어디에 위치했는지, 반납 시 차량 시동은 잘 꺼져있는지, 주유량이나 전기차 충전량은 충분한지, 문은 제대로 잘 잠기고 열리는지 등이 원격에서 실시간으로 확인이 되어야 비대면 카셰어링 서비스가 가능합니다.&lt;/p&gt;

&lt;p&gt;데이터를 수집할 때 있어 보안에도 신경 써야 합니다. 특히 고객의 개인 정보, 위치 정보 데이터가 대표적으로 그렇습니다. 이런 데이터는 정보보호 및 개인 정보보호 관리체계 인증(ISMS-P)에 따라 보안을 철저히 하여 숨겨져 있으며, 권한을 가진 일부 직원들만 해당 정보를 조회할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/control-device-with-car-sharing/sts-2-data.jpg&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;p&gt;차량의 데이터를 수집해서 고객의 편리한 운행을 돕는 것 뿐만 아니라, 보다 효율적으로 차량을 운영하고 관리할 수 있습니다. 예를 들어 차량 내부의 다양한 센서 및 ECU(Electronic Control Unit)로 수집되는 데이터를 수집해 사용 중인 차량, 시스템, 장치의 이상 징후 및 안정성을 관리(PHM, Prognostics and Health Management)할 수 있습니다.&lt;/p&gt;

&lt;p&gt;차량의 데이터를 수집하는 엔지니어링이 궁금하신 분은 &lt;a href=&quot;https://tech.socarcorp.kr/mobility/2022/01/06/socar-iot-pipeline-1.html&quot;&gt;차량용 단말을 위한 IoT 파이프라인 구축기 #1&lt;/a&gt;, &lt;a href=&quot;https://tech.socarcorp.kr/mobility/2022/02/09/socar-iot-pipeline-2.html&quot;&gt;차량용 단말을 위한 IoT 파이프라인 구축기 (feat. Kafka) #2&lt;/a&gt; 두 글을 추천합니다.&lt;/p&gt;

&lt;h3 id=&quot;2-차량의-문을-잠그고-열-수-있습니다&quot;&gt;2) 차량의 문을 잠그고 열 수 있습니다.&lt;/h3&gt;

&lt;p&gt;쏘카의 비대면 서비스를 위해선 근거리뿐만 아니라, 원거리에서도 차량을 제어할 수 있어야 합니다.
일반적인 차량에서는 스마트키를 통해 차량의 문을 열고 잠글 수 있으며, 스마트키를 차량 실내에 두어야만 차량의 시동을 걸 수 있습니다.
쏘카에는 스마트폰만으로도 차를 열고 잠글 수 있어야 하는데, 이때 관제 장치가 차량의 문을 열고 닫는 명령하는 역할을 담당합니다. 
또한 고객분들이 차량의 위치를 보다 편하게 찾을 수 있도록, 스마트폰으로도 비상등을 켜거나 경적(Horn)을 울릴 때에도 관제 장치가 사용됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/control-device-with-car-sharing/sts-3-app.png&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;3-다양한-통신-방법으로-데이터를-교환합니다&quot;&gt;3) 다양한 통신 방법으로 데이터를 교환합니다.&lt;/h3&gt;

&lt;p&gt;쏘카의 관제 장치는 스마트폰처럼 LTE나 3G 통신을 통해 쏘카의 서버와 메시지를 교환하게 됩니다. 이를 통해 서버는 차량 제어에 관한 데이터를 수집하게 됩니다.&lt;/p&gt;

&lt;p&gt;LTE/3G 네트워크 망은 전국적으로 통신사의 전파 중계기가 설치되어 있어 대부분의 지역에서 네트워크 연결이 가능합니다. 하지만 전파 중계 설비가 고장났거나, 네트워크 전파가 미처 닿지 않는 통신 음영 지역에서는 데이터 송수신이 잠시 끊기는 경우가 있습니다. 이를 막기 위해 쏘카에서는 또 다른 무선 통신 기술도 사용합니다. 블루투스는 2.4~2.485GHz의 극초단파를 사용한 개인 근거리 무선 통신 산업 표준 규격입니다. 쏘카의 관제 장치는 BLE 5.0 통신이 가능하여 지하주차장, 산지, 바다지역 등 3G/LTE 통신이 매우 약한 지역에서도 문제없이 차량을 제어할 수 있습니다. 그리고 근거리에서 차량 제어 시, 스마트폰의 블루투스를 켤 경우 켜지 않았을 때 보다 더 빠르게 차량을 제어할 수 있습니다.&lt;/p&gt;

&lt;p&gt;블루투스 통신을 통해 스마트폰뿐만 아니라 다양한 전자 장치와도 무선 통신이 가능합니다. 이를 통해 차량 내/외부, 도로와 주차장 등 다양한 환경에서의 센서나 장치에서 무선으로 데이터를 수집할 수 있습니다. 보다 정확하게 차량의 위치를 찾거나, 차량에 장착된 센서에서 데이터를 획득하고, 차량의 다양한 정보들을 수집하거나 데이터를 교환할 수 있습니다.&lt;/p&gt;

&lt;h3 id=&quot;4-외부에-노출된-차량이라는-조건온도-습기을-견뎌야만-합니다&quot;&gt;4) 외부에 노출된 차량이라는 조건(온도, 습기)을 견뎌야만 합니다.&lt;/h3&gt;

&lt;p&gt;쏘카의 차량은 자연 환경에 노출되어 있습니다. 운전 중 일 때의 수많은 진동, 여름에는 90도 겨울에는 -20도까지 변하는 온도, 비 오는 날에는 엄청난 습기까지 일반적인 전자 장비는 바로 고장이 날 수 밖에 없는 조건입니다.&lt;/p&gt;

&lt;p&gt;이런 조건에서 정상적인 사용이 가능할 수 있도록 쏘카 차량 내 장치들은 &lt;a href=&quot;https://www.koreascience.or.kr/article/JAKO202129159578200.pdf&quot;&gt;AEC-Q100&lt;/a&gt; 같은 인증을 획득하거나, 인증 규격 이상의 성능을 가져야만 합니다. (인증은 환경 시험(Environmental Test, 저/고온, 열 충격시험 등), 기구 시험(Mechanical Test, 진동 낙하 충격 시험 등), 전기적 성능 시험(Electrical Test, 작동 전압, 전원 순단 및 전압 변동 시험)을 통해 장치의 성능을 평가하게 됩니다)&lt;/p&gt;

&lt;p&gt;220V 콘센트가 아니라 차량의 배터리만 사용할 수 있는 차량 내 전자 장치들은 전기를 공급 받는 것도 힘든 일입니다. 모든 전자 장치는 회로에서 전자기 노이즈가 발생하며, 이 정도가 심한 경우 다른 전자 장치가 영향을 받아 오작동을 하거나 고장날 수도 있습니다. 차량에 설치되는 장치인만큼, 장착된 장비들이 전자 장치 간 간섭(EMI/EMC)로 인한 영향을 방지하기 위해, &lt;a href=&quot;https://www.rra.go.kr/FileDownSvl?file_type=LAWKR&amp;amp;file_parentseq=113&amp;amp;file_seq=1&quot;&gt;표준 인증(KN41)&lt;/a&gt;을 득하거나 표준 규격보다 더 낮은 양의 전자기 노이즈만 발생시키도록 해야합니다.&lt;/p&gt;

&lt;p&gt;이러한 조건 속에서도 서비스가 가능할 수 있도록, 관제 장치에는 개발, 제조, 납품, 장착, AS 전반에 걸친 다양한 노하우와 기술이 포함되어 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/control-device-with-car-sharing/sts-4-env.png&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/control-device-with-car-sharing/sts-5-soldering.png&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;맺으며&quot;&gt;맺으며&lt;/h2&gt;

&lt;p&gt;쏘카의 손으로 제작된 관제 장치는 2020년 처음 장착된 이래 10,000대가 넘는 차량에 장착되었습니다.
관제 장치는 약 6천만 시간 동안, 57만 명의 고객들의 176만 번의 차량 운행을 가능하게 하였으며 2억 Km의 거리의 여정 동안 3천만 번의 제어를 수행하고 6억 개의 데이터셋을 수집하였습니다.&lt;/p&gt;

&lt;p&gt;쏘카 차량 내부에는 쏘카에서 직접 제작한 관제 장치뿐만 아니라, 고객이 보다 편하고 효율적으로 차량을 운영할 수 있도록 하기 위해 또 다른 장치들이 장착되어 있습니다.
다음 글에서는 운전 편의를 위한 장치에 대해서 소개 드리겠습니다.&lt;/p&gt;</content><author><name>juno</name></author><category term="mobility" /><category term="iot" /><summary type="html">안녕하세요. 쏘카 커넥티드플랫폼 그룹 커넥티드디바이스팀 주노입니다.</summary></entry><entry><title type="html">차량용 단말을 위한 IoT 파이프라인 구축기 (feat. Kafka) #2</title><link href="https://tech.socarcorp.kr/mobility/2022/02/09/socar-iot-pipeline-2.html" rel="alternate" type="text/html" title="차량용 단말을 위한 IoT 파이프라인 구축기 (feat. Kafka) #2" /><published>2022-02-09T01:00:00+00:00</published><updated>2022-02-09T01:00:00+00:00</updated><id>https://tech.socarcorp.kr/mobility/2022/02/09/socar-iot-pipeline-2</id><content type="html" xml:base="https://tech.socarcorp.kr/mobility/2022/02/09/socar-iot-pipeline-2.html">&lt;div class=&quot;photo-copyright&quot;&gt;
Photo by &lt;a href=&quot;https://unsplash.com/@selimarda?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText&quot;&gt;SELİM ARDA ERYILMAZ&lt;/a&gt; on &lt;a href=&quot;https://unsplash.com/photos/XYeCKHcZNz8?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText&quot;&gt;Unsplash&lt;/a&gt;
&lt;/div&gt;

&lt;p&gt;안녕하세요. 데이터 엔지니어링 그룹 모비딕 팀의 바다, 올리버입니다.
&lt;a href=&quot;https://tech.socarcorp.kr/mobility/2022/01/06/socar-iot-pipeline-1.html&quot;&gt;차량용 단말을 위한 IoT 파이프라인 구축기 #1&lt;/a&gt;에 이어, 차량에서 수집한 정보를 전사적으로 활용할 수 있도록 어떻게 단말 파이프라인을 설계하고 만들어 가는지에 대해 자세히 이야기하려고 합니다.&lt;/p&gt;

&lt;p&gt;이 글은 다음과 같은 분들에게 도움이 됩니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;데이터 파이프라인 구축에 관심 있는 개발자&lt;/li&gt;
  &lt;li&gt;차량의 정보 수집과 데이터 흐름에 관심 있는 분&lt;/li&gt;
  &lt;li&gt;AWS IoT Core, MSK(Managed Streaming for Apache Kafka) 솔루션에 관심 있는 개발자&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;목차&quot;&gt;목차&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#쏘카의-첫-단말-파이프라인을-소개합니다-&quot;&gt;쏘카의 첫 단말 파이프라인을 소개합니다 &lt;a name=&quot;introduce&quot;&gt;&lt;/a&gt;&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#기존-단말-파이프라인&quot;&gt;기존 단말 파이프라인&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#기존-파이프라인의-한계&quot;&gt;기존 파이프라인의 한계&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#한계를-넘기-위한-신규-파이프라인-설계&quot;&gt;한계를 넘기 위한 신규 파이프라인 설계&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#본격적으로-신규-단말-파이프라인을-구축해봅시다-&quot;&gt;본격적으로 신규 단말 파이프라인을 구축해봅시다 &lt;a name=&quot;build&quot;&gt;&lt;/a&gt;&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#kafka-클러스터&quot;&gt;Kafka 클러스터&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#producer&quot;&gt;Producer&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#iot-core의-메시지-생성&quot;&gt;IoT Core의 메시지 생성&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#텔레매틱스-서버의-메시지-생성&quot;&gt;텔레매틱스 서버의 메시지 생성&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#consumer&quot;&gt;Consumer&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#kafka-connect&quot;&gt;Kafka Connect&lt;/a&gt;
            &lt;ul&gt;
              &lt;li&gt;&lt;a href=&quot;#s3-sink-connector&quot;&gt;S3 Sink Connector&lt;/a&gt;&lt;/li&gt;
              &lt;li&gt;&lt;a href=&quot;#elasticsearch-sink-connector&quot;&gt;Elasticsearch Sink Connector&lt;/a&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#단말-차량-converter&quot;&gt;단말-차량 Converter&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#단말-파이프라인-모니터링-&quot;&gt;단말 파이프라인 모니터링 &lt;a name=&quot;monitoring&quot;&gt;&lt;/a&gt;&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#마치며-&quot;&gt;마치며 &lt;a name=&quot;wrap-up&quot;&gt;&lt;/a&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;쏘카의-첫-단말-파이프라인을-소개합니다-&quot;&gt;쏘카의 첫 단말 파이프라인을 소개합니다 &lt;a name=&quot;introduce&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&quot;기존-단말-파이프라인&quot;&gt;기존 단말 파이프라인&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;/img/iot-pipeline-2/pipeline-prev.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;과거에는 차량에서 수집한 정보를 HTTPS 프로토콜을 이용해 쏘카의 텔레매틱스 서버에 전달했습니다. 텔레매틱스 서버에서 단말 데이터를 수집, 가공, 적재하는 작업의 일환으로 파이프라인에 단말 데이터를 투입했습니다. 텔레매틱스 서버는 쏘카 서비스의 원활한 운영과 고객 불편의 최소화를 위해 차량에서 수집한 정보를 최대한 빠른 시간 안에 처리하여야 합니다.&lt;/p&gt;

&lt;p&gt;단말이 차량에서 수집한 정보의 종류에 따라 텔레매틱스 서버의 다른 엔드포인트에 이를 보고합니다. 예를 들어 일반적인 차량 정보의 주기적 보고의 경우 &lt;code class=&quot;highlighter-rouge&quot;&gt;/log&lt;/code&gt; 엔드포인트로, 단말 재부팅시에  대한 보고는 &lt;code class=&quot;highlighter-rouge&quot;&gt;/boot&lt;/code&gt; 엔드포인트로 보고하는 방식입니다.&lt;/p&gt;

&lt;p&gt;차량에서 수집한 정보를 보고받은 텔레매틱스 서버는 이 정보를 서비스 운영을 위해 데이터베이스의 차량 정보 스키마에 맞추어 변환하여 데이터베이스에 적재합니다. 이렇게 변환하는 과정에서 운영에 꼭 필요한 데이터만을 필터링해 적재하기 때문에, 운영에는 충분한 정보를 가지고 있지만 연구와 분석을 위해 사용하기에는 한계가 있습니다.&lt;/p&gt;

&lt;p&gt;따라서 연구, 분석에도 차량에서 수집한 정보를 충분히 활용할 수 있도록 필터링 되지 않은 데이터를 AWS Kinesis에 흘려보냅니다. Kinesis는 실시간으로 데이터 스트림을 수집하고 처리, 분석하는 데에 사용하는 AWS의 솔루션입니다. 당시 Kinesis를 선택했던 이유는 데이터 스트림에 대한 관리와 개발을 최소화하면서도 차량에서 수집한 정보를 필요한 곳에서 최대한으로 활용하고자 했던 선택이었습니다.&lt;/p&gt;

&lt;p&gt;이렇게 Kinesis Stream에 전달된 차량에서 수집한 정보는 Kinesis Firehose를 거쳐 각각 Elasticsearch, S3, BigQuery에 저장하여 활용하고 있었습니다.&lt;/p&gt;

&lt;h3 id=&quot;기존-파이프라인의-한계&quot;&gt;기존 파이프라인의 한계&lt;/h3&gt;
&lt;p&gt;하지만 단순히 ‘수집 정보를 흘려보내기만 하면 되겠다’라고 가볍게 여겼던 Kinesis는 생각보다 많은 관리가 필요했고, Kinesis Stream을 사용하는 프로젝트가 늘어날수록 파이프라인은 점점 복잡해졌습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/iot-pipeline-2/pipeline-bang.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;기본적으로 Elasticsearch와 S3, BigQuery에 적재하는 것 외에도, 전사에서 필요한 용도에 따라 단말 수집 정보가 실시간으로 수집되는 Kinesis Stream에 Consumer를 연결하여 활용할 수 있었습니다. 그러나 이 파이프라인을 관리하는 주체가 없어서 불필요하게 많은 Consumer가 연결되었습니다. &lt;strong&gt;Kinesis 스트림에 많은 Lambda 함수, 많은 Process들이 붙었고 Kinesis Stream에 병목이 생기는 경우가 생겼습니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;더 많은 처리량을 위해 샤드(샤드 당 1초에 최대 2MB의 데이터 처리)를 늘려보기도 하고, 향상된 팬아웃 기능을 사용하여 극복할 수 있었지만 이는 비용 증가와 직결되며, 근본적인 해결책도 아니었습니다.&lt;/p&gt;

&lt;h3 id=&quot;한계를-넘기-위한-신규-파이프라인-설계&quot;&gt;한계를 넘기 위한 신규 파이프라인 설계&lt;/h3&gt;
&lt;p&gt;Server-side Application의 업데이트는 보통 즉각적인 효과를 발휘하지만, 사용자의 PC에 설치되는 소프트웨어나 하드웨어의 펌웨어는 상황에 따라 업데이트에 상당한 시간을 필요로 합니다. 쏘카의 단말 펌웨어 업데이트도 항상 쉽지 않은 일입니다.&lt;/p&gt;

&lt;p&gt;차량에 명령을 내리는 명령 채널에 &lt;a href=&quot;https://aws.amazon.com/ko/iot-core&quot;&gt;IoT Core&lt;/a&gt;를 사용하게 되면서, 보고 채널에도 IoT Core로 갈아탈 수 있는 기회가 왔고, 기존 파이프라인의 한계점을 개선할 수 있는 절호의 찬스를 맞이했습니다! 그리하여 발 빠르게 신규 파이프라인 설계에 착수했습니다. 설계하면서 중점을 두었던 주제들은 다음과 같습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;단말 수집 정보를 수집-가공-저장하던 텔레매틱스 서버를 은퇴시키자
    &lt;ul&gt;
      &lt;li&gt;텔레매틱스 서버는 그동안 단말 데이터 처리를 위해 수고해주었지만, 장애가 발생하면 파이프라인의 병목이 되는 원인이기도 했습니다. 이는 파이프라인의 흐름에 치명적일 수 있어 용도를 최소화하거나 은퇴시키고자 했습니다.&lt;/li&gt;
      &lt;li&gt;IoT Core를 사용하면서 프로토콜이 제한적인 HTTP 프로토콜 통신을 걷어내고 대용량의 데이터를 전송하기 적합한 MQTT 프로토콜 통신을 사용할 수 있습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;전사에서 Kafka를 사용하는 분위기에 발맞추어, 데이터 스트리밍 플랫폼의 최강자인 Kafka를 사용하자
    &lt;ul&gt;
      &lt;li&gt;모비딕 팀뿐만 아니라 전사에서 Kafka를 도입하고자 하는 준비 과정이 있었고, Kafka에 대한 사내 지식이 쌓여가고 공유하고 있었기 때문에 이 또한 좋은 기회라고 생각했습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;하나로 통합되어 있던 토픽을 관심 분류에 따라 여러 토픽으로 나누어 사용하자
    &lt;ul&gt;
      &lt;li&gt;기존 파이프라인에서는 차량에서 수집한 정보를 저장되는 데에 하나의 토픽을 사용하고 있었습니다. 이 때문에 스트림 내의 차량 수집 정보를 특정 프로젝트 내에서 사용하기 위해서는 프로젝트에 불필요한 정보도 일단 모두 읽어야 하는 문제가 있었습니다. 이러한 비효율을 제거하고자, 단말 수집 정보의 토픽을 관심사별로 분리하고자 했습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;시스템 부하가 일으키는 장애에 대한 걱정 없이 신규 서비스를 개발하자
    &lt;ul&gt;
      &lt;li&gt;Kinesis 파이프라인에서 Throttling이 지속적으로 발생하면서 Kinesis와 연결하여 사용하려던 신규 서비스를 투입하는 것도 굉장히 부담스러워졌습니다. 이를 극복하면서 신규 서비스 개발에도 데이터 스트림이 걸림돌이 되지 않았으면 했습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;MSK를 사용하여, 운영 리소스를 최소화하자
    &lt;ul&gt;
      &lt;li&gt;우리의 리소스를 고려한다면 Kafka 운영을 위한 리소스가 추가 투입되는 것도 부담스러운 요소 중 하나였습니다. AWS에서 완전 관리형 Kafka 서비스인 MSK를 제공하고 있습니다. MSK 덕분에 Kafka를 직접 사용하면서 운영 리소스를 최소화하며 빠르게 요구사항을 충족할 수 있겠다고 생각했습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;데이터 파이프라인의 토픽, 파티션 등의 세부 설정을 우리가 직접 하여 상황에 맞게 사용할 수 있도록 하자&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이런 목표들을 가지고 설계한 파이프라인을 통해 차량에서 수집한 정보를 보고받고, MSK의 토픽에 정보가 담긴 메시지를 전달하며, 각각의 Consumer가 MSK에 붙어 필요한 데이터들을 가져갈 수 있는 기존보다 안정적인 새로운 파이프라인을 구성하기로 했습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/iot-pipeline-2/pipeline-next.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이제 본격적으로 파이프라인을 구현해볼까요?&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;본격적으로-신규-단말-파이프라인을-구축해봅시다-&quot;&gt;본격적으로 신규 단말 파이프라인을 구축해봅시다 &lt;a name=&quot;build&quot;&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;쏘카의 신규 단말 파이프라인은 크게 토픽을 관리하며 메시지를 저장하는 Kafka 클러스터와 메시지를 생산하는 Producer, 메시지를 소비하는 Consumer 세 가지로 구성됩니다.&lt;/p&gt;

&lt;h3 id=&quot;kafka-클러스터&quot;&gt;Kafka 클러스터&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/img/iot-pipeline-2/create-msk-cluster.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Kafka 클러스터는 AWS MSK를 통해 쉽게 구축할 수 있었습니다. 사용하고자 하는 인스턴스와 브로커 당 용량 및 Kafka의 버전, 보안 설정만 거치면 쉽게 클러스터를 구축할 수 있습니다.&lt;/p&gt;

&lt;p&gt;주의할 점은 생성 후 클러스터의 설정 변경에 제약이 있다는 점입니다. 예를 들어 인스턴스의 타입은 자유롭게 Up &amp;amp; Down이 가능하나, 브로커의 수량과 브로커의 용량은 증설만 가능합니다. (이 부분을 놓쳐 초기에 클러스터를 여러 번 새로 만드는 고생하기도 했습니다)&lt;/p&gt;

&lt;p&gt;스토리지의 경우 그동안 기존 파이프라인을 운영했던 데이터에 기반하여 최대 피크 수준도 버틸 수 있도록 설정했습니다. 이를 넘어서서 스토리지가 꽉 차게 되면 메시지가 유실되는 문제가 발생합니다. 이런 문제를 겪지 않도록 MSK에서는 스토리지 오토스케일링 기능을 제공합니다. 전체 용량의 10~80%에 도달하면 Auto Scaling이 되도록 설정이 가능합니다. 다만 안타깝게도 오토 스케일링도 스케일링 업만 가능하며 다운은 불가능하다는 점 유의하셔야 합니다.&lt;/p&gt;

&lt;p&gt;마지막으로 Cluster Configuration을 통해 Kafka 클러스터 설정을 할 수 있습니다. Kafka는 스트리밍 데이터 처리 플랫폼으로 데이터를 영구 저장할 수도 있지만 보통은 메시지의 저장 기간을 정해놓고 사용합니다. 장애가 발생해도 2일 이내에 해결하겠다는 마음으로 48시간(2일)로 설정했습니다. 이외 자세한 설정값들은 &lt;a href=&quot;https://kafka.apache.org/documentation/&quot;&gt;Kafka 문서&lt;/a&gt;를 참고해주세요.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;s&quot;&gt;log.cleanup.policy&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;delete&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;log.retention.hours&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;48&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이렇게 기본적인 클러스터 설정이 끝나면 수분 내에 Kafka 클러스터가 생성됩니다. 이제 메시지를 위한 토픽을 만들어주어야겠죠. 로컬 머신에 MSK와 같은 버전(권장)의 Kafka를 다운로드하시면 기본적으로 제공하는 CLI를 이용하여 토픽을 생성할 수 있습니다. (또는 원하는 언어의 Kafka 클라이언트를 통해서도 생성할 수 있어요!)&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/bin/kafka-topics.sh --create \
    --zookeeper &amp;lt;주키퍼 호스트&amp;gt;:&amp;lt;주키퍼 포트&amp;gt; \
    --topic &amp;lt;토픽 이름&amp;gt; \
    --partitions &amp;lt;파티션 수&amp;gt; \
    --replication-factor &amp;lt;복제 팩터&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;참고로 &lt;code class=&quot;highlighter-rouge&quot;&gt;auto.create.topics.enable&lt;/code&gt; 설정을 켜두면 자동으로 토픽을 생성하게 할 수 있습니다. 저희는 무분별하게 토픽이 생성되는 것을 막고자 이 방식은 사용하지 않았습니다.&lt;/p&gt;

&lt;p&gt;토픽 생성 시에는 토픽 이름, 파티션의 개수, 복제 팩터를 설정하게 됩니다.&lt;/p&gt;

&lt;p&gt;Kafka는 토픽에 메시지를 저장할 때 파일 시스템을 사용하기 때문에, 파티션을 하나로 지정하면 브로커의 I/O에 따라 성능이 좌지우지됩니다. 따라서 클러스터의 브로커 수, 데이터의 크기, Consumer의 수 같은 요소를 적절하게 고려하여 파티션의 수량을 정해야 합니다.&lt;/p&gt;

&lt;p&gt;복제 팩터는 중요한 설정 중 하나로, 하나의 파티션이 몇 개까지 복제될지를 설정하는 수치입니다. MSK는 중요 보안 업데이트나 설정 변경 시에 브로커를 한 대씩 차례차례 재부팅합니다. 이때 복제 팩터가 1인 경우 해당 파티션이 있는 브로커가 업데이트 등으로 인해 잠시 OFF되어 있을 때 Producer가 해당 파티션에 데이터를 쓰려고 하면 데이터 유실이 발생할 수 있습니다. 이러한 문제 없이 운영하기 위해서는 복제 팩터를 최소 2 이상으로 설정해 주셔야 합니다. 2 이상으로 설정한 경우, 기존 파티션 Leader를 가지고 있던 브로커가 OFF 되어도 복제본을 갖고 있던 다른 브로커가 파티션 Leader를 넘겨받아 Kafka 클러스터가 다운타임 없이 정상적으로 역할을 수행해냅니다.&lt;/p&gt;

&lt;h3 id=&quot;producer&quot;&gt;Producer&lt;/h3&gt;
&lt;p&gt;Kafka 클러스터가 준비되었으니, 메시지를 생산할 Producer를 설정해 보겠습니다. 엄밀히 말하면 단말에서 차량 정보를 수집하여 전달하는 부분을 Producer라고 볼 수도 있겠지만, 여기서는 Kafka 클러스터를 기준으로 하여, Kafka에 메시지를 생성하는 부분을 Producer의 역할로 정의하겠습니다.&lt;/p&gt;

&lt;p&gt;위에서 말씀드린 것처럼, &lt;strong&gt;단말의 펌웨어는 Server-side Application처럼 어느 시점에 한 번에 업데이트하기 어렵습니다&lt;/strong&gt;. 빨라도 몇 주에서 오래 걸리면 몇 달은 길게 두고 보아야 하는 작업입니다. 이렇게 짧지 않은 기간동안 보고 채널이 파편화되어 있는 동안에도 파이프라인에는 펌웨어 구분 없이 모든 차량에서 수집한 정보가 적재되어야 했습니다. 그렇게 하기 위해 IoT Core의 메시지 생성과 텔레매틱스 서버의 메시지 생성을 모두 구현하게 되었습니다.&lt;/p&gt;

&lt;h4 id=&quot;iot-core의-메시지-생성&quot;&gt;IoT Core의 메시지 생성&lt;/h4&gt;
&lt;p&gt;먼저 신규 펌웨어에서 IoT Core로 차량에서 수집한 정보를 전달하는 경우를 살펴보겠습니다. 단말에서는 차량 정보를 수집하여 IoT Core의 특정 토픽에 보고합니다. 그리고 IoT Core Rule을 만들어 이 정보를 구독할 수 있습니다. 예를 들어 단말은 &lt;code class=&quot;highlighter-rouge&quot;&gt;report&lt;/code&gt;라는 토픽에 차량 정보를 보고하고, IoT Core Rule에 &lt;code class=&quot;highlighter-rouge&quot;&gt;report&lt;/code&gt; 토픽을 구독하도록 Rule을 생성했다면, 새로운 차량 정보 메시지가 보고될 때마다 Rule에 설정된 작업이 실행됩니다.&lt;/p&gt;

&lt;p&gt;IoT Core Rule에 대해 자세히 알아볼까요? IoT Core Rule은 익숙한 SQL 쿼리(정확히는 AWS IoT Core SQL)를 통해 입맛에 맞게 단말에서 보고한 데이터를 가공할 수 있으며, 다른 데이터 시스템으로 전달하는 역할을 수행합니다. 신규 단말 파이프라인에서는 단말에서 JSON 형식의 메시지를 전달받고, 여기에 SQL을 이용하여 Timestamp를 추가해 사용합니다. 이를 위해 다음과 같은 쿼리문을 사용합니다.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parse_time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;&quot;yyyy-MM-dd'T'HH:mm:ssz&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;timestamp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;timestamp&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'report'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;AWS IoT Core SQL에서 지원하는 SQL 구문은 일반적인 SQL 구문과 비슷하지만 다를 수 있으니, 자세한 내용은 AWS에서 제공하는 &lt;a href=&quot;https://docs.aws.amazon.com/iot/latest/developerguide/iot-sql-reference.html&quot;&gt;AWS IoT Core SQL 레퍼런스&lt;/a&gt;를 참고하시기 바랍니다. IoT Core SQL의 특별한 점을 꼽자면, 무려 Lambda 함수를 실행할 수 있는 Function까지 지원해 원하는 대로 데이터 가공이 가능합니다.&lt;/p&gt;

&lt;p&gt;이렇게 원하는 대로 가공을 마쳤다면, 이 데이터를 다른 데이터 시스템으로 전달하기 위해 여러 개의 작업을 설정할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/iot-pipeline-2/worker-list.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;작업에는 미리 정의된 약 20개의 템플릿이 있으며, HTTPS 엔드포인트로도 전송할 수 있는 작업까지 준비되어 있어 원하는 대로 커스텀이 가능합니다. 이제 Kafka에 메시지를 전송할 수 있도록 작업을 추가해 보겠습니다.&lt;/p&gt;

&lt;p&gt;Apache Kafka 클러스터에 메시지 전송을 선택한 후 구성을 누르면, Kafka의 구성 정보를 입력하여 세팅할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/iot-pipeline-2/create-kafka-sink-worker.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;먼저 기본적인 Kafka 정보(Kafka 엔드포인트, SASL 구성 등)를 설정해 주세요.
Kafka에서 어떤 토픽에 메시지를 저장할 것인지 토픽 이름을 지정해야 합니다. 저희는 여기서 하나의 토픽에만 메시지를 전달하는 것이 아니라, 차량에서 수집된 정보의 종류에 따라 다른 토픽에 메시지를 전달하고 싶었습니다. 이런 처리를 위해서는 &lt;a href=&quot;https://docs.aws.amazon.com/ko_kr/iot/latest/developerguide/iot-substitution-templates.html&quot;&gt;대체 템플릿&lt;/a&gt;을 사용할 수 있습니다.&lt;/p&gt;

&lt;p&gt;대체 템플릿은 치환자라고 생각하시면 됩니다. IoT SQL 레퍼런스에서 지원하는 SELECT 절, WHERE 절 또는 Function을 사용할 수 있습니다. 쏘카 단말에서 보고하는 정보 중에는 해당 정보의 종류를 나타내는 타입이 존재합니다. 이 타입 별로 토픽을 분리하기 위해, 토픽 이름을 &lt;code class=&quot;highlighter-rouge&quot;&gt;message-${type}&lt;/code&gt; 으로 지정하였습니다. 이렇게 설정하면 log 타입의 메시지는 &lt;code class=&quot;highlighter-rouge&quot;&gt;message-log&lt;/code&gt;에, boot 타입의 메시지는 &lt;code class=&quot;highlighter-rouge&quot;&gt;message-boot&lt;/code&gt;에 저장하게 됩니다. 토픽이 자동 생성되는 옵션을 켜지 않으신 경우 꼭 미리 각 type에 대한 토픽을 먼저 생성하셔야 한다는 점 잊지 말아 주세요!&lt;/p&gt;

&lt;p&gt;다음은 파티션 설정입니다. 파티션은 파티션 번호를 직접 지정할 수도 있고, 지정하지 않으면 Kafka의 &lt;code class=&quot;highlighter-rouge&quot;&gt;DefaultPartitioner&lt;/code&gt;에 따라 파티션이 선택되어 메시지가 분배되게 됩니다. 여기에서 카프카의 중요한 특징을 하나 알고 가셔야 하는데, 파티션이 2개 이상인 토픽 내 메시지는 시간 순서가 지켜지지 않는다는 점입니다. 다만 파티션 내에서는 시간 순서가 지켜집니다. 쏘카에서는 각각의 프로젝트에서 실시간으로 데이터를 사용하게 될 때, 최소한 단말기 별로라도 메시지의 시간 순서가 꼭 지켜져야 합니다. 같은 단말의 메시지들이 다른 파티션에 저장되어 시간 순서대로 메시지를 사용할 수 없다면 실시간 처리가 사실상 불가능하게 됩니다. 대체 템플릿을 이용하여 메시지의 Key를 단말 번호인 &lt;code class=&quot;highlighter-rouge&quot;&gt;${device_no}&lt;/code&gt;로 지정하여 같은 단말의 메시지는 같은 파티션에 생성될 수 있도록 설정하여 이와 같은 문제를 해결할 수 있었습니다.&lt;/p&gt;

&lt;p&gt;(참고로, Kafka의 &lt;code class=&quot;highlighter-rouge&quot;&gt;DefaultPartitioner&lt;/code&gt;는 Key 값이 Null인 경우 해당 토픽의 파티션에 Round Robin 방식으로 분배하며, Key 값이 Null이 아닌 경우 Key 값을 해시화하여 파티션을 선택해 분배합니다)&lt;/p&gt;

&lt;p&gt;이렇게 메시지를 IoT Core에서 Kafka 토픽으로 무사히 전달했습니다!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/iot-pipeline-2/pipeline-next-msk.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;텔레매틱스-서버의-메시지-생성&quot;&gt;텔레매틱스 서버의 메시지 생성&lt;/h4&gt;
&lt;p&gt;기존에 차량과 통신할 때에는 총 두 채널로 통신했습니다. 명령 전달은 MQTT로 하고, 명령에 대한 응답 보고 혹은 상태 보고들을 텔레매틱스 서버로 HTTPS 방식의 보고를 하고 있었습니다. 이때, 신규 STS 단말기의 데이터 형태와 구형 단말기(CSA 단말기)의 형태가 달라 데이터를 호환시켜주는 모듈을 거쳐 동일하게 데이터가 쏘카 데이터베이스에 적재될 수 있도록 하는 일련의 과정들을 거칩니다.&lt;/p&gt;

&lt;p&gt;텔레매틱스 서버가 AWS IoT Core로 전환이 된다면, HTTPS로 텔레매틱스 서버에 상태 데이터를 전달하고 쏘카 데이터베이스에 적재되는 일련의 과정들이 생략됩니다. 기존의 연구나 분석에 사용하고 있던 데이터의 형태가 달라질 수 있기 때문에 기존에 보내고 있는 데이터의 형태와 호환성을 잘 가져갈 수 있도록 하는 것을 우선적인 목표로 잡았습니다.&lt;/p&gt;

&lt;p&gt;첫 번째로, 텔레매틱스 서버로 차량이 상태를 보고 하게 되면, 차량의 정보와 상태가 담긴 데이터가 Kinesis와 Kafka로 동시에 보내도록 작업을 했습니다. Kafka는 데이터를 전송할 때 여러 개의 토픽으로 나누어 데이터를 전송할 수 있습니다. 그 기능을 활용해 차량에서 올라오는 데이터들을 GPS, Kinematic, ADAS와 차량 주기 보고 데이터 등 각각 다른 토픽에 전송했습니다. 이로써 차량 데이터가 쏘카 데이터베이스에 저장됨은 물론, 프로젝트별로 데이터를 가져갈 때 실시간 데이터를 원하는 정보만, 원하는 토픽만을 가져와서 쉽게 처리할 수 있게 되었습니다.&lt;/p&gt;

&lt;p&gt;Kafka로 데이터를 보내기 위해 작업하는 도중, 서버 앞단의 트래픽을 보조하기 위해 사용한 uWSGI 모듈과 Python에서 Kafka를 사용할 수 있게 해 주는 kafka-python 모듈 간에 서로 충돌이 생겨서 첫 테스트에는 많은 어려움을 겪었습니다. 결국 uWSGI을 gunicorn으로 대체하고, Kafka 라이브러리도 kafka-python 대신 AWS가 제공하는 라이브러리인 boto3로 대체했습니다.&lt;/p&gt;

&lt;p&gt;두 번째로, IoT Core에서 전송된 데이터를 판별하여 데이터베이스에 적재할 수 있도록 고민이 필요했습니다. 단말기가 IoT Core로 보고하고 데이터가 바로 Kafka로 전송이 된다면, 데이터베이스에 데이터를 저장해 주는 역할을 하는 텔레매틱스 서버를 거치지 않기 때문에 차량 정보에 대해 저장이 어렵게 됩니다. 이를 위해 AWS IoT Core에 Rule을 추가해 주어 IoT Core의 데이터가 바로 Kafka로 전송되지 않고, 텔레매틱스 서버를 한번 거쳐서 Kafka로 전송할 수 있도록 해주었습니다. 텔레매틱스 서버에서 IoT Core에 대한 새로운 엔드포인트를 만들고, 해당하는 엔드포인트에서 데이터를 받아온 후 판별하여 Kafka 토픽별로 전송했습니다.&lt;/p&gt;

&lt;p&gt;IoT Core를 도입하면서 텔레매틱스 서버의 역할을 점차 줄여나가고, 결국에는 텔레매틱스 서버의 역할을 Kakfa와 연결된 Consumer 들에서 처리할 수 있도록 기능들을 점차 옮기려고 합니다. 현재는 여러 차량들을 놓고 테스트해 보고 있습니다. IoT Core를 적용 한 차량이 기존 차량과 동일하게 큰 어려움 없이 차량 데이터를 보내주고 있습니다. 아직은 초기지만, 많은 차량들이 점차 업데이트가 되어서 IoT Core로 데이터를 보낼 수 있게 되는 날이 벌써 기대가 됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/iot-pipeline-2/pipeline-prev-msk.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;consumer&quot;&gt;Consumer&lt;/h3&gt;
&lt;p&gt;이제 수집된 차량 정보가 Kafka 토픽에 안전하게 저장되어 있습니다. 이 데이터를 적재적소에 가져다가 활용하면 됩니다.
하지만 카프카는 영구 저장소가 아니라서, 우리가 설정한 값에 따르면 2일 후에 사라지게 됩니다. 먼저 이를 더 오랫동안 보관하고 활용할 수 있는 공간으로 먼저 저장해야 합니다. 이런 툴을 일일이 개발해야 할까요?&lt;/p&gt;

&lt;h4 id=&quot;kafka-connect&quot;&gt;Kafka Connect&lt;/h4&gt;
&lt;p&gt;물론 자신 있는 언어의 Kafka 클라이언트를 이용하여 Consumer를 한 땀 한 땀 개발할 수도 있겠지만, Kafka 생태계에서는 Kafka와 다른 데이터 시스템 사이를 쉽고 믿을 수 있게 이어줄 수 있는 Kafka Connect를 제공합니다.&lt;/p&gt;

&lt;p&gt;많은 회사와 개발자들이 사용하는 RDBMS부터 NoSQL, S3 같은 클라우드 저장소, Elasticsearch 등 수많은 데이터 시스템과 카프카를 이어주는 Connector를 공식적으로 제공하고 있으며, 커뮤니티에서 만든 비공식의 Connector들도 활발하게 만들어져 있어 Kafka Connect 클러스터만 구축한다면 Connector들을 바로 사용할 수 있습니다.&lt;/p&gt;

&lt;p&gt;다른 데이터 시스템에서 Kafka로 데이터를 가져오는 커넥터를 Source Connector라 하고, Kafka에서 다른 데이터 시스템으로 데이터를 적재하는 커넥터를 Sink Connector라고 합니다. 우리는 Kafka에 있는 데이터를 소비하는 Consumer를 만드는 과정이므로 Sink Connector를 설정해보겠습니다.&lt;/p&gt;

&lt;p&gt;쏘카의 단말 데이터는 오래 저장하고 다시 여러 가지 용도로 사용할 수 있도록 1차적으로 S3에 저장하고 있으며, 최신 데이터는 바로 분석과 연구에 사용할 수 있도록 Elasticsearch에 적재해 활용하고 있습니다.&lt;/p&gt;

&lt;p&gt;Kafka Connect 클러스터는 구축되어 있다고 가정하고, 바로 Sink Connector를 설정해보겠습니다. Kafka Connect에서는 Connector를 실행시킬 수 있는 REST API를 제공합니다. S3와 Elasticsearch Sink Connector를 세팅하면서 자세히 알아보도록 하겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/iot-pipeline-2/pipeline-next-kafkaconnect.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;s3-sink-connector&quot;&gt;S3 Sink Connector&lt;/h5&gt;
&lt;p&gt;Confluent에서 공식으로 제공하는 S3 Sink Connector입니다.
다음 요청을 통해 해당 커넥터를 이용한 Worker를 생성할 수 있습니다.&lt;/p&gt;

&lt;p&gt;Endpoint : &lt;code class=&quot;highlighter-rouge&quot;&gt;POST ${카프카_커넥트_호스트}/connectors&lt;/code&gt;&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{
    &quot;name&quot;:&quot;s3-sink-worker&quot;,
    &quot;config&quot;: {
        // 사용하려는 커넥터의 클래스 이름
        &quot;connector.class&quot;: &quot;io.confluent.connect.s3.S3SinkConnector&quot;,

        // S3가 위치한 리전
        &quot;s3.region&quot;: &quot;ap-northeast-2&quot;,

        &quot;partition.duration.ms&quot;: &quot;180000&quot;,
        
        // 여기서 지정한 수만큼 메시지가 쌓이면 S3에 파일로 저장합니다.
        &quot;flush.size&quot;: &quot;20000&quot;,
        
        &quot;schema.compatibility&quot;: &quot;NONE&quot;,
        
        // 메시지를 가져오려는 카프카의 토픽 이름을 지정합니다. 콤마를 사용해 여러 토픽을 가져올 수 있습니다.
        &quot;topics&quot;: &quot;토픽 이름&quot;,
        
        // 하나의 파일이 가질 최대 용량을 지정합니다.
        &quot;s3.part.size&quot;: &quot;5242880&quot;,
        
        // 타임존을 지정합니다.
        &quot;timezone&quot;: &quot;Asia/Seoul&quot;,
        
        // 로케일을 지정합니다.
        &quot;locale&quot;: &quot;ko_KR&quot;,
        
        // 압축 방식을 지정합니다. none 또는 gzip을 사용할 수 있습니다.
        &quot;s3.compression.type&quot;: &quot;gzip&quot;,
        
        // 데이터 포맷을 지정힙니다. JSON 타입이므로 JsonFormat을 사용합니다.
        &quot;format.class&quot;: &quot;io.confluent.connect.s3.format.json.JsonFormat&quot;,
        
        // 메시지를 어떻게 파티셔닝할지 설정합니다. 여기서는 TimeBasedPartitioner를 사용하여 날짜 기준으로 S3에 저장되는 폴더를 분리합니다.
        &quot;partitioner.class&quot;: &quot;io.confluent.connect.storage.partitioner.TimeBasedPartitioner&quot;,
        
        // S3Storage로 지정해주시면 됩니다.
        &quot;storage.class&quot;: &quot;io.confluent.connect.s3.storage.S3Storage&quot;,
        
        // 저장될 S3의 버킷 이름입니다.
        &quot;s3.bucket.name&quot;: &quot;S3 버킷 이름&quot;,
        
        // 얼마나 주기적으로 S3에 파일을 저장할지 설정합니다. flush.size에서 설정한 메시지 수에 도달하지 않아도 해당 주기가 되면 S3에 파일을 쓰게 됩니다.
        &quot;rotate.schedule.interval.ms&quot;: &quot;180000&quot;,
        
        // 파일이 저장될 위치를 설정합니다. 시간 기반의 파티셔닝을 통해 시간별로 폴더가 나눠지도록 설정했습니다.
        &quot;path.format&quot;: &quot;YYYY/MM/dd/HH&quot;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Worker를 생성한 후, 다음 REST API를 통해 Worker가 제대로 동작하는지 확인하실 수 있습니다.&lt;/p&gt;

&lt;p&gt;Endpoint : &lt;code class=&quot;highlighter-rouge&quot;&gt;${카프카_커넥트_호스트}/connectors?expand=info&amp;amp;expand=status&lt;/code&gt;&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{
  &quot;s3-sink-worker&quot;: {
    &quot;status&quot;: {
      &quot;name&quot;: &quot;s3-sink-worker&quot;,
      &quot;connector&quot;: {
        &quot;state&quot;: &quot;RUNNING&quot;,
        &quot;worker_id&quot;: &quot;Worker 1&quot;
      },
      &quot;tasks&quot;: [
        {
          &quot;id&quot;: 0,
          &quot;state&quot;: &quot;RUNNING&quot;,
          &quot;worker_id&quot;: &quot;Worker 1&quot;
        },
        {
          &quot;id&quot;: 1,
          &quot;state&quot;: &quot;RUNNING&quot;,
          &quot;worker_id&quot;: &quot;Worker 2&quot;
        },
        {
          &quot;id&quot;: 2,
          &quot;state&quot;: &quot;RUNNING&quot;,
          &quot;worker_id&quot;: &quot;Worker 3&quot;
        }
      ],
      &quot;type&quot;: &quot;sink&quot;
    },
    &quot;info&quot;: {
      &quot;name&quot;: &quot;s3-sink-worker&quot;,
      &quot;config&quot;: {
        &quot;connector.class&quot;: &quot;io.confluent.connect.s3.S3SinkConnector&quot;,
        &quot;s3.region&quot;: &quot;ap-northeast-2&quot;,
        &quot;partition.duration.ms&quot;: &quot;180000&quot;,
        &quot;flush.size&quot;: &quot;20000&quot;,
        &quot;schema.compatibility&quot;: &quot;NONE&quot;,
        &quot;topics&quot;: &quot;토픽 이름&quot;,
        &quot;s3.part.size&quot;: &quot;5242880&quot;,
        &quot;timezone&quot;: &quot;Asia/Seoul&quot;,
        &quot;locale&quot;: &quot;ko_KR&quot;,
        &quot;s3.compression.type&quot;: &quot;gzip&quot;,
        &quot;format.class&quot;: &quot;io.confluent.connect.s3.format.json.JsonFormat&quot;,
        &quot;partitioner.class&quot;: &quot;io.confluent.connect.storage.partitioner.TimeBasedPartitioner&quot;,
        &quot;storage.class&quot;: &quot;io.confluent.connect.s3.storage.S3Storage&quot;,
        &quot;s3.bucket.name&quot;: &quot;S3 버킷 이름&quot;,
        &quot;rotate.schedule.interval.ms&quot;: &quot;180000&quot;,
        &quot;path.format&quot;: &quot;YYYY/MM/dd/HH&quot;
      },
      &quot;tasks&quot;: [
        {
          &quot;connector&quot;: &quot;s3-sink-worker&quot;,
          &quot;task&quot;: 0
        },
        {
          &quot;connector&quot;: &quot;s3-sink-worker&quot;,
          &quot;task&quot;: 1
        },
        {
          &quot;connector&quot;: &quot;s3-sink-worker&quot;,
          &quot;task&quot;: 2
        }
      ],
      &quot;type&quot;: &quot;sink&quot;
    }
  },
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;다른 문제가 없다면 수 분 내로 S3의 파일로 메시지가 잘 적재되는 모습을 확인하실 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/iot-pipeline-2/result-s3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Kafka Connect의 Worker들은 동작하면서 필요한 메타데이터를 Kafka에 별도의 토픽으로 저장합니다. Worker는 자신의 업무 프로세스를 기억하기 위해 순차적으로 토픽의 파티션에서 데이터를 읽어가면서 책갈피를 꽂아둡니다. 이 책갈피를 Offset이라고 합니다. Kafka Connect는 프로세스가 죽어서 Worker가 재시작되는 상황이 발생해도 이 메타데이터를 다시 읽어와 책갈피를 꽂은 부분에서부터 다시 데이터를 읽어가도록 설계되어 있습니다.&lt;/p&gt;

&lt;h5 id=&quot;elasticsearch-sink-connector&quot;&gt;Elasticsearch Sink Connector&lt;/h5&gt;
&lt;p&gt;S3에 무사히 적재했다면, 다음은 분석과 연구를 위한 Elasticsearch에 적재해보겠습니다. Confluent에서 공식으로 제공하는 Elasticsearch Sink Connector를 사용합니다. S3 Sink Connector와 같은 방식으로 생성하는데, 다음과 같은 요청을 통해 Elasticsearch Sink Worker를 실행할 수 있습니다.&lt;/p&gt;

&lt;p&gt;Endpoint : &lt;code class=&quot;highlighter-rouge&quot;&gt;POST ${카프카_커넥트_호스트}/connectors&lt;/code&gt;&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{
  &quot;name&quot;:&quot;es-sink-worker&quot;,
  &quot;config&quot;: {
    // 사용하려는 커넥터의 클래스 이름
    &quot;connector.class&quot;: &quot;io.confluent.connect.elasticsearch.ElasticsearchSinkConnector&quot;,
    
    // Elasticsearch7부터는 type이 사라져, _doc로 지정하면 됩니다.
    &quot;type.name&quot;: &quot;_doc&quot;,
    
    &quot;behavior.on.null.values&quot;: &quot;IGNORE&quot;,
    
    // 메시지를 가져오려는 토픽 이름
    &quot;topics&quot;: &quot;토픽 이름&quot;,
    
    // true일 때, 메시지에 문제가 있는 경우 무시합니다.
    &quot;drop.invalid.message&quot;: &quot;true&quot;,
    
    // 문제가 생긴 경우 최대 재시도 횟수를 설정합니다.
    &quot;max.retries&quot;: &quot;50&quot;,
    
    // true일 때, Elasticsearch 문서의 키로 메시지의 key를 사용하지 않고, topic+partition+offset를 사용합니다. ex) message-log+0+1
    &quot;key.ignore&quot;: &quot;true&quot;,
    
    // Elasticsearch 동시 요청 수를 제한합니다. retry.backoff.ms: 요청 실패 후 재시도까지 기다릴 시간을 설정합니다. 다음 재시도할 때엔 이전 재시도 대기 시간보다 2배 더 기다립니다.
    &quot;max.in.flight.requests&quot;: &quot;20&quot;,
    
    &quot;retry.backoff.ms&quot;: &quot;2000&quot;,
    
    // 사용하려는 Elasticsearch의 Endpoint
    &quot;connection.url&quot;: &quot;ELASTICSEARCH_ENDPOINT&quot;,
    
    // Elasticsearch 서버와의 Read Timeout을 설정합니다.
    &quot;read.timeout.ms&quot;: &quot;60000&quot;,
    
    // 주어진 시간만큼 데이터가 쌓이기를 기다린 다음, Bulk Request로 처리하여 효율성을 높입니다. connection.compression: Elasticsearch 서버와 통신 시에 gzip 압축을 사용할지 여부를 선택합니다.
    &quot;linger.ms&quot;: &quot;1000&quot;,
    &quot;connection.compression&quot;: &quot;true&quot;,
    
    // 메시지가 원하는 만큼 쌓이지 않았더라도, 해당 주기가 되면 Elasticsearch로 메시지를 전송합니다.
    &quot;flush.timeout.ms&quot;: &quot;60000&quot;,
    
    // 배치로 처리할 메시지의 수
    &quot;batch.size&quot;: &quot;2000&quot;,
    
    // 최대 버퍼 될 레코드의 수, 태스크 당 메모리 사용량 제한을 위해 사용합니다.
    &quot;max.buffered.records&quot;: &quot;40000&quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;S3 커넥터 설정할 때와 마찬가지로 REST API를 통해 Worker가 정상적으로 동작하고 있는지를 확인해 주세요. 잠시만 기다리면 Elasticsearch에도 메시지가 잘 적재되는 것을 확인하실 수 있습니다!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/iot-pipeline-2/result-es.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Elasticsearch Sink Connector에는 알려진 버그가 있습니다. 쏘카에서는 최신의 단말 데이터만 Elasticsearch에서 활용하고 있어서 일자별로 인덱스를 생성하고, 며칠 뒤 오래된 인덱스를 삭제하는 형식을 취하고 있습니다. Elasticsearch Sink Connector는 &lt;code class=&quot;highlighter-rouge&quot;&gt;TimebasedPartitioner&lt;/code&gt;를 사용하면 Offset을 제대로 기록하지 못해 설정을 변경하는 등의 이유로 Worker를 재시작할 때마다 토픽에 있는 모든 데이터를 처음부터 다시 읽는 버그가 있습니다.&lt;/p&gt;

&lt;p&gt;이를 해결하기 위해, Elasticsearch Sink Connector를 사용할 때에는 &lt;code class=&quot;highlighter-rouge&quot;&gt;TimeBasedPartitioner&lt;/code&gt;를 사용하지 않고 Elasticsearch의 Index를 고정하여 사용하기로 했습니다. Elasticsearch에서 Index를 생성할 때 Write Index와 Rollover를 사용하여 Index가 일자별로 자동으로 생성되도록 데이터가 저장되도록 설정해 이 문제를 해결할 수 있었습니다.&lt;/p&gt;

&lt;h3 id=&quot;단말-차량-converter&quot;&gt;단말-차량 Converter&lt;/h3&gt;
&lt;p&gt;“단말-차량 Converter”는 모비딕 팀에서 최근에 시작한 프로젝트로, Kafka의 도입과 비슷한 시기에 시작한 프로젝트입니다. Kafka에서 수집하는 차량의 데이터는 거의 실시간으로 파악할 수 있기 때문에 이 데이터의 활용도가 무척 높을 거라고 생각했습니다.&lt;/p&gt;

&lt;p&gt;차량 데이터는 차량 단말기 번호를 기준으로 수집되는데, “단말-차량 Converter”는 이 데이터를 바로 사용할 수 있도록, 데이터를 변형하여 Kafka로 다시 흘려보내주는 역할을 합니다. 즉, “단말-차량 Converter”는 확장성이 높은 첫 Consumer이자 동시에 데이터를 제공해 주는 Producer 역할을 동시에 하게 됩니다. 이렇게 수집된 데이터는 원하는 곳에서, 필요한 만큼 실시간으로 확인할 수 있습니다.&lt;/p&gt;

&lt;p&gt;“단말-차량 Converter”의 기능을 구체적으로 말씀드리면, 단말기에서 올라온 정보를 기반으로 차량 정보를 매칭해 주고, 해당하는 데이터가 어떤 차량의 어떤 상태인지 파악할 수 있도록 데이터 조립을 해 줍니다. 차량의 정보를 데이터베이스에서 계속 가져온다면 너무 비효율적이기 때문에, 임시로 저장해 놓은 캐싱 된 데이터를 사용하고, 일정 주기로 데이터를 새로 받아오는 일들을 하고 있습니다.&lt;/p&gt;

&lt;p&gt;이렇게 조립한 데이터들이 앞으로 필요한 프로젝트들에 잘 활용될거라 기대하고 있습니다. 또한 어떤 프로젝트든 쉽게 데이터를 사용할 수 있게 데이터를 좀 더 유연하게 설계해나가고 싶습니다. 
추가적으로 필요한 연산 작업이라든지, 적재 작업들도 “단말-차량 Converter”를 통해 만들어나갈 수 있을 것 같고, 최근 뜨고 있는 스트림 처리 프레임워크인 Flink를 써 볼 수 있지 않을까 하는 기대감도 가지고 있습니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;단말-파이프라인-모니터링-&quot;&gt;단말 파이프라인 모니터링 &lt;a name=&quot;monitoring&quot;&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;구축한 단말 파이프라인이 문제 없이 원활히 흘러가도록 하려면 모니터링의 역할도 아주 중요합니다.&lt;/p&gt;

&lt;p&gt;쏘카에는 여러 모니터링 시스템이 구축되어 있는데, 그중 Grafana를 통해 단말 파이프라인 모니터링 대시보드를 구축했습니다. 데이터 소스로 CloudWatch가 이미 연동되어 있어, MSK의 중요한 메트릭으로 대시보드를 꾸리기만 하면 완성입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/iot-pipeline-2/monitoring.png&quot; alt=&quot;&quot; /&gt;
&lt;em&gt;운영 중인 Grafana 대시보드&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;CPU, Disk 사용량, 네트워크 In/Out, Elasticsearch의 스토리지 사용량을 기본적으로 모니터링하고 있으며, 각 Consumer의 OffsetLag까지 추가적으로 모니터링하여 각 Consumer에서 데이터를 가져가는 데에 지연이 발생하지 않는지를 모니터링하고 있습니다.&lt;/p&gt;

&lt;p&gt;OffsetLag가 무엇일까요? 각 Consumer에서는 토픽의 파티션 별로 메시지를 어디까지 가져갔는지를 기록하는 책갈피를 남겨놓는다고 했는데, 바로 Offset입니다. 파티션의 가장 마지막 메시지와 Offset의 차이가 OffsetLag입니다. OffsetLag가 줄어들지 않고 지속적으로 증가하는 경우 해당 Consumer가 제대로 동작하지 않는다고 판단할 수 있고, 이를 통하여 Consumer의 장애를 인지하고 장애에 대한 조치를 수행할 수 있습니다.&lt;/p&gt;

&lt;p&gt;(참고로 OffsetLag는 MSK의 고급 모니터링 옵션을 사용해야 모니터링이 가능합니다.)&lt;/p&gt;

&lt;p&gt;이렇게 단말 데이터 파이프라인을 모니터링할 수 있는 대시보드가 완성되었습니다! 필요한 메트릭에 알림을 만들어, 임계치에 도달한 경우 Slack 또는 Opsgenie를 통해 알림을 받아 장애를 인지하고, 조치하고 있습니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;마치며-&quot;&gt;마치며 &lt;a name=&quot;wrap-up&quot;&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;여전히 신규 데이터 파이프라인 개발은 현재진행형입니다. Schema Registry를 이용해 단말 데이터에 스키마를 입히고, 사내 많은 분들이 활발하게 사용 중인 BigQuery에 스트리밍으로 단말 데이터를 적재해야 하는 등 해야 할 일들이 많이 있습니다.&lt;br /&gt;
하지만 첫 술에 배부를 수 없듯이, 이번 목표는 토대를 단단하게 구축하여 어떤 서비스나 프로젝트에 찰떡처럼 붙을 수 있는 파이프라인을 만드는 것이었고, 결과적으로 짧은 시간 안에 소기의 성과를 달성할 수 있었습니다.&lt;/p&gt;

&lt;p&gt;이번에 개선한 신규 단말 파이프라인을 토대로 전사에서 단말 데이터를 더욱 잘 활용할 수 있도록 하고, 더 나아가 유저에게 더 나은 쏘카 서비스 경험을 선물할 수 있도록 앞으로도 모비딕 팀이 계속 노력하겠습니다.&lt;/p&gt;</content><author><name>bada, oliver</name></author><category term="mobility" /><category term="iot" /><category term="data" /><category term="data-engineering" /><summary type="html">Photo by SELİM ARDA ERYILMAZ on Unsplash</summary></entry><entry><title type="html">Android Studio 플러그인으로 코드 자동 리팩토링하기</title><link href="https://tech.socarcorp.kr/dev/2022/02/03/refactoring-with-intellij-plugin.html" rel="alternate" type="text/html" title="Android Studio 플러그인으로 코드 자동 리팩토링하기" /><published>2022-02-03T08:00:00+00:00</published><updated>2022-02-03T08:00:00+00:00</updated><id>https://tech.socarcorp.kr/dev/2022/02/03/refactoring-with-intellij-plugin</id><content type="html" xml:base="https://tech.socarcorp.kr/dev/2022/02/03/refactoring-with-intellij-plugin.html">&lt;p&gt;안녕하세요, 쏘카 안드로이드 팀의 지안입니다.&lt;/p&gt;

&lt;p&gt;리팩토링 작업은 한두 개의 함수를 개선하는 것으로 충분한 때도 있지만, 때로는 여러 개의 파일을 전체적으로 고치고 나서야 끝이 나는 경우도 있습니다.
복잡한 로직이 아닌 단순한 코드 수정 작업이라 생각하여 가볍게 시작하더라도, 리팩토링의 대상이 되는 코드가 곳곳에 사용되고 있다면 처음에 생각한 예상 시간보다 많은 시간이 걸려 난처해지는 경우도 생기곤 합니다.
또한 그 과정에서 처음에는 예상하지 못했던 특이한 케이스라던가, 수정 과정에서 실수로 빠트리는 부분, 반복되는 동일 작업으로 인한 집중력 하락 등으로 인해 일정이 밀리다 보면 ‘리팩토링을 시작하지 말았어야 했나?’ 하는 생각이 드는 경우도 있습니다.&lt;/p&gt;

&lt;p&gt;저희 안드로이드 팀에서도 몇 개월 전, 광범위한 코드에 대한 리팩토링을 수행한 경험이 있습니다.
코드 변환의 규칙은 단순했지만, 수십에서 수백 개 파일에 걸친 변경사항을 하나하나 고치려고 하다 보니 마냥 쉽지만은 않았습니다.
그리고 자칫 길어질 뻔했던 그 반복적인 작업은 IntelliJ Platform Plugin을 통해서 훨씬 수월해질 수 있었습니다.&lt;/p&gt;

&lt;p&gt;당시에 리팩토링 작업을 하며 내부 세미나를 통해 발표했던 내용을, 연말연시를 맞이하여 이 글을 통해 다시금 정리해서 공유해 보고자 합니다.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;리팩토링을-마음먹게-된-계기&quot;&gt;리팩토링을 마음먹게 된 계기&lt;/h2&gt;
&lt;h3 id=&quot;view-binding으로의-전환&quot;&gt;View Binding으로의 전환&lt;/h3&gt;
&lt;p&gt;안드로이드에서 View에 접근하는 방식은 &lt;a href=&quot;https://medium.com/mobile-app-development-publication/how-android-access-view-item-the-past-to-the-future-bb003ae84527&quot;&gt;계속해서 바뀌어&lt;/a&gt; 왔습니다.
이러한 변화 중에서 현재 가장 이슈가 되고 있는 것은 아무래도 Jetpack Compose의 &lt;a href=&quot;https://android-developers.googleblog.com/2021/07/jetpack-compose-announcement.html&quot;&gt;정식 출시&lt;/a&gt;겠지만, 이 글은 그보다 약간 이전에 있었던 사건에 관한 이야기입니다.&lt;/p&gt;

&lt;p&gt;2020년 말, Kotlin Synthetics 가 Kotlin Android Extensions와 함께 &lt;a href=&quot;https://github.com/JetBrains/kotlin/releases/tag/v1.4.20&quot;&gt;deprecated&lt;/a&gt; 되었습니다.
다행스럽게도 저희는 그 시점에 Kotlin Synthetics를 직접 사용하지 않고 &lt;a href=&quot;https://github.com/JakeWharton/butterknife&quot;&gt;ButterKnife&lt;/a&gt; 기반의 &lt;a href=&quot;https://github.com/Rajin9601/ButterKt&quot;&gt;ButterKt&lt;/a&gt;를 수정해서 활용하고 있었기 때문에 deprecation의 직접적인 영향 없이 Kotlin 버전을 업데이트할 수 있었습니다.
그러나 ButterKnife의 README 파일에도 적혀있듯이, View Binding을 사용하라는 권고는 늘 마음 한편과 기술 부채 목록에 남아있었죠.&lt;/p&gt;

&lt;p&gt;하기야 View에 대한 타입 추론도 잘해주고, 속도도 이전에 비해 빨라지고, View에 대한 구조적인 접근도 가능한 View Binding을 사용하는 것에 딱히 나쁜 점은 없었습니다.
더군다나 이렇게 &lt;a href=&quot;https://developer.android.com/topic/libraries/view-binding/migration&quot;&gt;Migration 가이드&lt;/a&gt;도 제공하고 있고요.&lt;/p&gt;

&lt;p&gt;가이드를 보면서 저희 코드를 기준으로 얼핏 생각해 보았을 때는 기존에 사용하던 아래와 같은 코드를&lt;/p&gt;
&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SomeActivity&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BaseActivity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;maybe_different_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;TextView&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;bindView&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;R&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;declared_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;someFunction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;..&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;maybe_different_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;이렇게 아래처럼 변경해 주기만 하면 될 것으로 보입니다.&lt;/p&gt;
&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ChangedActivity&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BaseActivity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;changedFunction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;..&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;binding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;declaredId&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;그러나 이렇게 가벼운 마음으로 작업을 하다 보면 이어지는 절에서 이야기할 번거로운 부분들이 보이기 시작합니다.
혹시 이런 번거로운 부분들을 해결해 줄 더 좋은 Migration 방법이 제공될까 싶어서 기다리다 보니, 어느새 이 작업의 우선순위는 다른 Feature들에 의해 계속해서 밀리게 되었습니다.&lt;/p&gt;

&lt;p&gt;하지만 역설적이게도 우선순위가 높은 Feature 화면의 개발 중에는 여전히 View의 타입이나 XML ID 매칭으로 인한 문제가 종종 발생해서 시간을 소비하곤 했습니다.
결국 이러한 문제로 인해 개발 시간이 불필요하게 늘어나고 있다는 의견에 도달하자 View Binding으로 전환하는 리팩토링을 본격적으로 시작하게 되었습니다.
다만, 무작정 작업에 돌입하기보다는 효율적인 방법에 대해서 생각해 볼 필요가 있었죠.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;리팩토링-검토&quot;&gt;리팩토링 검토&lt;/h2&gt;
&lt;h3 id=&quot;view-binding-전환에-필요한-것&quot;&gt;View Binding 전환에 필요한 것&lt;/h3&gt;
&lt;p&gt;위에서도 언급했다시피 View Binding으로 리팩토링하는 작업을 위해 요구사항을 정리하다 보면 처음에 가졌던 생각보다 번거로운 지점이 보여서 멈칫멈칫하게 되는 부분들이 있었습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;by bindView&lt;/code&gt; Delegate를 사용하는 변수들을 쓰고 있는 모든 Usage에 대해 이름 변경이 필요하다.&lt;/li&gt;
  &lt;li&gt;기존 방식과는 달리 앞에 &lt;code class=&quot;highlighter-rouge&quot;&gt;binding.&lt;/code&gt;을 붙여서 접근하도록 해야 한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;위의 요구사항만 놓고 보면 단순하게 Regex를 사용해서 치환해도 어떻게든 작업이 가능할 것 같다는 생각이 듭니다.&lt;/p&gt;

&lt;p&gt;그러나 요구사항 검토를 계속해서 진행하다가 아래와 같이 조금 더 까다로운 항목을 발견하게 되면 골치가 아파지기 시작합니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Kotlin 파일에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;bindView&lt;/code&gt;로 사용하고 있는 변수명의 케이스를 변경(&lt;code class=&quot;highlighter-rouge&quot;&gt;snake_case&lt;/code&gt; → &lt;code class=&quot;highlighter-rouge&quot;&gt;lowerCamelCase&lt;/code&gt;)해줘야 한다.&lt;/li&gt;
  &lt;li&gt;만약 XML에 있는 ID(&lt;code class=&quot;highlighter-rouge&quot;&gt;R.id.~&lt;/code&gt;)와 다른 변수명을 사용하고 있다면 XML의 ID를 사용하도록 변경해야 한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 시점에서 Regex를 이용한 ‘단순’ 치환은 어렵겠다는 생각이 듭니다.
그래도 Android Studio를 사용하고 있으니 IDE의 기능을 빌어서 &lt;code class=&quot;highlighter-rouge&quot;&gt;Refactoring → Rename&lt;/code&gt; 기능을 시도해 볼 수는 있을 것 같습니다.
변수 하나를 변경하는데 타이핑을 빠르게 하면 5~10초 정도 걸리는 것 같으니 나쁘지는 않아 보입니다.
하지만…&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Activity, Fragment, Custom View를 포함한 뷰 코드 파일들이 백 개가 넘고, 각각의 파일에는 XML ID와 연결되어 있는 변수가 수십 개 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이렇게 되면 하나하나 타이핑해가면서 수동으로 수정하기에는 부담스러운 분량입니다.
수정하는 과정에서 행여나 누락되는 곳이나 실수하는 곳이 있지는 않을지 걱정도 되고요.
단순한 작업이다 싶어서 시작한 일인데 이렇게까지 반복적인 작업을 오랜 시간에 걸쳐서 신경 써가며 작업해야 할까 싶은 생각이 듭니다.&lt;/p&gt;

&lt;p&gt;그렇게 해서 자동으로 Kotlin 코드를 파싱 하여 수정하는 방법들까지도 검토해 보게 되었습니다.&lt;/p&gt;

&lt;h3 id=&quot;사용해-볼-만한-방법들&quot;&gt;사용해 볼 만한 방법들&lt;/h3&gt;
&lt;p&gt;그런 생각을 거쳐서 아래에 있는 다섯 가지 정도의 방법을 떠올리고 간단하게 비교를 진행했습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Android Studio의 Rename 기능을 변수 하나하나에 적용해서 바꾸기&lt;/li&gt;
  &lt;li&gt;Regex를 사용해서 찾아 바꾸기&lt;/li&gt;
  &lt;li&gt;Kotlin Compiler의 &lt;a href=&quot;https://github.com/JetBrains/kotlin/tree/master/compiler/psi/src/org/jetbrains/kotlin/parsing&quot;&gt;Parsing&lt;/a&gt;을 사용하기&lt;/li&gt;
  &lt;li&gt;LSP와 &lt;a href=&quot;https://github.com/fwcd/kotlin-language-server&quot;&gt;비공식 Kotlin Language Server&lt;/a&gt;의 &lt;a href=&quot;https://github.com/fwcd/kotlin-language-server/pull/319&quot;&gt;Rename&lt;/a&gt;을 사용하기&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://plugins.jetbrains.com/docs/intellij/welcome.html&quot;&gt;IntelliJ Platform Plugin&lt;/a&gt;을 만들어서 동작시키기&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 중에서 Android Studio의 IDE 기능을 써서 Renaming 하는 방식은 신뢰도가 높고 추가적인 개발이 필요 없지만, 각각의 변수들을 하나하나 수정해야 하므로 작업에 걸리는 시간이 길어진다는 단점이 있었습니다.&lt;/p&gt;

&lt;p&gt;그리고 정규 표현식으로 찾아 바꾸는 작업은 여러 변수나 파일들을 한꺼번에 고칠 수는 있었지만, Reference(Usage)를 명확하게 구분해 내기가 어렵고 정규 표현식을 작성하는 것에도 시간이 많이 소요된다는 문제가 있었습니다.&lt;/p&gt;

&lt;p&gt;Kotlin Compiler를 써서 Parsing 하거나, LSP를 사용해서 수정하는 것은 해당 기능을 개발하기 위해 필요한 배경지식들이 과도하게 많이 필요했습니다.
전체 작업에 드는 시간을 고려하면 변수를 하나하나 바꾸는 데 걸리는 시간이 오히려 비슷하거나 빠를 수도 있겠다는 판단도 들었습니다.
또한 Kotlin Language Server는 아직 &lt;a href=&quot;https://discuss.kotlinlang.org/t/any-plan-for-supporting-language-server-protocol/2471&quot;&gt;공식적으로 제공되지 않고 있으며&lt;/a&gt;, 비공식 Language Server에서는 &lt;a href=&quot;https://github.com/fwcd/kotlin-language-server/pull/319&quot;&gt;Rename 기능에 문제&lt;/a&gt;가 있다는 이야기도 있어서 섣불리 시도해 보기도 어려웠고요.&lt;/p&gt;

&lt;p&gt;반면에 IntelliJ Platform Plugin은 기존에 IDE에서도 사용해왔던 기능들을 그대로 사용할 테니 Reference를 제대로 찾아서 변경해 주는 안정성이 확보되어 있다고 볼 수 있었습니다.
또한 이미 다양한 기능을 가진 플러그인들이 Plugin Marketplace에 올라와 있는 것을 보면 단지 이번 리팩토링뿐만 아니라 다른 기능을 추가해 볼 수도 있을 것이라는 생각도 들었습니다.
물론 개발에 들어가는 시간이 있겠지만 Kotlin Compiler나 LSP를 다루는 것보다는 빠르게 진행할 수 있으리라고 보았습니다.&lt;/p&gt;

&lt;p&gt;앞서 이야기한 몇몇 기준점을 가지고 각각의 방식을 간략하게 비교하면 아래의 표와 같이 정리할 수 있습니다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt; &lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;IntelliJ Rename&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Regex Replace&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Kotlin Parser&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Language Server&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;IntelliJ Plugin&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;대량 수정(자동화)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;X&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;O&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;O&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;O&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;strong&gt;O&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Usage 검색 기능&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;O&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;X&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;O&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;O&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;strong&gt;O&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;포매팅 유지&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;O&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;X&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;?&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;?&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;strong&gt;O&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;개발에 필요한 시간&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;없음&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;보통&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;많음&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;많음&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;보통&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;확장성&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;낮음&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;낮음&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;보통&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;보통&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;strong&gt;높음&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;이러한 비교를 바탕으로 개발 시간이 많이 필요하지 않으면서도 자동화가 가능한 IntelliJ Platform Plugin 방식을 선택했고, 이를 통해 View Binding으로의 리팩토링을 진행해 보기로 했습니다.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;intellij-platform-plugin&quot;&gt;IntelliJ Platform Plugin&lt;/h2&gt;
&lt;p&gt;그렇다고 하더라도 자료를 찾기 어렵다면 개발 시간이 길어질 것이므로 걱정했지만, 다행스럽게도 JetBrains에서는 공식적으로 IntelliJ Platform에서 사용 가능한 &lt;a href=&quot;https://lp.jetbrains.com/gradle-intellij-plugin/&quot;&gt;플러그인&lt;/a&gt; 개발에 대한 &lt;a href=&quot;https://plugins.jetbrains.com/docs/intellij/welcome.html&quot;&gt;문서&lt;/a&gt;를 제공하고 있었습니다.
이 문서의 &lt;a href=&quot;https://plugins.jetbrains.com/docs/intellij/getting-started.html&quot;&gt;Getting Started 페이지&lt;/a&gt;에 따르면 아래와 같은 방식으로 플러그인을 개발하는 것을 권장하고 있습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;There are three supported workflows available for building plugins. The &lt;strong&gt;recommended workflow&lt;/strong&gt; for new projects is to use &lt;a href=&quot;https://github.com/JetBrains/intellij-platform-plugin-template&quot;&gt;GitHub Template&lt;/a&gt; or to use &lt;a href=&quot;https://github.com/JetBrains/gradle-intellij-plugin&quot;&gt;Gradle&lt;/a&gt; to create everything from scratch. The old Plugin DevKit workflow still supports existing projects.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이렇게 나열된 방식 중에서 비교적 간단하게 개발할 수 있는 방식인 &lt;a href=&quot;https://github.com/JetBrains/intellij-platform-plugin-template&quot;&gt;GitHub Template&lt;/a&gt;를 통해 그 안에 있는 예제 플러그인 코드로부터 개발을 시작했습니다.&lt;/p&gt;

&lt;h3 id=&quot;예제-플러그인-동작-확인&quot;&gt;예제 플러그인 동작 확인&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/JetBrains/intellij-platform-plugin-template&quot;&gt;링크&lt;/a&gt;로부터 예제 템플릿 레포지토리를 클론 해와서 Android Studio로 열어보면 &lt;code class=&quot;highlighter-rouge&quot;&gt;Run Configurations&lt;/code&gt; 중에 &lt;code class=&quot;highlighter-rouge&quot;&gt;Run Plugin&lt;/code&gt;이라는 항목을 볼 수 있습니다.
그 항목을 선택하고 &lt;code class=&quot;highlighter-rouge&quot;&gt;Run&lt;/code&gt; 버튼을 눌러서 이를 실행시키면 예제 플러그인이 설치되어 동작할 IntelliJ Community Edition이 자동으로 다운로드되고, 그 Sandbox 인스턴스 IDE가 새로 뜨며, 그 위에서 예제 플러그인이 돌아가는 것을 확인해 볼 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/JetBrains/intellij-platform-plugin-template/tree/v1.1.0#plugin-configuration-file&quot;&gt;설명&lt;/a&gt;에도 나와있듯이 &lt;code class=&quot;highlighter-rouge&quot;&gt;/src/main/resources/META-INF/plugin.xml&lt;/code&gt; 파일에 &lt;code class=&quot;highlighter-rouge&quot;&gt;applicationService&lt;/code&gt;로 지정된 &lt;code class=&quot;highlighter-rouge&quot;&gt;MyApplicationService.kt&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;projectService&lt;/code&gt;로 지정된 &lt;code class=&quot;highlighter-rouge&quot;&gt;MyProjectService.kt&lt;/code&gt;가 Sandbox IDE의 로드 시점에 수행되며, &lt;code class=&quot;highlighter-rouge&quot;&gt;println&lt;/code&gt;으로 출력하는 메시지가 바깥쪽 IDE의 Run 탭에 출력되는 것을 확인할 수 있었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/intellij-plugin/sample.png&quot; alt=&quot;기본 예제 확인&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;kotlin-코드-다루기&quot;&gt;Kotlin 코드 다루기&lt;/h3&gt;
&lt;p&gt;하지만 우리가 플러그인을 통해 최종적으로 이름 변경을 하기 위해서는 Kotlin 코드를 인식하고 분석하는 기능이 필요합니다.
기존에 Android Studio를 비롯한 IntelliJ 계열 IDE에도 Renaming 기능이 있기 때문에, 플러그인에도 관련 내용이 있으리라 판단했고, 아니나 다를까 &lt;a href=&quot;https://plugins.jetbrains.com/docs/intellij/kotlin.html#handling-kotlin-code&quot;&gt;이 문서&lt;/a&gt;에서 Kotlin 관련 내용을 찾을 수 있었습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;If a plugin processes Kotlin code (e.g., providing inspections), it needs to add a dependency on the Kotlin plugin (Plugin ID &lt;code class=&quot;highlighter-rouge&quot;&gt;org.jetbrains.kotlin&lt;/code&gt;) itself. Please refer to &lt;a href=&quot;https://plugins.jetbrains.com/docs/intellij/plugin-dependencies.html&quot;&gt;Plugin Dependencies&lt;/a&gt; for more information.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;제시된 여러 문서를 따라가 보면 아래의 두 가지 작업으로 귀결됩니다.
우선 &lt;code class=&quot;highlighter-rouge&quot;&gt;plugin.xml&lt;/code&gt;에 아래의 코드를 추가하고,&lt;/p&gt;

&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;...
&lt;span class=&quot;nt&quot;&gt;&amp;lt;depends&amp;gt;&lt;/span&gt;org.jetbrains.kotlin&lt;span class=&quot;nt&quot;&gt;&amp;lt;/depends&amp;gt;&lt;/span&gt;
...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;build.gradle.kts&lt;/code&gt;이 플러그인 의존성 값을 받아오고 있는 &lt;code class=&quot;highlighter-rouge&quot;&gt;gradle.properties&lt;/code&gt; 파일에다가 아래와 같이 &lt;code class=&quot;highlighter-rouge&quot;&gt;java&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;Kotlin&lt;/code&gt; 플러그인 의존성을 추가해서 IntelliJ &lt;strong&gt;Kotlin&lt;/strong&gt; Plugin 의존성을 사용하도록 하면 됩니다.&lt;/p&gt;
&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nn&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;platformPlugins = ..., java, Kotlin&lt;/span&gt;
&lt;span class=&quot;nn&quot;&gt;...&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이제 해당 변경사항을 IDE가 인지할 수 있도록 &lt;code class=&quot;highlighter-rouge&quot;&gt;Sync Project with Gradle Files&lt;/code&gt;를 해주면 Kotlin 코드를 다룰 준비가 되었습니다.&lt;/p&gt;

&lt;h3 id=&quot;psi-사용하기&quot;&gt;PSI 사용하기&lt;/h3&gt;
&lt;p&gt;실질적으로 코드를 다루는 작업은 IntelliJ platform에서 제공하는 인터페이스인 &lt;a href=&quot;https://plugins.jetbrains.com/docs/intellij/psi.html&quot;&gt;PSI(Program Structure Interface)&lt;/a&gt;를 통해서 진행합니다.
여기서 PSI란 &lt;a href=&quot;https://plugins.jetbrains.com/docs/intellij/implementing-parser-and-psi.html&quot;&gt;공식 문서&lt;/a&gt;에 적혀있는 것처럼 특정 언어를 다루기 쉽도록 IntelliJ Platform이 파싱한 AST 요소들 위에 부가정보(문법적인 정보나, 언어 특유의 속성)들을 더한 것입니다.
저희는 위에서 적었던 &lt;code class=&quot;highlighter-rouge&quot;&gt;platformPlugins = ..., Kotlin&lt;/code&gt;을 통해서 IntelliJ Kotlin Plugin이 제공하는 Kotlin PSI를 사용할 수 있게 되었습니다.&lt;/p&gt;

&lt;p&gt;즉, 위에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;Kotlin&lt;/code&gt; 의존성을 추가해 줌으로써 &lt;code class=&quot;highlighter-rouge&quot;&gt;org.jetbrains.kotlin.psi.KtClass&lt;/code&gt;와 같이 &lt;code class=&quot;highlighter-rouge&quot;&gt;org.jetbrains.kotlin&lt;/code&gt; 패키지에 있는 내용을 우리가 만드는 플러그인 코드에서 사용할 수 있습니다.
결과적으로 우리가 만드는 플러그인에서 PSI tree에 있는 이 Kotlin PSI Element에 대해 다음과 같은 동작들을 해볼 수 있습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;해당 Element가 Class인지 Property인지 Function인지 판별&lt;/li&gt;
  &lt;li&gt;이 Element를 참조하고 있는 다른 Element로 이동&lt;/li&gt;
  &lt;li&gt;AST에 있는 하위 Element들은 어떤 것들이 있는지 확인&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;모든-ktclass-이름-출력&quot;&gt;모든 KtClass 이름 출력&lt;/h3&gt;
&lt;p&gt;Kotlin PSI를 사용해서 프로젝트에 있는 모든 &lt;code class=&quot;highlighter-rouge&quot;&gt;.kt&lt;/code&gt; 파일에 정의된 Kotlin Class의 이름을 출력해 보려면 아래와 같은 함수를 만들어서 사용해 볼 수 있습니다.&lt;/p&gt;

&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;printKtClassNames&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;project&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Project&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;project&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;allModules&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;forEach&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;module&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;-&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;FilenameIndex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;getAllFilesByExt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;project&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;kt&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;moduleContentScope&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mapNotNull&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;toPsiFile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;project&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;?&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;KtFile&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;flatMap&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ktFile&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ktFile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;collectDescendantsOfType&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;KtClass&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;forEach&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ktClass&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ktClass&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;아래의 스크린샷은 기본 예제 프로젝트의 &lt;code class=&quot;highlighter-rouge&quot;&gt;MyProjectService.kt&lt;/code&gt;파일을 수정한 뒤에 &lt;code class=&quot;highlighter-rouge&quot;&gt;Run Plugin&lt;/code&gt;을 통해 실행된 테스트용 Sandbox IDE에서 동일한 프로젝트를 열었을 때 바깥쪽 IDE에 값들이 출력되는 모습입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/intellij-plugin/ktclass.png&quot; alt=&quot;KtClass 이름 출력&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Sandbox IDE에서 열린 프로젝트의 &lt;code class=&quot;highlighter-rouge&quot;&gt;KtClass&lt;/code&gt; 이름들이 아래쪽의 콘솔 창에 찍힌 것을 확인해 볼 수 있습니다.
다만 프로젝트가 열리는 시점에는 Indexing이 끝나지 않아 모듈이나 파일 목록들이 아직 구성되지 않은 상태일 수도 있기 때문에 위와 같이 &lt;code class=&quot;highlighter-rouge&quot;&gt;DumbService.getInstance(project).runWhenSmart()&lt;/code&gt;를 사용해서 Indexing이 완료된 후에 실행될 수 있도록 했습니다.&lt;/p&gt;

&lt;h3 id=&quot;특정-프로퍼티-가져오기&quot;&gt;특정 프로퍼티 가져오기&lt;/h3&gt;
&lt;p&gt;그렇다면 &lt;code class=&quot;highlighter-rouge&quot;&gt;KtClass&lt;/code&gt; 내부에 정의된 &lt;code class=&quot;highlighter-rouge&quot;&gt;bindView&lt;/code&gt;를 사용하는 프로퍼티와 연결된 XML ID는 어떻게 가져올 수 있을까요?&lt;/p&gt;

&lt;p&gt;클래스 안에 정의된 프로퍼티를 가져와서 그 PSI tree를 보면서 &lt;code class=&quot;highlighter-rouge&quot;&gt;bindView&lt;/code&gt;를 사용하고 있는지, 그리고 어떤 ID를 사용하는지 확인해 보면 됩니다.
현재 활성화된 파일의 PSI tree가 어떤 식으로 구성되어 있는지 간단하게 확인해 보기 위해 &lt;a href=&quot;https://plugins.jetbrains.com/docs/intellij/explore-api.html#31-use-internal-mode-and-psiviewer&quot;&gt;이 문서&lt;/a&gt;에 나와 있는 것처럼 IntelliJ Plugins Marketplace에 있는 &lt;em&gt;PsiViewer&lt;/em&gt; 플러그인을 사용했습니다.&lt;/p&gt;

&lt;p&gt;해당 플러그인을 사용하면 아래와 같이 현재 커서가 있는 곳의 PSI element가 전체 트리의 어떤 위치에 있는지 파악하는 것이 가능합니다.
&lt;img src=&quot;/assets/images/intellij-plugin/psi-viewer.png&quot; alt=&quot;PsiViewer plugin&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이러한 기능을 바탕으로 PSI tree를 확인해서 우리가 수정할 대상인 &lt;code class=&quot;highlighter-rouge&quot;&gt;bindView&lt;/code&gt; Delegate를 사용하는 프로퍼티 목록을 가져올 수 있습니다.
가져오는 방법은 여러 가지가 있겠지만, 저는 아래와 같은 코드로 접근했습니다.&lt;/p&gt;
&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;KtClass&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;getBindViewProperties&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;getProperties&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mapNotNull&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;property&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;-&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;bindViewCall&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;property&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delegate&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;?.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expression&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;?.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;castSafelyTo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;KtCallExpression&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;()&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;?.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;takeIf&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;referenceExpression&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;?.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;bindView&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;firstArgument&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bindViewCall&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;?.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;valueArgumentList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;?.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arguments&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;?.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;xmlId&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;firstArgument&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;?.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;getArgumentExpression&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;?.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lastChild&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;?.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;xmlId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;?.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BindViewProperty&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;property&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;data class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BindViewProperty&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;property&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;KtProperty&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;xmlId&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;프로퍼티의-이름을-변경하기&quot;&gt;프로퍼티의 이름을 변경하기&lt;/h3&gt;
&lt;p&gt;위쪽 단락에서 받아온 Kotlin PSI의 &lt;code class=&quot;highlighter-rouge&quot;&gt;KtProperty&lt;/code&gt; 타입은 &lt;code class=&quot;highlighter-rouge&quot;&gt;PsiNamedElement&lt;/code&gt;를 구현한 타입입니다.
따라서 아래와 같이 함수를 만들어서 Reference를 포함한 모든 장소의 이름을 변경하고, 그 변경사항을 반영할 수 있습니다.&lt;/p&gt;

&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;PsiNamedElement&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;renameAllReferences&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;project&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Project&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;newName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;updateAndCommit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;project&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;files&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ReferencesSearch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;map&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;handleElementRename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;newName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;resolve&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;?.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;containingFile&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;setName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;newName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;[Rename] ${this.elementType} ${this.name} -&amp;gt; $newName&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;files&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;plus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;containingFile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;filterNotNull&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;updateAndCommit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;project&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Project&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Iterable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;PsiFile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;DumbService&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;getInstance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;project&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;runWhenSmart&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;WriteCommandAction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;runWriteCommandAction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;project&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;filesToCommit&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;filesToCommit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;toSet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;forEach&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;commitAndUnblockDocument&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;View binding에서는 snake case 대신에 lower camel case를 사용하므로, 실제 코드에서는 아래와 같이 간단한 변환 함수를 활용해서 &lt;code class=&quot;highlighter-rouge&quot;&gt;renameAllReferences()&lt;/code&gt;를 호출해 주었습니다.&lt;/p&gt;

&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;snakeToLowerCamelCase&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sc&quot;&gt;'_'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;joinToString&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;capitalize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;decapitalize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;그 밖에도 &lt;code class=&quot;highlighter-rouge&quot;&gt;PsiElement.astReplace&lt;/code&gt;를 활용하면 이름을 변경하는 것을 넘어서 직접 AST를 조작하는 것 또한 가능합니다.
가령 아래와 같이 임의의 &lt;code class=&quot;highlighter-rouge&quot;&gt;PsiElement&lt;/code&gt;를 white space로 변경시킬 수 있습니다.&lt;/p&gt;
&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;psiElement&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;astReplace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;PsiWhiteSpaceImpl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;action으로-등록해서-사용&quot;&gt;Action으로 등록해서 사용&lt;/h3&gt;
&lt;p&gt;앞서 말한 동작들이 프로젝트 로딩 시점마다 매번 실행되는 것은 플러그인이라는 특성상 그다지 바람직하지 않은 일입니다.
따라서 IntelliJ에서는 &lt;a href=&quot;https://plugins.jetbrains.com/docs/intellij/basic-action-system.html&quot;&gt;action&lt;/a&gt;을 등록할 수 있게 해 두었습니다.
&lt;code class=&quot;highlighter-rouge&quot;&gt;plugins.xml&lt;/code&gt;에 아래와 같이 작성하고 &lt;code class=&quot;highlighter-rouge&quot;&gt;Run Plugin&lt;/code&gt;을 돌려서 켜진 Sandbox IntelliJ를 확인해 보면, 상단의 Tools 메뉴 가장 위에 Action이 등록된 것을 볼 수 있습니다.&lt;/p&gt;
&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;actions&amp;gt;&lt;/span&gt;
    ...
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;action&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;class=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;path.to.the.action.class&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;description=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;...&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;id=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;...&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;text=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;...&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;add-to-group&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;anchor=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;first&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;group-id=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;ToolsMenu&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/action&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/actions&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이제 &lt;code class=&quot;highlighter-rouge&quot;&gt;class&lt;/code&gt;에 지정한 클래스로 가서 Action에서 수행할 내용을 적어주면 됩니다.
저희 플러그인에서는 아래 코드처럼 커서가 있는 &lt;code class=&quot;highlighter-rouge&quot;&gt;KtClass&lt;/code&gt;에 대해서만 리팩토링을 수행하도록 했습니다.&lt;/p&gt;

&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BindViewRefactoring&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;AnAction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;event&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;AnActionEvent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;// Set the availability based on whether a project is open&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;event&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;presentation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isEnabledAndVisible&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;event&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;project&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;null&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;actionPerformed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;event&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;AnActionEvent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;elementAtCursor&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;event&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;getData&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;CommonDataKeys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;PSI_FILE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;?.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;findElementAt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;event&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;getData&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;CommonDataKeys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;CARET&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;?.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;offset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;?:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;targetElement&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;elementAtCursor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;?.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parentOfType&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;KtClass&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;()&lt;/span&gt;

        &lt;span class=&quot;nc&quot;&gt;Messages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;showOkCancelDialog&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;event&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;project&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;&quot;리팩토링 대상: ${targetElement?.name}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;&quot;View Binding&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;&quot;실행&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;&quot;취소&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;nc&quot;&gt;Messages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;getInformationIcon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;it&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Messages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;OK&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;targetElement&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;KtClass&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;nf&quot;&gt;refactorBindViewProperties&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;project&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!!&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;targetElement&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;마무리하며&quot;&gt;마무리하며&lt;/h2&gt;
&lt;p&gt;이러한 과정을 거쳐서 작성한 플러그인 코드를 빌드 하여 Android Studio에 설치하고, 리팩토링에 빠르게 사용해 볼 수 있었습니다.
&lt;img src=&quot;/assets/images/intellij-plugin/plugin.png&quot; alt=&quot;Android Studio에 설치한 쏘카 플러그인&quot; /&gt;&lt;/p&gt;

&lt;p&gt;또한 작성한 플러그인의 기능에는 전처리/후처리를 좀 더 편하게 할 수 있도록 위에서 언급했던 프로퍼티 변경 기능 외에도 아래와 같은 기능들을 추가했습니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;View Binding Migration 페이지에 있는 것처럼 레이아웃을 &lt;code class=&quot;highlighter-rouge&quot;&gt;R.layout.~&lt;/code&gt; Resource 대신 &lt;code class=&quot;highlighter-rouge&quot;&gt;...Binding&lt;/code&gt; 클래스로부터 받아와서 초기화하는 코드 삽입 기능&lt;/li&gt;
  &lt;li&gt;IntelliJ에서 제공하는 &lt;code class=&quot;highlighter-rouge&quot;&gt;OptimizeImportsProcessor&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;ReformatCodeProcessor&lt;/code&gt; 등을 사용해서 수정한 코드를 다시 정리하는 기능&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;덕분에 &lt;code class=&quot;highlighter-rouge&quot;&gt;Activity&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;Fragment&lt;/code&gt;, Custom View 등 100개가 넘는 파일에 있던 &lt;code class=&quot;highlighter-rouge&quot;&gt;bindView&lt;/code&gt; 프로퍼티들을 한꺼번에 수정할 수 있었습니다.
PR에서 코드 리뷰 과정을 거치는 도중, View Binding 초기화 코드를 수정하면 좋겠다는 의견이 있어서 이를 전체적으로 반영할 때에도 하나하나 파일을 찾아가며 고칠 필요가 없던 것도 큰 이득이었습니다.&lt;/p&gt;

&lt;p&gt;그뿐만 아니라 현재는 이 플러그인을 확장해서 Live Template으로 하기에는 까다로운 템플릿 코드 기능을 추가하는 등, 더 다양한 형태로 활용하고 있습니다.
이런 식으로 앞으로도 IntelliJ 플러그인을 통해서 개발자들의 소중한 개발 시간을 조금이나마 절약해 볼 수 있으면 좋겠습니다.&lt;/p&gt;

&lt;h3 id=&quot;ps&quot;&gt;P.S.&lt;/h3&gt;
&lt;p&gt;2021년 11월 말, JetBrains에서 차세대 IDE &lt;a href=&quot;https://www.jetbrains.com/fleet/&quot;&gt;Fleet&lt;/a&gt;을 발표했습니다.
짧은 지원자 신청 기간을 거쳐 현재는 Closed Preview를 진행 중인데요, Fleet에서 Plugin 지원은 어떻게 진행할지, Language Server에 대한 정책은 어떻게 바뀔지 흥미롭습니다.
비록 플러그인을 작성하는 방식이 기존과 달라질 수도 있겠지만, 여기서 진행했던 리팩토링 자동화 경험에 약간의 변주만 더한다면 수월하게 작업할 수 있으리라 생각합니다.&lt;/p&gt;</content><author><name>jian</name></author><category term="dev" /><category term="kotlin" /><category term="intellij" /><category term="android-studio" /><category term="plugin" /><summary type="html">안녕하세요, 쏘카 안드로이드 팀의 지안입니다.</summary></entry><entry><title type="html">자동차 배터리를 더 소중하게 공학적으로 관리하기 #2</title><link href="https://tech.socarcorp.kr/mobility/2022/01/18/socar-mobility-lab-battery-management-process-second-stage.html" rel="alternate" type="text/html" title="자동차 배터리를 더 소중하게 공학적으로 관리하기 #2" /><published>2022-01-18T03:00:00+00:00</published><updated>2022-01-18T03:00:00+00:00</updated><id>https://tech.socarcorp.kr/mobility/2022/01/18/socar-mobility-lab-battery-management-process-second-stage</id><content type="html" xml:base="https://tech.socarcorp.kr/mobility/2022/01/18/socar-mobility-lab-battery-management-process-second-stage.html">&lt;p&gt;안녕하세요. 쏘카 모빌리티 Lab의 찰리입니다. &lt;a href=&quot;https://socarcharlie.github.io/mobility/2021/07/20/socar-mobility-lab-battery-management-process-first-stage.html&quot;&gt;지난 글&lt;/a&gt;에서는 10,000대가 넘는 차량을 운영하는 쏘카에서, 차량의 배터리 상태 관리를 위한 공학적인 접근 방식과 해결 방법에 대해 다뤘습니다. 이번 글에서는 배터리 방전을 사전에 막기 위해 알람 서비스를 도입하고, 운영에 도입한 내용을 공유해 보고자 합니다. 다소 전문적인 지식이 필요했던 지난번 글에 비해 이번 글은 누구나 쉽게 읽으실 수 있을 거라 생각합니다.&lt;/p&gt;

&lt;h2 id=&quot;목차&quot;&gt;목차&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;의도치 않은 실수들로 생기는 배터리 방전&lt;/li&gt;
  &lt;li&gt;적당한 차량 상태 조회 주기 찾기&lt;/li&gt;
  &lt;li&gt;차량이 방전될 상태인지 판단하기&lt;/li&gt;
  &lt;li&gt;그래서 알림은 어떻게 보내지나요?&lt;/li&gt;
  &lt;li&gt;조금만 더 세심하게 다뤄주세요. 다 같이 쓰는 차니까요.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;의도치-않은-실수들로-생기는-배터리-방전&quot;&gt;의도치 않은 실수들로 생기는 배터리 방전&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://socarcharlie.github.io/mobility/2021/07/20/socar-mobility-lab-battery-management-process-first-stage.html&quot;&gt;지난 글&lt;/a&gt;을 보면 쏘카에서 일어나는 배터리 방전의 60% 이상이 고객의 사용 습관과 밀접하다고 말씀드렸습니다. 그러나 배터리 방전을 고객께서 의도적으로 내지는 않습니다. 대부분은 어떤 상황에서 방전이 되는지 잘 모르시기 때문에 일어나곤 합니다.&lt;/p&gt;

&lt;p&gt;저 역시 의도치 않게 쏘카 차량의 방전을 일으킬만할 경험이 있습니다. 제가 보유하고 있는 차는 시동 버튼을 두 번 눌러 시동을 완전히 종료시키는 반면, 쏘카 차량 (현대/기아차, Jeep)은 시동 버튼을 한 번만 눌러도 시동 종료가 이루어졌습니다. 기어 상태도 시동을 종료하면 자동으로 주차 모드로 바뀌는 제 차와 달리 기어 봉을 직접 P로 옮겨주어야 했습니다. 사실 자동 변속기 차량에서 시동을 P에 두고 시동을 종료하는 일은 대단히 당연합니다. 단지 제가 익숙한 방식과 조금 달랐기에 이런 실수를 저질렀고, 그 결과 차량 반납 불가의 메시지를 받았습니다. 저와 비슷한 상황에 놓였던 고객과 핸들러 입장에서 가시동이나 기어봉 P가 아닌 D 혹은 R 모드 중 강제 반납으로 인한 방전 상황 노출이 대단히 쉬운 일임을 깨닫게 된 순간이었습니다.&lt;/p&gt;

&lt;p&gt;주위에 비슷한 사례가 있나 싶어 지인들에게 물어보니, 쏘카 패스를 구독하는 저의 친구 역시 비슷한 경험이 있었습니다. 몹시 더운 여름 어느날 주차 중에 에어컨을 켜고 싶어서 가시동 상태로 송풍기를 열심히 돌리면서 노래도 들었다고 합니다. 그렇게 한 시간 정도가 지났고 차를 다시 움직여 이동하려고 하는데 시동이 걸리지 않았다고 합니다. 친구는 가시동 상태에서 송풍기를 돌리고(에어컨 컴프레셔는 멈춰있어서 바람만 나왔을텐데) 차량 스피커로 음악을 들으면 필요한 전력을 모두 차량 배터리에서 가져 온다는 사실을 몰랐습니다.&lt;/p&gt;

&lt;p&gt;이 외에도 고객께서 전혀 의도하지 않았지만 차량의 전원관리에 나쁜 영향을 미칠 수 있는 차량 운용으로 인해 방전이 생기는 경우는 다양할 거라 생각했습니다. 어떻게 해야 고객께서도 방전을 겪지 않아 기분이 좋고 쏘카도 관리 이슈를 줄일 수 있을까요?&lt;/p&gt;

&lt;p&gt;저는 이렇게 생각했습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“고객께서 실수하지 않도록 우리가 도와드리자. 알림을 보내드리면 상황 인지를 빨리하실 수 있겠지?”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;결론은 고객에게 어떤 형태로든 &lt;strong&gt;“알림을 드리자!”&lt;/strong&gt;였습니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;적당한-차량-상태-조회-주기-찾기&quot;&gt;적당한 차량 상태 조회 주기 찾기&lt;/h2&gt;

&lt;p&gt;고객에게 방전될 수 있는 상황임을 알리는 알림을 보내기 위해서는, 먼저 현재 차량의 상태를 알아야 합니다. 쏘카 차량에는 관제 장치가 붙어있는데, 이 장치로부터 차량 상태에 대한 데이터를 주기적으로 받을 수 있습니다. 데이터를 받는 주기는 다음과 같이 3가지 상황에 따라 다릅니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;일반 주행 혹은 가시동 상황일 때: 2분에 1회&lt;/li&gt;
  &lt;li&gt;시동 OFF 후 정차 중인 상황일 때: 30분에 1회&lt;/li&gt;
  &lt;li&gt;문열림/문잠금/시동 상태의 변화가 일어날 때: 각각 1회&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;위의 주기는 하나의 차량에서 어떤 주기로 차량 정보 데이터를 올려주는지에 대한 내용입니다. 쏘카에서 운영하는 총 차량은 10,000대가 넘고, 차량 각각에서 일어나는 상태 변화 시점은 제각각입니다. 따라서 하나의 시스템이 많은 차량을 다루기 위해선 일정 시점마다 전체 차량을 조회하고, 각 차량의 상태 시점과 이벤트 시점의 시간 차이와 상태 변화 추이를 각각 계산해야 합니다. 따라서 전체 차량의 상태 조회 주기가 너무 늦으면 방전 상태를 늦게 판단할 가능성이 높아지고, 너무 빠르게 하면 알람이 너무 자주 가게 됩니다. 따라서 &lt;strong&gt;전체 차량 상태 조회의 적당한 주기를 찾는 것이 중요합니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;이를 위해 가장 먼저 해야 할 일은 차량 방전이 일어날만한 시나리오를 생각해 보고, 각 &lt;strong&gt;시나리오별 전류가 어느 정도로 빨리 소모되는지 측정하는 것&lt;/strong&gt;이었습니다. 또한 차종별로 장착된 부품의 사이즈나 전력 소모량이 모두 다르기 때문에, 각 차종별로 위의 시나리오에 맞추어 실험을 따로 진행해야 하는 것도 고려해야 했습니다.&lt;/p&gt;

&lt;p&gt;처음에는 차량 방전이 일어나기 쉬운 사용 시나리오를 찾는 일부터 시작해보았습니다. 가시동 중 노래 듣기, 송풍기(1~n단까지 모두 다른 케이스로 가정했음), 전조등, 미등, 상향등, 경고등, 실내등 등등 모든 전력 소모 및 방전 요소를 모두 조합한 시나리오를 세웠고 &lt;strong&gt;조합한 시나리오별로 전류가 얼마정도 소모되는지 모두 측정&lt;/strong&gt;하기로 했습니다.&lt;/p&gt;

&lt;p&gt;전류 측정은 초등학교 시절 한번 즈음 모두가 거쳐갔을 라디오 조립 키트의 전류 측정보다 아주 조금 어려운 정도입니다 (&lt;del&gt;쉽다는 말을 어렵게 해 보았습니다.&lt;/del&gt;). 직접 실험을 해보고 싶으신 분도 계시리라 생각하여 측정법에 대해 설명드리겠습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;우선 배터리의 - 단자에 연결된 터미널을 제거합니다.&lt;/li&gt;
  &lt;li&gt;배터리가 제거되는 순간 자동차에 연결된 IBS 단자 (Intelligent Battery Sensor)는 초기화됩니다. 이 센서는 배터리의 상태와 관련된 값을 수집하는 센서인데 이 센서의 초기화 부분은 차량 제조사와 차종마다 모두 상이하므로 다루지 않도록 하겠습니다. 차량 제조사 매뉴얼에 보면 이 센서의 초기화와 관련된 내용이 상세히 적혀 있으니 참고하시면 좋습니다.&lt;/li&gt;
  &lt;li&gt;전력계의 모드를 전류 측정으로 전환합니다.&lt;/li&gt;
  &lt;li&gt;제거된 터미널에 전력계의 양극 부를 연결하고, 배터리의 - 단자에는 전력계 음극 부를 연결합니다. 이때 측정기의 리드 케이블은 클립형이 좋으며 길고 튼튼할수록 좋습니다. 측정할 때는 보닛을 닫아두는 게 좋기 때문입니다.&lt;/li&gt;
  &lt;li&gt;잘 연결이 되었다면 전력계에 전류 값이 표시됩니다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;위의 설명은 고전적인 측정기를 사용하는 방법입니다. 요즈음에는 블루투스로 연동하여 핸드폰으로 값을 받을 수 있는 전류 측정기가 있어서 측정이 비교적 쉽습니다. 블루투스 전류 측정기의 자동차 단자 연결법도 위와 동일합니다.&lt;/p&gt;

&lt;p&gt;측정기 연결이 잘 되었다면 미리 세워둔 시나리오별로 전류 소모의 변화를 모두 기록합니다. 다양한 차종에 대해 실험하다 보니 하루에 끝내기는 어려웠고 실험 완료까지 수 일이 걸렸습니다. 측정이 완료된 시점에서 보니 생각보다 방전을 일으키키 정말 쉬운 물건이 자동차구나 싶었습니다.&lt;/p&gt;

&lt;p&gt;시나리오 중 한 가지 예를 아래에 공유드리도록 하겠습니다. 실험값과 차종은 모두 예시입니다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Avg[A]&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Max[A]&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;검출 여부&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;비고&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;실내등(개당)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.6&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;△&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;문 열림 상태로 간접 추론&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;ACC1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;2.1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;O&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;ACC2&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;7.5&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;12&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;O&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;송풍기 1단&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;X&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;송풍기 2단&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;4.2&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;X&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;송풍기 3단&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;6.8&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;X&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;송풍기 4단&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;11.2&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;X&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;라이트 1단&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.8&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;△&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;단계는 나오지 않음&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;라이트 2단&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;8.8&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;△&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;단계는 나오지 않음, 차종별로 ACC2부터 가능함&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;라이트 3단(High)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;9.8&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;△&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;단계는 나오지 않음, 차종별로 ACC2부터 가능함&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;비상등&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;5.5&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;X&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;그리고 구현 가능한 시나리오는 다음과 같았습니다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;일반적인 시나리오

S1. 시동 OFF + 문 열림: 0.6A 소모
S2. ACC1 단독: 2.1A 소모
S3. ACC2 단독: 7.5A 소모
S4. ACC1 + Light 1단 (흔한 유형): 2.9A 소모
S5. ACC2 + Light 2단 (흔한 유형): 16.3A 소모
S6. ACC2 + 송풍기 2단 (흔히 말하는 차박): 11.7A 소모

최악의 시나리오

SW. ACC2 + 실내등 2개 (문 앞뒤 열림) + 송풍기 4단계 + Light 3단 + 비상등 +핸드폰 충전기: 32.7A 소모
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이제 이렇게 세워둔 시나리오 별로 각 차량별 정격 용량의 절반에 도달하기까지 걸리는 시간까지의 시간을 측정했습니다.&lt;/p&gt;

&lt;p&gt;예를 들어, 아래는 60Ah 배터리를 사용하는 차량의 경우입니다. 각 S1 - S6는 시나리오를 뜻하며, 값은 시간(hour)입니다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;SW&lt;/th&gt;
      &lt;th&gt;S1&lt;/th&gt;
      &lt;th&gt;S2&lt;/th&gt;
      &lt;th&gt;S3&lt;/th&gt;
      &lt;th&gt;S4&lt;/th&gt;
      &lt;th&gt;S5&lt;/th&gt;
      &lt;th&gt;S6&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;0.5&lt;/td&gt;
      &lt;td&gt;27.0&lt;/td&gt;
      &lt;td&gt;7.7&lt;/td&gt;
      &lt;td&gt;2.2&lt;/td&gt;
      &lt;td&gt;5.6&lt;/td&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;1.4&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;이렇게 모든 차종에 대해 시나리오에 따른 전류 소모 측정 실험을 마친 후, 전체 차량의 상태 조회의 적당한 주기를 &lt;strong&gt;10분&lt;/strong&gt;으로 결정지었습니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;차량이-방전될-상태인지-판단하기&quot;&gt;차량이 방전될 상태인지 판단하기&lt;/h2&gt;

&lt;p&gt;위에서 정의한 시나리오는 전류 소모 측정을 위해 어느 정도 미리 생각해두어 생각한 틀일 뿐, 실제로 쏘카 데이터를 기반으로 만들어진 시나리오는 아닙니다. 이제 수집된 데이터로부터 실제로 방전이 될만한 상황인지를 판단해야 합니다. 저희는 쏘카 내 데이터로부터 이런 시나리오를 분석하여 정의하기로 했습니다.&lt;/p&gt;

&lt;p&gt;앞서 쏘카 차량에는 관제 단말기가 부착되어 있고, 이 단말기로부터 차량 주행과 관련된 데이터를 주기적으로 수집하고 있다고 말씀 드렸습니다. 수집하는 데이터 중에는 시동/가시동/정지 여부, 전조등 켜짐/꺼짐 여부, 전압 정보 등등 고객님의 차량 운용 패턴과 관련된 데이터가 모두 담겨있습니다. 따라서 &lt;strong&gt;과거의 방전 관련 CS 콜이 들어온 시간을 전/후로 주행 데이터를 살펴보면 문제 발생을 일으키는 주요한 운용 패턴을 발견할 수 있습니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;예를 들면, 여름철에 가장 많이 들어온 방전 관련 CS 콜을 살펴보면 위의 시나리오 중 S6이 가장 많습니다. 주행은 하고 있지만 엔진이 작동하기에 추가적인 기름 소모는 아쉽고, 차에서 좀 쉬고 싶기는 해서 송풍기에서 나오는 바람을 좀 쐬고 있다 보니 발생하는 일입니다. 그 외에도 희귀하지만 인상 깊었던 상황을 공유드리자면, 자주 방전이 일어나 발전기까지 체크했는데도 방전 문제가 개선되지 않았던 차량에 대한 신고를 받고 데이터를 살펴보니, 퓨즈단의 배선이 잘못되어 시동이 꺼진 후에도 암전류가 지속적으로 일어났던 상황이었습니다. 다음의 그림은 각각 “블루투스 계측기를 이용한 전류 측정 사진”과 “같은 잔존 수명을 가진 배터리가 암전류의 유무에 따라 시간당 전압 변화율이 어떻게 달라지는지 보여주는 예시 차트”입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/socar-mobility-lab-battery-management-process-second-stage/Figure-2.jpg&quot; alt=&quot;&quot; /&gt;
&lt;em&gt;블루투스 계측기를 이용한 전류 측정&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/socar-mobility-lab-battery-management-process-second-stage/Figure-3.png&quot; alt=&quot;&quot; /&gt;
&lt;em&gt;같은 잔존 수명을 가진 배터리가 암전류의 유무에 따라 시간당 전압 변화율이 어떻게 달라지는지 보여주는 예시&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;실험과 데이터를 보기 전에는 고객께서 단순히 전조등만 켜 놓았거나, 송풍기만 켜 놓았다거나, 실내등만 켜두는 등의 단일 조작 위주의 시나리오가 많을 거라 생각했습니다. 그러나 실험과 데이터를 통해, 생각과는 달리 꽤나 다양한 요소가 결합된 시나리오가 많다는 사실을 알 수 있었습니다.&lt;/p&gt;

&lt;p&gt;결과적으로 저희는 수집된 데이터가 다음과 같은 조건일 때 방전 알림을 보내야 하는 상황이라고 판단했습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;시동 종료 후 가시동(ACC) 10분 이상 지속 할 때&lt;/li&gt;
  &lt;li&gt;시동 종료 후 10분간 문 잠금/열림 연속 10회 이상 시도할 때&lt;/li&gt;
  &lt;li&gt;전조등이 켜져 있을 때&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;데이터 수집은 위에서 정한 대로 10분마다 이루어지며 1~3은 모두 OR 조건으로 엮입니다. 따라서 어느 한 조건이라도 충족이 되면 그 차량은 알림의 대상이 됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/socar-mobility-lab-battery-management-process-second-stage/Figure-4.png&quot; alt=&quot;&quot; /&gt;
&lt;em&gt;실행 프로세서의 순서도. 실제 시스템 구축은 모비딕 팀 스팍께서 해주셨습니다.&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;그래서-알림은-어떻게-보내지나요&quot;&gt;그래서 알림은 어떻게 보내지나요?&lt;/h2&gt;

&lt;p&gt;위 과정에 의해 DB에 알림 대상이 되는 차량들이 저장되며, 이후에는 쏘카의 서비스 서버가 이 DB를 조회해 알림을 보냅니다.&lt;br /&gt;
서비스 서버에서는 대상 차량 확인 후 다음을 고려하여 알람 주기 및 방식을 정합니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;알림 주기
    &lt;ul&gt;
      &lt;li&gt;고객께서 차량 정차 후 정차된 차량으로 돌아오기 어려울 정도로 멀리 떠나기까지 걸리는 시간을 고려해야 합니다.&lt;/li&gt;
      &lt;li&gt;차량을 정차(강제 반납의 가능성이 높음) 후 고객께서 다른 교통수단으로 갈아타서 이동을 시작하거나, 개인 사정으로 어떠한 연락에도 즉시 확인 및 응답이 불가능하다면 그 고객에게는 어떠한 알림도 무의미합니다.&lt;/li&gt;
      &lt;li&gt;따라서 고객의 다음 행동이 구체화되어 차량으로 다시 돌아오기엔 어려워지는 상황이 오기 전에 미리 연락을 취해야 합니다.&lt;/li&gt;
      &lt;li&gt;이 시간은 과거 CS 콜 분석을 통해 &lt;strong&gt;10분&lt;/strong&gt;으로 결정하였습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;알림 방식 소모 비용
    &lt;ul&gt;
      &lt;li&gt;기존에 쏘카에서 사용하고 있으며 고객에게 친숙한 채널을 최대한 활용하기로 했습니다.&lt;/li&gt;
      &lt;li&gt;비용적으로도 저렴한 &lt;strong&gt;카카오톡 알림&lt;/strong&gt;을 활용하기로 결정했습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;전체 과정을 최종적으로 정리해 보면 다음과 같습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;전체 차량에 대한 상태 데이터를 10분마다 수집합니다.&lt;/li&gt;
  &lt;li&gt;미리 세워둔 시나리오를 기반으로 현재 차량이 방전이 될만한 상태인지 판단합니다.&lt;/li&gt;
  &lt;li&gt;방전이 될만한 차량을 발견하면, 해당 차량과 고객에 대한 데이터를 DB에 적재합니다.&lt;/li&gt;
  &lt;li&gt;쏘카 서비스 서버는 DB에서 알림을 보낼 차량과 고객을 확인합니다.&lt;/li&gt;
  &lt;li&gt;해당 고객의 카카오톡으로 10분마다 방전 주의 알림을 보냅니다.&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;조금만-더-세심하게-다뤄주세요-다-같이-쓰는-차니까요&quot;&gt;조금만 더 세심하게 다뤄주세요. 다 같이 쓰는 차니까요.&lt;/h2&gt;

&lt;p&gt;위의 기준으로 쏘카는 본 서비스를 2021년 2월부터 투입했습니다. 성과를 간략히 말씀드리면, &lt;strong&gt;동기 대비 이용건수가 8% 늘어난 상황에서 (2021년 n월 기준) 긴급 출동 건수 35% 감소가 이루어졌으며 방전 비율도 절반 정도 감소 (2021년  n월 기준)&lt;/strong&gt; 했음을 확인했습니다 (회사의 영업 기밀이기에 자세한 기준을 공개하기 어려운 점 양해 부탁드립니다.).&lt;/p&gt;

&lt;p&gt;본 아이디어의 기본 개념은 “고객께서 실수할 확률 자체를 낮추어드리자”입니다. 누구도 쏘카의 차량을 일부러 고장 내고 싶지 않으리라 생각합니다. 단지 자동차에 대한 경험적 이해가 아직 부족해서 혹은 피할 수 없는 상황에 놓여서, 어쩌면 쏘카 정비의 미진한 점으로 인한 일들이 있었겠죠. 이런 상황에 놓이지 않도록 미리 도움을 드리는 일도 쏘카가 기술적으로 해결할 일이라고 생각합니다.&lt;/p&gt;

&lt;p&gt;쏘카는 &lt;strong&gt;누구나&lt;/strong&gt; 이용할 수 있고, &lt;strong&gt;누구나&lt;/strong&gt; 이용하는 ‘&lt;strong&gt;카-셰어링&lt;/strong&gt;’ 서비스입니다. 따라서 &lt;strong&gt;쏘카 차량의 주인은 “쏘카”가 아닌 “여러분 모두”라고 생각합니다.&lt;/strong&gt; 쏘카는 단지 모두가 사용하는 차량에 날개를 달아주는 도우미라고 생각합니다. 앞으로도 좋은 날개를 달기 위해 고객의 주행 환경과 경험 개선을 위한 다양한 기술 기반 아이템을 많이 발굴하도록 노력하겠습니다. 쏘카를 이용해 주시는 쏘카 차량의 주인이신 여러분들께서도 여러분들의 차량을 조금만 더 아껴주시면 감사하겠습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;쏘카의 모빌리티 Lab&lt;/strong&gt;은 모두 높은 수준의 기계 공학 지식을 보유한 인력으로 이루어졌으며, 쏘카의 풍부한 차량 데이터에 기계 공학 지식을 녹여 운영에 필요한 최적 솔루션을 만들고 있습니다. (우리에게 힘을 더해주실 우수한 분을 모시고 있습니다. 언제든지 지원해 주세요)&lt;/p&gt;
&lt;/blockquote&gt;</content><author><name>charlie</name></author><category term="mobility" /><category term="mechanical engineering" /><category term="chemical engineering" /><category term="data" /><summary type="html">안녕하세요. 쏘카 모빌리티 Lab의 찰리입니다. 지난 글에서는 10,000대가 넘는 차량을 운영하는 쏘카에서, 차량의 배터리 상태 관리를 위한 공학적인 접근 방식과 해결 방법에 대해 다뤘습니다. 이번 글에서는 배터리 방전을 사전에 막기 위해 알람 서비스를 도입하고, 운영에 도입한 내용을 공유해 보고자 합니다. 다소 전문적인 지식이 필요했던 지난번 글에 비해 이번 글은 누구나 쉽게 읽으실 수 있을 거라 생각합니다.</summary></entry><entry><title type="html">차량용 단말을 위한 IoT 파이프라인 구축기 #1</title><link href="https://tech.socarcorp.kr/mobility/2022/01/06/socar-iot-pipeline-1.html" rel="alternate" type="text/html" title="차량용 단말을 위한 IoT 파이프라인 구축기 #1" /><published>2022-01-06T00:00:00+00:00</published><updated>2022-01-06T00:00:00+00:00</updated><id>https://tech.socarcorp.kr/mobility/2022/01/06/socar-iot-pipeline-1</id><content type="html" xml:base="https://tech.socarcorp.kr/mobility/2022/01/06/socar-iot-pipeline-1.html">&lt;div class=&quot;photo-copyright&quot;&gt;
Photo by &lt;a href=&quot;https://unsplash.com/@mbenna?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText&quot;&gt;Mike Benna&lt;/a&gt; on &lt;a href=&quot;https://unsplash.com/s/photos/pipeline?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText&quot;&gt;Unsplash&lt;/a&gt;
&lt;/div&gt;

&lt;h2 id=&quot;떼려야-뗄-수-없는-관계-단말과-서비스&quot;&gt;떼려야 뗄 수 없는 관계, 단말과 서비스&lt;/h2&gt;

&lt;p&gt;안녕하세요. 모빌리티 플랫폼 그룹 - 모비딕 팀의 스팍입니다.&lt;/p&gt;

&lt;p&gt;쏘카가 서비스를 제공하기 위해서는 &lt;strong&gt;차량의 상태 정보&lt;/strong&gt;가 필수적입니다. 사용이 끝난 차량이 정상적으로 제 위치에 안전한 상태로 돌아왔는지 언제든지 확인할 수 있어야 합니다.&lt;/p&gt;

&lt;p&gt;따라서 차량의 상태 정보를 수집하여 서버에 전달하며, 고객의 요청에 따라 차량을 제어해주는 장치가 필요합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/iot-pipeline-1/pipeline_concept.jpg&quot; alt=&quot;&quot; width=&quot;75%&quot; height=&quot;75%&quot; style=&quot;display: block; margin: 0 auto&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;잠깐-쏘카의-구형-단말을-돌아봅시다&quot;&gt;잠깐 쏘카의 구형 단말을 돌아봅시다&lt;/h2&gt;

&lt;p&gt;서비스 초기부터 쏘카는 차량 내에 서비스를 위한 단말을 장착하여 사용하고 있었습니다(편의상 구형 단말이라 부르겠습니다). 그리고 서비스가 급격하게 성장하던 시절에도 이 단말은 그럭저럭 제 역할을 해주었죠.&lt;/p&gt;

&lt;p&gt;이 구형 단말이 개발될 당시에는 운영 편의성을 위한 적합한 기술들이 아직 등장하기 전이었습니다. 따라서 단말을 제어할 때는 단말을 식별할 수 있는 고유번호인 전화번호를 이용하여 SMS 메시지를 통해 제어하였고, 단말이 데이터를 보낼 때는 웹서버에 데이터를 보내듯 HTTP로 데이터를 전달하였습니다.&lt;/p&gt;

&lt;p&gt;이러한 구형 단말은 잠재적인 문제를 갖고 있었습니다. 그중 몇 가지를 꼽아보자면 다음과 같습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;SMS의 특성상 단말에 명령이 도달하는 데 시간이 많이 소요됩니다. 게다가 이 시간은 모든 지역에서 동일하지 않고 서울에서 멀어질수록 오래 걸리는 경향이 있습니다.&lt;/li&gt;
  &lt;li&gt;데이터 수집을 HTTP로 하다 보니 이를 위한 웹서버가 필요합니다.&lt;/li&gt;
  &lt;li&gt;데이터 전달 요청이 급증하면서 서버에 부하가 걸리면 데이터 수집에 지연이 발생합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/img/iot-pipeline-1/old_device_arch.jpg&quot; alt=&quot;&quot; width=&quot;75%&quot; height=&quot;75%&quot; style=&quot;display: block; margin: 0 auto&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;이렇게-된-이상-새로운-단말을-만든다&quot;&gt;이렇게 된 이상 새로운 단말을 만든다!&lt;/h2&gt;

&lt;p&gt;이러한 문제를 해결하기 위해 새로운 단말을 만들기로 하였습니다.&lt;/p&gt;

&lt;p&gt;새로운 단말을 만들 때 기존 단말이 갖고 있던 한계점과 문제를 보완하기 위해 아래와 같은 요구사항들을 세웠습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;HTTP를 통한 단말 데이터 수집을 더는 않는다. -&amp;gt; 단말 메시지보다 HTTP 프로토콜이 더 많은 네트워크 자원을 소모해야 할 이유가 없음.&lt;/li&gt;
  &lt;li&gt;SMS를 통한 차량 제어를 더는 하지 않는다. -&amp;gt; 메시지 도달 시간이 환경에 따라 다르고 발송할 때마다 비용이 발생하는 방식에서 탈피.&lt;/li&gt;
  &lt;li&gt;데이터 전달이 급증할 때 유연하게 대응할 수 있어야 함 -&amp;gt; 트래픽에 유동적으로 대응이 힘든 웹서버를 사용해서는 안 됨.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;해서, 위와 같은 요구사항에 맞춰 신규 단말은 &lt;a href=&quot;https://ko.wikipedia.org/wiki/MQTT&quot;&gt;MQTT&lt;/a&gt; 프로토콜 기반의 통신 방식을 채택하였습니다.&lt;/p&gt;

&lt;p&gt;MQTT를 단말 프로토콜로 선정한 이유는, 무엇보다 프로토콜 자체가 제한적인 IoT 기기에서 대용량의 데이터를 전송하기 위한 프로토콜로써 설계가 되었다는 점입니다.&lt;/p&gt;

&lt;p&gt;그리고 Publisher/Subscriber 구조로 되어 있어 여러 단말에 메시지를 퍼트리거나 상태 정보를 수집하는 것도 직접 각각의 단말들에 P2P로 연결할 필요 없이 메시지 브로커의 중개를 따르면 되므로 네트워크 관리 측면에도 용이합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/iot-pipeline-1/MQTT_protocol_example_without_QoS.png&quot; alt=&quot;출처:ko.wikipedia.org/wiki/MQTT&quot; width=&quot;45%&quot; height=&quot;45%&quot; style=&quot;display: block; margin: 0 auto&quot; /&gt;&lt;/p&gt;

&lt;p&gt;마지막으로 MQTT는 국제 표준화된 (ISO 표준 ISO/IEC PRF 20922) 프로토콜이므로 별도로 메시지 브로커를 개발할 필요 없이 이미 존재하는 수많은 메시지 브로커 중 하나를 선택하여 사용하면 된다는 것도 장점입니다.&lt;/p&gt;

&lt;p&gt;MQTT를 지원하는 메시지 브로커는&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://mosquitto.org/&quot;&gt;mosquitto&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://vernemq.com/&quot;&gt;VernaMQ&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.hivemq.com/&quot;&gt;HiveMQ&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.rabbitmq.com/&quot;&gt;RabbitMQ&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;정도가 있습니다.&lt;/p&gt;

&lt;p&gt;하지만, 위에 나열된 MQTT 브로커들을 직접 운영한다고 하면 아래와 같은 고민에 부딪히게 됩니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;메시지 브로커들을 직접 관리해야 하므로 운영에 대한 부담이 늘어납니다.&lt;/li&gt;
  &lt;li&gt;대부분의 브로커가 스스로에 대한 모니터링 방법은 제공하지만 어떤 단말이 연결 중인지에 대한 정보까지는 제공해주지 않습니다.&lt;/li&gt;
  &lt;li&gt;서비스 안정성을 위해서 클러스터링 할 수 있어야 하지만 이것을 지원해주지 않는 브로커도 많습니다.&lt;/li&gt;
  &lt;li&gt;차량 제어라는 특수성을 만족하기에는 보안 측면에서 부족한 부분이 있습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;그리하여 저희 팀에서는 직접 브로커를 관리 및 운영하기보다는, 클라우드 관리형 메시지 브로커 서비스인 &lt;a href=&quot;https://aws.amazon.com/ko/iot-core/&quot;&gt;AWS IoT Core&lt;/a&gt;를 사용하기로 하였습니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;새-술은-새-부대에-aws-iot-core&quot;&gt;새 술은 새 부대에. AWS IoT Core.&lt;/h2&gt;

&lt;p&gt;AWS IoT Core를 쓰면 여러 이점을 얻을 수 있습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;관리되는 서비스이므로 운영에 있어 수기로 작업해줘야 하는 부분이 줄어듭니다.&lt;/li&gt;
  &lt;li&gt;IoT 단말들을 정책기반으로 운영할 수 있습니다.&lt;/li&gt;
  &lt;li&gt;어떤 단말들이 연결되었는지 확인이 가능합니다.&lt;/li&gt;
  &lt;li&gt;메시지 브로커에 대한 모니터링 역시 손쉽게 가능합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/img/iot-pipeline-1/new_device_arch.jpg&quot; alt=&quot;&quot; width=&quot;75%&quot; height=&quot;75%&quot; style=&quot;display: block; margin: 0 auto&quot; /&gt;&lt;/p&gt;

&lt;p&gt;AWS IoT Core를 쓸 때 서비스를 운영하는 입장에서 가장 주요한 부분은 “관리되는 서비스”라는 점입니다. 카셰어링 서비스의 특성상 시간이나 시즌마다 데이터양이 크게 달라지는 이슈를 가지고 있습니다. 그리고 서비스에 부하가 걸리더라도 항상 단말은 명령 수신과 상태 보고에 있어 준비된 상태를 유지해야 합니다. 단말이나 통신 환경에 문제가 없을지라도 브로커의 상태가 불안정하면 서비스의 운영 안정성에 크게 영향을 미치므로 관리되는 서비스가 주는 이점은 강력하다 하겠습니다.&lt;/p&gt;

&lt;p&gt;특히나 AWS IoT Core를 사용하면서 강력한 도구가 되어주는 것이 &lt;a href=&quot;https://docs.aws.amazon.com/ko_kr/iot/latest/developerguide/provision-wo-cert.html&quot;&gt;Fleet provisioning&lt;/a&gt;이라는 것입니다. 메시지 브로커에 인증받지 않은 단말이나 시스템이 접속하여 멋대로 메시지를 구독 혹은 발행하게 되면 보안 측면에서 데이터 유출이 일어나거나 차량 제어 측면에서 적절치 못한 제어를 통해 고객의 안전이 위협받을 수도 있습니다.&lt;/p&gt;

&lt;p&gt;따라서 메시지 브로커에 대한 접근 제한이 필수라 하겠는데, 수천 대가 넘어가는 단말들에 대해 일일히 접근 권한을 부여하고 관리하는 것도 큰일입니다. 이를 Fleet provisioning 기능을 통해 인증서와 보안정책 간의 결합을 통해 매우 편리하게 관리할 수 있게 되었습니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;aws-iot-core-쓰면-끝&quot;&gt;AWS IoT Core 쓰면 끝?&lt;/h2&gt;

&lt;p&gt;AWS IoT Core를 활용하여 단순히 차량 데이터를 수집을 하는 것에만 머무르기엔 아쉽습니다. 여기서 더 나아가 각 부서(도메인)의 관점과 필요에 따라 수집된 데이터를 유연하게 활용한다면 더 좋을 것입니다. 기존에는 단말 데이터를 전부 DB에 저장하여 활용하는 방식을 사용했습니다. 그러나 이 방식은 DB 부하를 불러온다는 단점을 가지고 있습니다.&lt;/p&gt;

&lt;p&gt;모비딕 팀에서는 이 단점을 극복하기 위해 AWS IoT Core로부터 수집한 데이터를 &lt;a href=&quot;https://aws.amazon.com/ko/msk/&quot;&gt;Amazon MSK&lt;/a&gt;를 활용하여 흘려보내고 있습니다. 이러한 구조로 인해 데이터가 필요한 각 비즈니스 영역에서 MSK를 구독하는 컨슈머를 만들기만 하면 수집된 차량 상태 데이터를 활용할 수 있게 됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/iot-pipeline-1/aws_iot_arch.jpg&quot; alt=&quot;&quot; width=&quot;75%&quot; height=&quot;75%&quot; style=&quot;display: block; margin: 0 auto&quot; /&gt;&lt;/p&gt;

&lt;p&gt;여기까지 쏘카에서 사용 중인 단말들을 더 빠르게 제어하고 더 많은 데이터를 더 안정적으로 수집하기 위한 구조를 만들어 내는 과정을 설명해 드렸습니다.&lt;/p&gt;

&lt;p&gt;다음에는 실제 Amazon MSK를 구축할 때 마주쳤던 문제들을 해결하는 과정에서 얻어진 글로 찾아뵙겠습니다.&lt;/p&gt;</content><author><name>spock</name></author><category term="mobility" /><category term="iot" /><summary type="html">Photo by Mike Benna on Unsplash</summary></entry><entry><title type="html">쏘카 신입 데이터 엔지니어 디니의 4개월 회고</title><link href="https://tech.socarcorp.kr/data/2021/12/28/data-engineering-team-onboarding.html" rel="alternate" type="text/html" title="쏘카 신입 데이터 엔지니어 디니의 4개월 회고" /><published>2021-12-28T08:00:00+00:00</published><updated>2021-12-28T08:00:00+00:00</updated><id>https://tech.socarcorp.kr/data/2021/12/28/data-engineering-team-onboarding</id><content type="html" xml:base="https://tech.socarcorp.kr/data/2021/12/28/data-engineering-team-onboarding.html">&lt;p&gt;안녕하세요! 쏘카 데이터 엔지니어링 팀의 디니입니다.&lt;/p&gt;

&lt;p&gt;저는 2021년 8월에 쏘카 데이터 엔지니어링 팀에 신입 데이터 엔지니어로 입사했습니다. 지난 4개월간 데이터 엔지니어링 팀에서 경험하며 느낀 점을 공유하려 합니다. 그 중 데이터 엔지니어링 팀의 온보딩과 실무를 겪으며 느낀 내용을 주로 다루었습니다. 혹시 데이터 분석가나 데이터 사이언티스트의 내용이 궁금하신 분은 &lt;a href=&quot;https://tech.socarcorp.kr/data/2020/08/19/socar-data-group-intern-review.html&quot; target=&quot;_blank&quot;&gt;쏘카 데이터 그룹 - 데이터 사이언티스트 인턴 9개월 후기&lt;/a&gt;를 보시면 도움이 될 것 같습니다.&lt;/p&gt;

&lt;p&gt;다음과 같은 분들이 읽으시면 도움이 될 것 같습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;쏘카 데이터 엔지니어링 팀의 신입 채용 과정이 궁금하신 분&lt;/li&gt;
  &lt;li&gt;쏘카 데이터 엔지니어링 팀에 입사한 인원이 빠르게 회사에 적응하기 위한 온보딩 과정이 궁금하신 분&lt;/li&gt;
  &lt;li&gt;온보딩 프로세스를 만들려고 하시는 분&lt;/li&gt;
  &lt;li&gt;쏘카 데이터 엔지니어링 팀이 어떻게 일을 하는지 관심 있으신 분&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;목차&quot;&gt;목차&lt;/h2&gt;

&lt;p&gt;목차는 다음과 같습니다. 각 제목을 클릭하시면 해당 부분으로 이동하실 수 있습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;#join-process-and-background&quot;&gt;입사 지원 배경과 과정&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;지원 배경&lt;/li&gt;
      &lt;li&gt;입사 과정&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#onboarding-process&quot;&gt;입사 후 온보딩 과정&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;온보딩 과제&lt;/li&gt;
      &lt;li&gt;과제 후 얻은 것&lt;/li&gt;
      &lt;li&gt;마무리 발표&lt;/li&gt;
      &lt;li&gt;그 외 온보딩 &amp;amp; 밍글링 과정&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#after-onboarding&quot;&gt;온보딩 후 실무 투입 과정&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;첫 프로젝트 : 메타데이터 플랫폼 구축&lt;/li&gt;
      &lt;li&gt;각종 파티 참여&lt;/li&gt;
      &lt;li&gt;온보딩 과정이 어떻게 도움되었나요?&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#throwback&quot;&gt;앞으로는 무엇을?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#qna&quot;&gt;Q &amp;amp; A&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;1-입사-지원-배경과-과정-&quot;&gt;1. 입사 지원 배경과 과정 &lt;a name=&quot;join-process-and-background&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;먼저 제가 회사를 지원하게 된 배경과 그 과정을 말씀드립니다.&lt;/p&gt;

&lt;h3 id=&quot;지원-배경&quot;&gt;지원 배경&lt;/h3&gt;

&lt;p&gt;저는 대학에서 경영학을 전공했고, 처음에는 데이터 분석에 관심이 있었습니다. 그런데 우연한 계기로 실시간 API의 데이터를 가공하여 데이터베이스에 적재하고 지표를 만드는 경험을 한 뒤, 데이터 엔지니어링의 매력을 느끼게 되었습니다.&lt;/p&gt;

&lt;p&gt;데이터 분석과 실험을 잘 하려면 원천(Raw) 데이터와 데이터 인프라 환경이 잘 만들어져야 하고, 이런 환경을 구축하는 것이 데이터 엔지니어링이라고 생각했습니다. 인프라, Database, 개발 등 다양한 경험을 할 수 있는 데이터 엔지니어가 멋있어(!) 보였고, 그렇게 저는 쏘카 데이터 엔지니어 포지션에 지원하게 되었습니다.&lt;/p&gt;

&lt;h3 id=&quot;입사-과정&quot;&gt;입사 과정&lt;/h3&gt;

&lt;p&gt;쏘카 데이터 엔지니어링의 채용 프로세스는 다음처럼 진행되었습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;서류 제출&lt;/li&gt;
  &lt;li&gt;전화 면접&lt;/li&gt;
  &lt;li&gt;1차 면접(기술 면접)&lt;/li&gt;
  &lt;li&gt;2차 면접(임원 면접)&lt;/li&gt;
  &lt;li&gt;처우 협의&lt;/li&gt;
  &lt;li&gt;최종 합격&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;1-서류-제출&quot;&gt;1. 서류 제출&lt;/h4&gt;

&lt;p&gt;원티드를 통해 서류를 제출했습니다. 따로 자기소개서 양식은 없었고, 과거 프로젝트 경험이 담긴 이력서와 함께 &lt;a href=&quot;https://diana-lab.tistory.com/&quot; target=&quot;_blank&quot;&gt;개인 블로그&lt;/a&gt;와 &lt;a href=&quot;https://github.com/yoonhyejin&quot; target=&quot;_blank&quot;&gt;Github&lt;/a&gt;를 첨부했습니다.&lt;/p&gt;

&lt;h4 id=&quot;2-전화-면접&quot;&gt;2. 전화 면접&lt;/h4&gt;

&lt;p&gt;이력서에 있는 경험들과 데이터 엔지니어링에 대해 얼마나 알고 있는지를 중심으로 면접이 진행되었습니다. 업무 관련 문제 해결 경험, 관련 프레임워크를 써보거나 공부한 경험, DB 관련 개념은 알고 있는지 등의 질문이 있었습니다. 데이터 엔지니어링 팀장이신 토마스가 면접을 해주셨고 30분 정도 진행되었습니다.&lt;/p&gt;

&lt;h4 id=&quot;3-1차-면접-기술-면접&quot;&gt;3. 1차 면접 (기술 면접)&lt;/h4&gt;

&lt;p&gt;1차 기술 면접엔 포트폴리오 위주로 직무 관련 꼬리 질문이 이어졌습니다. 그 뒤에 코딩테스트가 있었는데, 총 3문제를 한 시간에 걸쳐 풀었습니다. 면접자에게 시간을 주고 풀게 한 뒤, 코드를 보면서 질문과 답변을 주고받는 형식이었습니다. 멀티 스레드, 클래스 등의 개념과 파이썬을 통한 로직 구현, SQL 쿼리의 여러 기능과 활용법을 알아야 하는 질문이 나왔습니다.&lt;/p&gt;

&lt;p&gt;이론적인 알고리즘 문제보다 현업에서 마주칠만한 문제 상황을 어떻게 코드로 해결할지를 묻는 질문이었습니다. 쏘카가 모빌리티 기업인 만큼, 모빌리티 관련 도메인 지식도 있으면 좋다 생각했습니다. &lt;strong&gt;정답 여부가 아닌 전체적으로 문제에 접근하는 논리를 보시는 것 같았습니다.&lt;/strong&gt; 개인적으로 모든 채용 과정 중 가장 긴장을 많이 한 과정이었습니다. 1시간 30분 정도 진행되었습니다.&lt;/p&gt;

&lt;h4 id=&quot;4-2차-면접-임원-면접&quot;&gt;4. 2차 면접 (임원 면접)&lt;/h4&gt;

&lt;p&gt;데이터 그룹의 그룹장이신 DK가 면접을 진행했습니다. 대부분 이력서 기반의 인성 질문들이었으나 기술 질문도 있었습니다. 회사에 대해 질문하는 Reverse Interview 과정도 20분 정도 있었습니다. 기술 면접에서 너무 긴장했던 탓인지 2차 면접은 상대적으로 순한맛(?)으로 느껴졌습니다.  1시간 정도 진행되었습니다.&lt;/p&gt;

&lt;p&gt;모든 과정의 결과 발표는 1주일 이내로 신속하게 진행되었고, 전화와 이메일을 통해 명확한 의사소통이 이루어졌습니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;2-입사-후-온보딩-과정-&quot;&gt;2. 입사 후 온보딩 과정 &lt;a name=&quot;onboarding-process&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;약 한 달 정도의 채용 프로세스 끝에 드디어 쏘카 데이터 엔지니어링 팀에 입사하게 되었습니다.&lt;/p&gt;

&lt;p&gt;쏘카 데이터 엔지니어링 팀은 총 8명으로 쏘카 데이터 엔지니어링 팀이 하는 일은 데이터 엔지니어링 팀의 하디가 작성한 &lt;a href=&quot;https://tech.socarcorp.kr/data/2021/03/24/what-socar-data-engineering-team-does.html&quot; target=&quot;_blank&quot;&gt;데이터 엔지니어링 팀이 하는 일&lt;/a&gt;과 &lt;a href=&quot;https://www.notion.so/socarcorp/d458b6b77a2243fb873d1ac800c321f7?p=1e895c6f8d6c49d0962d9c3af3e37f81&quot; target=&quot;_blank&quot;&gt;쏘카 데이터 엔지니어 채용공고&lt;/a&gt;에 잘 설명되어 있습니다.&lt;/p&gt;

&lt;p&gt;며칠 뒤, 2주 동안 4개의 온보딩 과제를 진행하게 되었습니다.&lt;/p&gt;

&lt;h3 id=&quot;온보딩-과제&quot;&gt;온보딩 과제&lt;/h3&gt;

&lt;p&gt;이 온보딩 과제는 데이터 엔지니어링 팀에 가장 최근에 입사했던 그랩의 아이디어에서 출발했다고 합니다. 간단한 과제들을 통해 팀에서 다루는 도구와 업무 플로우에 익숙해지는 것이 목표였습니다. 과제를 통해 Kubernetes, Docker, Airflow, FastAPI, Git, Helm Chart와 같은 기술을 경험해볼 수 있었습니다. 구체적으로 과제 내용은 다음과 같았습니다.&lt;/p&gt;

&lt;h4 id=&quot;1-docker---docker-다루기&quot;&gt;1) Docker - Docker 다루기&lt;/h4&gt;

&lt;p&gt;첫 과제는 간단한 Docker 파일을 만들어 실행하고, Docker Compose로 Airflow를 띄워보는 내용이었습니다.&lt;/p&gt;

&lt;p&gt;데이터 엔지니어링 팀은 기본적으로 Kubernetes 환경에서 업무가 진행되기 때문에 Docker 부터 익혀야 한다는 생각으로 만들어진 과제입니다. 맨 처음에는 Docker를 설치하고, Ubuntu 컨테이너를 가져와서 실행하고 접속하여 파일을 만들어보는 등의 과정을 진행했습니다. 그다음에는 Ubuntu 이미지를 기반으로 hello world를 CMD를 이용해 출력하는 파일을 만들었습니다.&lt;/p&gt;

&lt;p&gt;이 뒤에는 Docker Compose를 이용해 Airflow를 띄우고 Web UI에 접속하는 것까지 진행했습니다. 이 과정에서 Airflow의 기본 구조도 공부할 수 있었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-engineering-onboarding/onboarding-comment.png&quot; alt=&quot;온보딩 과제 - 험프리 코멘트&quot; /&gt;
&lt;em&gt;Docker 과제 기록 - 천사 험프리의 코멘트&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&quot;2-docker-compose--airflow---간단한-web-server-개발하기&quot;&gt;2) Docker Compose &amp;amp; Airflow - 간단한 Web Server 개발하기&lt;/h4&gt;

&lt;p&gt;여기서는 앞에서 배운 Docker Compose를 활용해 웹서버와 DB를 띄우고, 마찬가지로 Docker Compose로 Airflow를 띄운 뒤 웹서버와 통신하는 DAG을 작성하는 과제가 주어졌습니다.&lt;/p&gt;

&lt;p&gt;웹 프레임워크는 딱히 제한이 없어, 그나마 익숙했던 Flask로 간단한 웹서버를 만들었습니다. 그다음에 이 웹서버를 띄울 수 있는 Docker 파일을 만들어야 했습니다. 이 과정에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;ENTRYPOINT&lt;/code&gt; 와 &lt;code class=&quot;highlighter-rouge&quot;&gt;CMD&lt;/code&gt;의 사용법을 익히느라 헤맨 기억이 있습니다.&lt;/p&gt;

&lt;p&gt;그리고 DB를 위해 MySQL 컨테이너도 띄우고 (마찬가지로 제일 익숙한 것으로 했습니다.) Docker Compose를 통해 둘을 연결했습니다. 이후 Airflow를 따로 띄운뒤, 만든 웹서버에 HTTP Request를 하는 함수를 &lt;code class=&quot;highlighter-rouge&quot;&gt;PythonOperator&lt;/code&gt;로 호출하는 간단한 DAG을 작성했습니다. 여기서 “웹서버에 연결하려면 DAG에서 어떤 주소를 넣어줘야 하는가?”를 트러블슈팅하느라 많이 헤맸는데요. 팀원 험프리의 도움으로 결국 해결할 수 있었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-engineering-onboarding/onboarding-crying.png&quot; alt=&quot;온보딩 과제 - 트러블슈팅 과정&quot; /&gt;
&lt;em&gt;트러블슈팅 기록 - 중간중간 오열했습니다.&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&quot;3-airflow---간단한-dag-만들어서-실행하기&quot;&gt;3) Airflow - 간단한 DAG 만들어서 실행하기&lt;/h4&gt;

&lt;p&gt;이 과제는 &lt;code class=&quot;highlighter-rouge&quot;&gt;PythonOperator&lt;/code&gt;를 이용한 간단한 Airflow DAG을 만들고, 팀의 CI/CD 환경에 배포 및 실행해보는 내용이었습니다. 특정 기능을 구현하는 것보다 팀 업무 환경에 익숙해지기 위한 과제였습니다. 다른 과제보다 수월하게 진행할 수 있었습니다. 또한 저희팀 Git Repository에 다양한 샘플 DAG 코드가 업로드되어 있어서, DAG의 기본 구조 이해에 도움이 되었습니다.&lt;/p&gt;

&lt;p&gt;이 과제에서 생성한 DAG 안의 Task의 내용 자체는 매우 단순했지만 (print 문 등), 대신 Task 하나를 실행하거나 여러 Task를 병렬 처리하는 DAG를 생성해봤습니다.&lt;/p&gt;

&lt;h4 id=&quot;4-kubernetes---helm-chart를-작성하여-웹서버를-kubernetes에-배포하기&quot;&gt;4) Kubernetes - Helm chart를 작성하여 웹서버를 Kubernetes에 배포하기&lt;/h4&gt;

&lt;p&gt;이 과제는 간단한 API 서버를 구축하고 Docker로 빌드하여 GCR(Google Container Registry)에 이미지로 Push한 뒤, Helm Chart를 작성하여 이 이미지를 GKE(Google Kubernetes Engine)에 배포하는 과정이었습니다. Helm Chart 기능들을 배우면서 팀 환경에도 익숙해지기 위한 과제였습니다.&lt;/p&gt;

&lt;p&gt;이 과제에서도 웹 프레임워크는 딱히 정해지지 않았지만, 팀에서 FastAPI를 자주 쓰고 있었기 때문에 겸사겸사해서 FastAPI로 웹서버를 구현했습니다. (이 과정에서 저만의 셀프 FastAPI 온보딩 과제- 간단한 CRUD 서버 구축해보기도 있었습니다.)&lt;/p&gt;

&lt;p&gt;Helm Chart를 직접 만들고 &lt;code class=&quot;highlighter-rouge&quot;&gt;values.yaml&lt;/code&gt; 을 작성하는 방법, GKE 환경을 설정하는 방법 등 짧은 시간에 많은 걸 접하고 배울 수 있었습니다. 처음에는 Kubernetes의 개념을 익히기 위해 minikube 로 테스트를 해봤고, 나중엔 팀 GKE에서 실습했습니다. 회사 GKE에서만 할 수 있는 설정들(GCR에 있는 이미지 Pull, Ingress 할당 등)이 있어서 조금 헤맸던 기억이 있습니다.&lt;/p&gt;

&lt;h3 id=&quot;과제-후-얻은-것&quot;&gt;과제 후 얻은 것&lt;/h3&gt;

&lt;p&gt;이렇게 4개의 온보딩 과제를 완료하는데 총 2주가 걸렸습니다. 신입 입장에서 이렇게 전체적으로 업무의 흐름을 파악하는 시간이 주어진 게 정말 감사한 일이었습니다. 👍&lt;/p&gt;

&lt;p&gt;모든 회사에서 이런 기회가 주어지지 않는다는 것을 알기에 더욱 소중한 시간이었습니다.&lt;/p&gt;

&lt;p&gt;가장 큰 장점은 &lt;strong&gt;“업무 적응에 대한 심적 부담이 크게 줄었다!”&lt;/strong&gt;입니다. 사실 데이터 엔지니어링 팀에 필요한 도메인이 매우 넓은데, 관련 경험이 거의 없어서 처음에 막연한 두려움이 있었습니다. 그런데 Task 자체는 매우 단순화한 상태에서 프레임워크를 사용해보고 플로우를 익혀보니, 좀 더 복잡한 업무도 “아, 일단 이건 해봤으니까 여기서 발전해나가면 되겠구나!” 하는 자신감이 생겼습니다.&lt;/p&gt;

&lt;p&gt;첫 환경 세팅이나 배포의 난관을 온보딩 과제를 통해 극복할 수 있던 것도 큰 의미가 있었습니다. 프레임워크뿐만 아니라 &lt;a href=&quot;https://k8slens.dev/&quot; target=&quot;_blank&quot;&gt;Lens&lt;/a&gt; 등 팀에서 활용하고 있는 모니터링 도구도 이때 빨리 접할 수 있었습니다. 팀 문서나 코드도 점점 눈에 들어오기 시작했습니다. 그리고 트러블슈팅 과정을 기록한 것들을 공유하며, 제가 어떤 부분에서 부족한지 팀원들의 피드백을 받아볼 수 있어서 좋았습니다.&lt;/p&gt;

&lt;h3 id=&quot;마무리-발표&quot;&gt;마무리 발표&lt;/h3&gt;

&lt;p&gt;이렇게 2주 동안 과제를 수행한 뒤, 온보딩 과제를 회고하는 발표를 하게 되었습니다. 주로 온보딩 과제와 트러블 슈팅 내용들, 제가 느꼈던 감정들 위주였습니다. 발표 후, 이런 식으로 온보딩 과정을 발전 및 정착시켰으면 좋겠다는 논의도 나왔습니다. 앞으로 더 개선된 온보딩 과정이 기대됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-engineering-onboarding/onboarding-pitch-airflow.png&quot; alt=&quot;온보딩 발표 중 Airflow&quot; /&gt;
&lt;em&gt;트러블슈팅 과정 설명&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-engineering-onboarding/onboarding-pitch-graph.png&quot; alt=&quot;과제에 따른 감정 변화&quot; /&gt;
&lt;em&gt;과제에 따른 감정 변화&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;그-외-온보딩--밍글링-과정&quot;&gt;그 외 온보딩 &amp;amp; 밍글링 과정&lt;/h3&gt;
&lt;p&gt;이런 온보딩 과제 외에도 쏘카에서는 다양한 방법으로 적응을 도와주는 아래와 같은 과정이 있습니다. 이런 과정들을 통해 쏘카 데이터 그룹 팀원들과 좀 더 친해지고, 빨리 적응할 수 있었습니다.&lt;/p&gt;

&lt;h4 id=&quot;1-각종-온보딩-세션&quot;&gt;1) 각종 온보딩 세션&lt;/h4&gt;
&lt;p&gt;회사 차원에서 PX(People Experience)팀에서 하루 정도 시간을 잡고 쏘카 회사의 히스토리와 문화에 대해서 알려주는 온보딩 과정이 있었습니다. 또한 PX팀과 따로 1:1 로 티타임을 하고, 온보딩 과정에 대한 만족도 조사를 하는 등 신규 입사자를 세심하게 신경 써주는 느낌을 받았습니다.  데이터 그룹 단위에서는 팀장인 토마스가 3번에 걸쳐 1:1로 한 시간씩 쏘카 데이터 그룹의 인프라와 히스토리를 설명해주는 시간이 있었습니다.&lt;/p&gt;

&lt;h4 id=&quot;2-라이브-슬랙&quot;&gt;2) 라이브 슬랙&lt;/h4&gt;

&lt;p&gt;라이브 슬랙은 데이터 그룹엔 신규 입사자가 자기를 소개하는 PPT를 한 장으로 만들어 슬랙(업무용 메신저)에 올리면, 데이터 그룹 전체가 질문하고 신규 입사자는 15분 동안 열심히 답변하는 이벤트입니다. 순발력과 빠른 타자 실력이 요구되었습니다. 참고로 이 문화는 VCNC에서 진행하는 라이브 슬랙을 참고했다고 합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-engineering-onboarding/live-slack.png&quot; alt=&quot;하디의 레전드 질문&quot; /&gt;
&lt;em&gt;인상 깊었던 하디의 레전드 질문&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&quot;3-해피아워&quot;&gt;3) 해피아워&lt;/h4&gt;

&lt;p&gt;데이터 그룹은 한 달에 한 번 금요일 오후에 해피아워를 진행합니다. 해피아워는 다양한 데이터 그룹의 사람들이 서로 친해지며 휴식하는 시간입니다. 코로나가 심하지 않을 때는 영화를 보거나 맥주를 마시러 가기도 했다고 합니다. 코로나 시국에는 비대면으로 마피아게임, 캐치마인드, 몸으로 말해요 등 여러 액티비티를 경험했습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-engineering-onboarding/happy-hour.png&quot; alt=&quot;해피아워 공지&quot; /&gt;
&lt;em&gt;지금은 제가 해피아워 공지를 올립니다.&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;3-실무-투입-과정-&quot;&gt;3. 실무 투입 과정 &lt;a name=&quot;after-onboarding&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;이렇게 온보딩 과제를 마무리한 후에도 조금씩 업무에 투입되었습니다. 이 기간에 팀원 그랩이 추천해준 &lt;a href=&quot;http://www.yes24.com/Product/Goods/89607047&quot; target=&quot;_blank&quot;&gt;“Kubernetes in Action”&lt;/a&gt;이라는 책을 읽으며 정리했습니다.&lt;/p&gt;

&lt;h3 id=&quot;첫-프로젝트--메타데이터-플랫폼-구축&quot;&gt;첫 프로젝트 : 메타데이터 플랫폼 구축&lt;/h3&gt;

&lt;p&gt;입사 후 처음 맡게 된 프로젝트입니다. 쏘카에선 개발 직군, 비개발 직군 상관없이 많은 분들이 데이터를 적극적으로 이용하고 있습니다. 점점 더 데이터가 복잡해지고 이용자가 늘어나는 상황에서 “어떤 데이터가 어디에 있는지”, “특정 테이블 혹은 칼럼은 어떤 정보를 담고 있는지”, 즉 메타데이터를 쉽게 파악하는 일이 중요해졌습니다.&lt;/p&gt;

&lt;p&gt;이런 메타데이터의 효율적 관리를 위한 “전사적 메타데이터 플랫폼”을 도입하는 과정에 카일과 함께 참여하게 되었습니다. 현재는 &lt;a href=&quot;https://github.com/linkedin/datahub&quot; target=&quot;_blank&quot;&gt;Datahub&lt;/a&gt;라는 프레임워크를 선택하여 GKE에서 테스트 과정 중에 있으며, 추후 전사 플랫폼으로 도입할 예정입니다. 기획 단계부터 리서치, 테스트와 배포와 커스텀 기능 개발까지 경험할 수 있어서 정말 재밌게 하고 있습니다.&lt;/p&gt;

&lt;p&gt;구체적으로는 다음과 같은 일들을 해볼 수 있었습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Data Ingestion 과정을 Docker 이미지로 만들고 Airflow DAG에 연동하여 스케줄링하기&lt;/li&gt;
  &lt;li&gt;Ingestion을 수행하는 계정 권한을 최소화하기 위해 자체 메타데이터 추출 로직 개발하기&lt;/li&gt;
  &lt;li&gt;Helm Chart, ArgoCD를 이용하여 GKE에 배포하기&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;아래는 Datahub 공식 사이트에서 제공하는 &lt;a href=&quot;https://demo.datahubproject.io/&quot; target=&quot;_blank&quot;&gt;데모 사이트&lt;/a&gt;의 스크린샷입니다. 이 플랫폼이 완성되면 또 다른 글로 찾아오겠습니다 :)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-engineering-onboarding/datahub-demo-main.png&quot; alt=&quot;Datahub 데모 메인 스크린샷&quot; /&gt;
&lt;em&gt;Datahub - 데모 메인 페이지.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-engineering-onboarding/datahub-demo-bigquery.png&quot; alt=&quot;Datahub 데모 빅쿼리 스크린샷&quot; /&gt;
&lt;em&gt;Datahub - 데모 상세 페이지.&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;각종-파티-참여&quot;&gt;각종 파티 참여&lt;/h3&gt;

&lt;p&gt;“파티”는 데이터 엔지니어링 팀에서 도입한 업무 형태입니다. 쉽게 말해 “중장기 프로젝트”라고 보시면 됩니다.&lt;/p&gt;

&lt;p&gt;데이터 엔지니어링 팀에서 해결해야 하는 문제를 파티의 주제로 선정하고, 관련된 사람들이나 혹은 해당 주제에 관심 있는 사람들을 모아 킥오프를 합니다. 파티의 리더인 파티장은 팀원 중 한 명이 맡게 되며, 파티장을 돌아가면서 할 수도 있습니다.&lt;/p&gt;

&lt;p&gt;파티는 여러 “시즌”이 있고, 한 시즌 안에는 여러 “액트(Act)”가 있습니다. 각자의 업무와 시간, 우선순위 등을 고려하여 필요한 일감을 시즌과 액트로 나누고 파티원들에게 일감을 분배합니다. 그리고 정기 회의를 통해 진행 상황을 리뷰하고 한 액트 혹은 시즌이 끝나면 회고하는 시간을 가집니다.&lt;/p&gt;

&lt;p&gt;현재 데이터 엔지니어링 팀에서 진행하는 파티는 로그 시스템, 가격 시스템, 데이터 마트 등 여러 분야가 있습니다.&lt;br /&gt;
제가 현재 참여하고 있는 파티는 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;소다 스토어 파티&lt;/strong&gt; - 쏘카의 데이터를 깔끔하고 편리하게&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;소다 스토어는 쏘카의 데이터를 한눈에 볼 수 있는 데이터 마트입니다. 자세한 설명은 &lt;a href=&quot;https://tech.socarcorp.kr/data/2021/03/24/what-socar-data-engineering-team-does.html&quot; target=&quot;_blank&quot;&gt;쏘카 데이터 그룹 - 데이터 엔지니어링 팀이 하는 일&lt;/a&gt;에서 볼 수 있습니다.&lt;/li&gt;
  &lt;li&gt;이 파티에서 쿼리의 확장성과 모듈화를 위해 &lt;a href=&quot;https://www.getdbt.com/&quot; target=&quot;_blank&quot;&gt;dbt&lt;/a&gt;라는 도구를 소다 스토어와 관련된 쿼리에 적용하는 작업을 하고 있습니다.&lt;/li&gt;
  &lt;li&gt;또한 dbt를 적용하는 대부분의 과정을 자동화하는 CLI를 만드는 과정에 참여하고 있습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-engineering-onboarding/shamanism-engineering.png&quot; alt=&quot;샤머니즘 엔지니어링&quot; /&gt;
&lt;em&gt;페어코딩 중 코드가 돌아가길 기도하고 있는 모습&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;소다 로그 파티&lt;/strong&gt; - 쏘카의 모든 로그를 효율적으로 관리한다&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;쏘카의 모든 로그를 잘 가공하여 사용자가 잘 사용할 수 있도록 만드는 파티입니다.&lt;/li&gt;
  &lt;li&gt;이 파티에서 기존 레거시 서버에 있는 로그 적재용 Airflow DAG들을 Kubernetes 환경으로 안전하게 옮기는 일을 하고 있습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;온보딩-과정이-어떻게-도움-되었나요&quot;&gt;온보딩 과정이 어떻게 도움 되었나요?&lt;/h3&gt;

&lt;p&gt;메타데이터 프로젝트에선 플랫폼에 메타데이터 주입 과정을 커스텀화 하기 위해서 Docker Image를 직접 빌드해야 했습니다. 온보딩 과제에서 Docker Image를 만들고 관련 명령어를 다뤄본 경험을 활용할 수 있었습니다. 그리고 이렇게 만든 Docker Image를 Airflow의 &lt;code class=&quot;highlighter-rouge&quot;&gt;KubernetesPodOperator&lt;/code&gt;로 실행해 배포하는 과정도 필요했습니다. 이 과정 역시 온보딩 과제 중 간단한 Airflow DAG을 만들고 배포해본 경험에서 응용할 수 있었습니다.&lt;/p&gt;

&lt;p&gt;또한 Datahub를 Helm chart를 이용하여 GKE에 배포해야 했습니다. 이 역시 온보딩 과제에서 Helm Chart로 GKE로 배포해보았던 경험이 도움 되었습니다. 물론 온보딩 때보다 Datahub의 차트가 훨씬 복잡했지만, 기본적인 플로우를 이해하고 있는 것이 큰 도움이 되었습니다.&lt;/p&gt;

&lt;p&gt;소다 로그 파티에서는 기존 레거시 서버에서 쿠버네티스로 DAG을 옮기는 과정에서, Airflow DAG의 설정을 수정하고 GitHub Repository를 통해 DAG을 CI/CD 파이프라인으로 배포해야 했습니다. 이 과정에서도 Airflow 관련 온보딩 경험을 다시 한번 활용할 수 있었습니다.&lt;/p&gt;

&lt;p&gt;결과적으로, 초기 업무를 할 때 온보딩 과제를 정리한 글을 20번 넘게 스스로 참고할 정도로 실질적인 도움이 되었습니다. 이렇게 보니 온보딩 과정이 없으면 정말 큰일 날뻔했네요 😂&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;4-앞으로는-무엇을-&quot;&gt;4. 앞으로는 무엇을? &lt;a name=&quot;throwback&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;많은 분의 도움이 있었던 온보딩 기간을 거치고, 앞으로 회사에서 하고 싶은 것이 생겼습니다.&lt;/p&gt;

&lt;h3 id=&quot;여러-사람이-편해지는-시스템이나-도구를-만들고-싶어요&quot;&gt;여러 사람이 편해지는 시스템이나 도구를 만들고 싶어요.&lt;/h3&gt;

&lt;p&gt;데이터 엔지니어링 업무 자체가 서포팅의 성격이 있습니다. 회사에서 저뿐만이 아니라 여러 사람이 편해지는 시스템이나 도구를 만들고 싶습니다.&lt;br /&gt;
예를 들면 “디니의 트러블슈팅 DB”를 만들고 있는데요. 지금 트러블슈팅한 과정을 미래의 나 혹은 다른 사람이 구글링처럼 편하게 검색하고 찾을 수 있었으면 좋겠다는 생각에서 시작되었습니다.&lt;/p&gt;

&lt;p&gt;그리고 제가 온보딩 과정에서 도움을 많이 받은 만큼 다음 오시는 분을 위해 온보딩 과정을 더욱 발전시키고 싶습니다. 개인적인 경험으로는 ArgoCD를 통한 배포와, Python 협업 환경(테스트 코드 짜기, 디버깅 하기 등)에 대한 온보딩 등이 추가되면 더 좋겠다고 느꼈습니다.&lt;/p&gt;

&lt;h3 id=&quot;문화-개선에-기여하고-싶어요&quot;&gt;문화 개선에 기여하고 싶어요.&lt;/h3&gt;

&lt;p&gt;함께 일하기 즐거운 회사가 되면 좋겠다는 소망이 있고, 제가 할 수 있는 것부터 하려고 노력 중입니다.
예를 들면 데이터 그룹 해피아워, 워크샵 등 밍글링 행사의 기획을 맡고 있고, “코딩 안풀릴때 소리지르는 방” 슬랙 채널 개설해서 다들 일하다 마음껏 소리지르는 (…) 공간을 만들었어요.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-engineering-onboarding/screaming.png&quot; alt=&quot;코딩 안될때 소리지르는 짤&quot; /&gt;
&lt;em&gt;입사 이후 최대의 업적 : 코딩 안될때 소리지르는 방 만든 것.&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;많이-공유하고-싶어요&quot;&gt;많이 공유하고 싶어요.&lt;/h3&gt;

&lt;p&gt;취업 준비 할 때 쏘카 기술 블로그를 많이 참고하기도 했고 공부하면서 언제나 다른 사람의 글을 보며 배우고 있기 때문에, 항상 유용한 글을 쓰고 싶다는 마음이 있습니다. 곧 메타데이터 플랫폼 글로 돌아오겠습니다. 😏&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;5-q--a-&quot;&gt;5. Q &amp;amp; A &lt;a name=&quot;qna&quot;&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;마지막으로 취업을 준비하면서 스스로 궁금했던, 그리고 비슷한 과정에 계실 분들이 궁금할만한 질문들과 이에 대한 답변을 정리해보았습니다.&lt;/p&gt;

&lt;h3 id=&quot;실무에서-데이터-분석가데이터-사이언티스트와-데이터-엔지니어의-차이는&quot;&gt;실무에서 데이터 분석가(데이터 사이언티스트)와 데이터 엔지니어의 차이는?&lt;/h3&gt;

&lt;p&gt;데이터 분석가와 데이터 사이언티스트 분들이 맘껏 능력 발휘할 수 있는 탄탄한 플레이그라운드를 만드는 것이 데이터 엔지니어링의 역할인 것 같습니다. 취업 준비할 때는 데이터 관련 직군 간의 업무 차이가 잘 와닿지 않았는데, 실무를 경험해보니 담당하는 업무가 확연히 다른 것 같습니다. (물론 회사마다 정의가 다르고, 작은 규모에서는 같이 하시는 분들도 있을 것 같습니다)&lt;/p&gt;

&lt;p&gt;아주 단순하게 얘기하자면 데이터 분석가는 말 그대로 ‘분석가’, 데이터 엔지니어는 ‘개발자’의 모습에 가깝다고 생각합니다. 어떤 목적을 해결하기 위해 데이터를 통해 분석하거나 사업적인 고민하는 것이 좋다면 데이터 분석을, 시스템 구축과 자동화, 프로그래밍 자체에 관심이 많다면 데이터 엔지니어링이 더 맞지 않을까 싶습니다.&lt;/p&gt;

&lt;h3 id=&quot;비전공자-문과라는-백그라운드가-회사에서-어떻게-작용하는지&quot;&gt;비전공자, 문과라는 백그라운드가 회사에서 어떻게 작용하는지?&lt;/h3&gt;

&lt;p&gt;저도 이 점에 대해서 걱정했는데, 저희 팀에는 오히려 비전공자가 더 많고 중요한 건 아무도 과(와 학교)에 신경을 쓰지 않습니다. 그런 백그라운드보다 요구하는 일을 할 수 있는 실력이 더 중요하다고 느꼈습니다.&lt;/p&gt;

&lt;p&gt;그리고 커뮤니케이션 능력은 어디서 무슨 일을 하든 무조건 플러스라고 생각합니다. 회사에 와서 보니 의사결정, 우선순위 산정 등 다른 게 더 중요할 수도 있다는 생각이 들었습니다. &lt;a href=&quot;https://eoeoeo.net/2021/08/12/%EB%B0%B0%EB%8B%AC%EC%9D%98%EB%AF%BC%EC%A1%B1-ceo%EA%B0%80-%EB%A7%90%ED%95%98%EB%8A%94-%ED%95%A8%EA%BB%98-%EC%9D%BC%ED%95%98%EA%B3%A0-%EC%8B%B6%EC%9D%80-%EA%B0%9C%EB%B0%9C%EC%9E%90%EC%9D%98-%EA%B8%B0/&quot; target=&quot;_blank&quot;&gt;배달의 민족 CEO 인터뷰&lt;/a&gt;에서 “개발자는 비즈니스 문제를 해결하는 사람”으로 정의하길 바란다는 말씀을 합니다. 이와 같이 코딩 뿐만 아니라 문제 해결에 지치지 않고 재밌어한다면 개발자가 잘 맞을 것 같습니다.&lt;/p&gt;

&lt;h3 id=&quot;신입-데이터-엔지니어를-희망한다면-어떻게-포트폴리오를-꾸리면-좋을까&quot;&gt;신입 데이터 엔지니어를 희망한다면 어떻게 포트폴리오를 꾸리면 좋을까?&lt;/h3&gt;

&lt;p&gt;개인적으로는 데이터 엔지니어링이 참 포트폴리오를 준비하기 힘든 분야라고 느꼈습니다. 소소하지만 저의 팁을 공유합니다.&lt;/p&gt;

&lt;h4 id=&quot;1-가고-싶은-회사가-어떤-환경인지-보고-공부하자&quot;&gt;1) 가고 싶은 회사가 어떤 환경인지 보고 공부하자.&lt;/h4&gt;

&lt;p&gt;가고 싶은 회사의 채용공고를 꼼꼼히 읽고, 어떤 툴과 프레임워크를 쓰는지 보시면서 그 프레임워크에 대한 공부를 하시면 좋을 것 같습니다&lt;/p&gt;

&lt;p&gt;저희가 알고 있는 IT 기업들은 AWS, GCP, Hadoop 이 선에서 크게 달라지지 않는다고 생각합니다. 온라인 강의 사이트에서 이런 프레임워크를 타겟으로 한 강의를 참고하시면 좋을 것 같습니다.&lt;/p&gt;

&lt;p&gt;쏘카 데이터 그룹은 기본적으로 GCP(Google Cloud Platform)를 이용하고 있기 때문에, 개인적으로 &lt;a href=&quot;https://www.qwiklabs.com/&quot; target=&quot;_blank&quot;&gt;Qwiklabs&lt;/a&gt; 플랫폼의 GCP 관련 실습 강의(ex.&lt;a href=&quot;https://www.qwiklabs.com/quests/132&quot; target=&quot;_blank&quot;&gt;Engineer Data in Google Cloud&lt;/a&gt;)가 많은 도움되었습니다. Hadoop의 경우 조금 오래된 강의지만 &lt;a href=&quot;https://www.udemy.com/&quot; target=&quot;_blank&quot;&gt;Udemy&lt;/a&gt; 플랫폼의 &lt;a href=&quot;https://www.udemy.com/course/the-ultimate-hands-on-hadoop-tame-your-big-data/&quot; target=&quot;_blank&quot;&gt;The Ultimate Hands-On Hadoop&lt;/a&gt; 강의를 통해 기본 개념을 익힐 수 있었던 기억이 납니다. 이 외에도 &lt;a href=&quot;https://www.udacity.com/&quot; target=&quot;_blank&quot;&gt;Udacity&lt;/a&gt;, &lt;a href=&quot;https://www.oreilly.com/&quot; target=&quot;_blank&quot;&gt;O’Reilly&lt;/a&gt; 등의 강의 플랫폼에서 유용한 강의들을 찾으실 수 있습니다.&lt;/p&gt;

&lt;h4 id=&quot;2-나만의-작고-귀여운-etl-파이프라인을-만들어보자&quot;&gt;2) 나만의 작고 귀여운 ETL 파이프라인을 만들어보자.&lt;/h4&gt;

&lt;p&gt;데이터 엔지니어링 분야에서 가장 무난하게 포트폴리오를 만들 수 있는 것은 ETL 파이프라인이라고 생각합니다. 꼭 가고 싶은 회사의 프레임워크와 일치하지 않아도 상관없으니, 관심 있는 API 데이터를 ETL 하는 파이프라인을 만들어보면 관련된 아이디어를 발전시킬 수 있을 거라 생각합니다.&lt;/p&gt;

&lt;h4 id=&quot;3-블로그를-잘-관리하자&quot;&gt;3) 블로그를 잘 관리하자.&lt;/h4&gt;

&lt;p&gt;신입 입장에서 이력서로 엄청난 차이를 보여주기는 쉽지 않다고 생각합니다. 이럴 때, 본인을 설명해줄 수 있는 개인 블로그나 포트폴리오 사이트가 있으면 좋습니다. 글이 완벽하지 않더라도 공부한 것들이나 관심있는 내용을 작성하면 좋은 것 같습니다.&lt;/p&gt;

&lt;p&gt;여기까지 데이터 엔지니어링팀 디니의 4개월 신입 회고였습니다.  온보딩 과정을 도와주신 팀원분들 이 자리를 빌어 다시 한번 감사드립니다.&lt;br /&gt;
긴 글 읽어주셔서 감사합니다. 궁금한 점이 있으시면 언제든 댓글 남겨주세요 :)&lt;/p&gt;</content><author><name>dini</name></author><category term="data" /><category term="data" /><category term="data-engineering" /><summary type="html">안녕하세요! 쏘카 데이터 엔지니어링 팀의 디니입니다.</summary></entry></feed>